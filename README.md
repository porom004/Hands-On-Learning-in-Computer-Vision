<div align="center">
  <p>
    <a align="center" href="https://www.labellerr.com/" target="_blank">
      <img
        width="850"
        src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp"
        alt="Labellerr Computer Vision Notebooks"
      >
    </a>
  </p>

  <div align="center">
      <a href="https://www.youtube.com/@Labellerr">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/youtube.svg"
            width="5%"
            alt="YouTube"
          />
      </a>
      <img src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/blank.png" width="3%"/>
      <a href="https://www.labellerr.com/">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/Logo2.svg"
            width="5%"
            alt="Labellerr App"
          />
      </a>
      <img src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/blank.png" width="3%"/>
      <a href="https://in.linkedin.com/company/labellerr">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/linkedin.svg"
            width="5%"
            alt="LinkedIn"
          />
      </a>
      <img src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/blank.png" width="3%"/>
      <a href="https://docs.labellerr.com/">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/SDK.svg"
            width="5%"
            alt="Documentation"
          />
      </a>
      <img src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/blank.png" width="3%"/>
      <a href="https://twitter.com/Labellerr1/status/1917643866460561520">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/twitter.svg"
            width="6%"
            alt="Twitter"
          />
      <img src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/blank.png" width="3%"/>
      <a href="https://www.labellerr.com/blog/">
          <img
            src="https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20GitHub%20Readme%20Assets/blog.svg"
            width="5%"
            alt="Blog"
          />
      </a>
      </a>
  </div>
</div>

# ðŸ‘‹ Welcome to Labellerr

This repository, **Labellerr Notebooks**, offers a growing collection of latest tutorials and notebooks related to AI Agents, computer vision, LLMs, and AI from Labellerr. Dive in to explore the exciting world of AI-powered vision for tasks ranging from object detection and segmentation to robust object tracking and OCR.

---

# ðŸš€ Model Notebooks

Here you'll find a curated collection of notebooks for state-of-the-art computer vision models, categorized by their primary task.

## *Fine-Tune YOLO for Various Use Cases*

| **Use Case**       | **Jupyter Notebook** |  **YouTube** *(Click to view)* |
|:----------------|:--------------------:|:-----------:|
| **Fine-Tune YOLO for PPE Detection** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/fine-tune-yolo-PPE-detection.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/fine-tune-yolo-PPE-detection.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/Q2-ZH9w3bgo/mqdefault.jpg)](https://www.youtube.com/watch?v=Q2-ZH9w3bgo&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=8&t=2s&pp=iAQB) |
| **Fine-Tune YOLO for Emergency Vehicle Detection** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/fine-tune-yolo-for-Emergency-vehicle-detection.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/fine-tune-yolo-for-Emergency-vehicle-detection.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/Mzk8ynEibGs/mqdefault.jpg)](https://www.youtube.com/watch?v=Mzk8ynEibGs&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=7&t=27s&pp=iAQB) |
| **Fine-Tune YOLO for Product Recognition in Retail Checkout** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune_YOLO_for_Product_Recognition_for_Price_Verification.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune_YOLO_for_Product_Recognition_for_Price_Verification.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/3qKqttdwxnM/mqdefault.jpg)](https://www.youtube.com/watch?v=3qKqttdwxnM&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=7&t=63s) |
| **Real-Time Intrusion Detection System with YOLO** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Intrusion_detection_using_YOLO.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Intrusion_detection_using_YOLO.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/kwQeokYDVcE/mqdefault.jpg)](https://www.youtube.com/watch?v=kwQeokYDVcE&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=6&t=58s) |
| **Fine-Tune Yolo for Football analytics** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine_tune_yolo_for_football_analytics.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine_tune_yolo_for_football_analytics.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/NIGLTumGF5o/mqdefault.jpg)](https://www.youtube.com/watch?v=NIGLTumGF5o&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=5) |
| **Fine-Tune YOLO for Automated Product Counting** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-Production-Line-Counting.ipynb.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-Production-Line-Counting.ipynb.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/fFjIkRte5R8/mqdefault.jpg)](https://www.youtube.com/watch?v=fFjIkRte5R8&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=4) |
| **Using YOLO for 3D Cuboid Detection** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Using-YOLO-for-3D-Cuboid_detection.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Using-YOLO-for-3D-Cuboid_detection.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/fsYoIE9Txmc/mqdefault.jpg)](https://www.youtube.com/watch?v=fsYoIE9Txmc&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=3) |
| **Fine-Tune YOLO for Traffic Flow Counting** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Traffic-Flow-Counting.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Traffic-Flow-Counting.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/L9RNTGcFbUg/mqdefault.jpg)](https://www.youtube.com/watch?v=L9RNTGcFbUg&list=PLNxw1dU6gZmj7HdqcnHl72yQbcajqJtQy&index=2) |
| **Fine-Tune YOLO for Threat Detection** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Threat-Detection.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Threat-Detection.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/0cB7X1CffTw/mqdefault.jpg)](https://youtu.be/0cB7X1CffTw?si=GzF8H1_NMNuc1owU) |
| **Fine-Tune YOLO for Car Parking Monitoring** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Parking-Space-Monitoring.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Parking-Space-Monitoring.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/CBQ1Qhxyg0o/mqdefault.jpg)](https://youtu.be/CBQ1Qhxyg0o?si=GzF8H1_NMNuc1owU) |
| **Fine-Tune YOLO For Fruits Counting** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-For-Fruits-Counting.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-For-Fruits-Counting.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/44G-myXqFZY/mqdefault.jpg)](https://youtu.be/44G-myXqFZY?si=GzF8H1_NMNuc1owU) |
| **Using-YOLO For Finding Athlete Speed** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Using-YOLO-For-Finding-Athlete-Speed.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Using-YOLO-For-Finding-Athlete-Speed.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/txW0CQe_pw0/mqdefault.jpg)](https://youtu.be/txW0CQe_pw0?si=GzF8H1_NMNuc1owU) |
| **Fine-Tune YOLO for Fire Detection** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Fire-Detection.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Fire-Detection.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/oHDoGYTdzyc/mqdefault.jpg)](https://youtu.be/oHDoGYTdzyc?si=GzF8H1_NMNuc1owU) |
| **Fine-Tune YOLO for Cell Counting** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Cell-Counting.ipynb)<br>[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/fine-tune%20YOLO%20for%20various%20use%20cases/Fine-Tune-YOLO-for-Cell-Counting.ipynb) | [![YouTube Thumbnail](https://img.youtube.com/vi/OxpR7DgGtC0/mqdefault.jpg)](https://youtu.be/OxpR7DgGtC0?si=GzF8H1_NMNuc1owU) |

## *Object Detection*

| **Model**            | **Jupyter Notebook** | **Complementary** | **Repository / Paper** |
|:---------------------|:--------------------:|:-----------------:|:----------------------:|
| **YOLO-NAS**         | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/YOLO/YOLO-NAS/yolo-nas.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/the-ultimate-yolo-nas-guide-2025-what-it-is-how-to-use/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=M0duRkr9GEg) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/YOLO/YOLO-NAS) |
| **YOLOv11**          | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/YOLO/YOLOv11/YOLO-EXP-all-vision-task.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/how-to-perform-yolos-various-task/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=L0nhtdvu6z0) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/YOLO/YOLOv11) [![arXiv](https://img.shields.io/badge/arXiv-2410.17725-b31b1b.svg)](https://www.arxiv.org/abs/2410.17725)|
| **YOLOv12**          | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/YOLO/YOLOv12/yolov12_testing.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/evaluation-of-yolov12/) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/YOLO/YOLOv12) [![arXiv](https://img.shields.io/badge/arXiv-2502.12524-b31b1b.svg)](https://arxiv.org/abs/2502.12524)|
| **RT-DETR V1 and V2**| [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/DETR/RT-DETR_V1_V2.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/rt-detrv2-beats-yolo-full-comparison-tutorial/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=9855PcoFceQ) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/DETR) |
| **Florence 2**       | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/Florence2/florence2_inference_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/how-to-perform-various-tasks-using-florence-2/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=L9ae7cvJ7Ow) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/Florence2) [![arXiv](https://img.shields.io/badge/arXiv-2311.06242-b31b1b.svg)](https://arxiv.org/abs/2311.06242) |
| **OWL v2**           | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/OWL/OWLv2/OWLv2.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/how-to-perform-various-task-using-owl-v2/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=O9QX8W9xXJY) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/OWL/OWLv2) [![arXiv](https://img.shields.io/badge/arXiv-2306.09683-b31b1b.svg)](https://arxiv.org/abs/2306.09683)|

## *Object Segmentation*

| **Model**                | **Jupyter Notebook** | **Complementary** | **Repository / Paper** |
|:-------------------------|:--------------------:|:-----------------:|:----------------------:|
| **SAM 2**                | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/SAM2/SAM2_inference_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/learn-sam-2-in-minutes/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=4Emb4j1T6-8) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/SAM2) [![arXiv](https://img.shields.io/badge/arXiv-2408.00714-b31b1b.svg)](https://arxiv.org/abs/2408.00714) |
| **Grounding DINO + SAM** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/Vision%20Agent/Vision_Agent_using_Segment_Anything.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/vision-agent-using-segment-anything/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=mVkPXbWxnEg) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/Vision%20Agent) [![arXiv](https://img.shields.io/badge/arXiv-2303.05499-b31b1b.svg)](https://arxiv.org/abs/2303.05499) |
| **Mask2Former**          | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/Mask2Former/Mask2Former_experiment_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/mask2former-hands-on-tutorial-guide/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=9rnRmx5WQzc) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/Mask2Former) [![arXiv](https://img.shields.io/badge/arXiv-2112.01527-b31b1b.svg)](https://arxiv.org/abs/2112.01527)  |
| **SegFormer**            | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/SegFormer/Segformer_inference_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/segformer/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=N-1_rt5kKN0) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/SegFormer) [![arXiv](https://img.shields.io/badge/arXiv-2105.15203v3-b31b1b.svg)](https://arxiv.org/abs/2105.15203v3) |
| **SegGPT**               | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/SegGPT/segGPT_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/seggpt-demo-code-next-gen-segmentation-is-here/) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/SegGPT) [![arXiv](https://img.shields.io/badge/arXiv-2304.03284-b31b1b.svg)](https://arxiv.org/abs/2304.03284) |
| **Florence 2**           | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/Florence2/florence2_inference_notebook.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/how-to-perform-various-tasks-using-florence-2/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=L9ae7cvJ7Ow) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/Florence2) [![arXiv](https://img.shields.io/badge/arXiv-2311.06242-b31b1b.svg)](https://arxiv.org/abs/2311.06242) |

## *Tracking Algorithms*

| **Model**      | **Jupyter Notebook** | **Complementary** | **Repository / Paper** |
|:---------------|:--------------------:|:-----------------:|:----------------------:|
| **ByteTrack**  | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/ByteTrack/bytetrack.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/how-to-implement-bytetrack/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=0gJjJ2P08GE) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/ByteTrack) [![arXiv](https://img.shields.io/badge/arXiv-2110.06864-b31b1b.svg)](https://arxiv.org/abs/2110.06864) |
| **BotSORT**   | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/BotSORT) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/bot-sort-tracking/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/nFQj6Qdxbus?si=2kBPcjj_QY-IsaAi) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/NirAharon/BoT-SORT) [![arXiv](https://img.shields.io/badge/arXiv-2206.14651-b31b1b.svg)](https://arxiv.org/abs/2206.14651) |
| **DeepSORT**   | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/DeepSORT/deepsort.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/deepsort-real-time-object-tracking-guide/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/MWi3BaAdw4g?si=3dO2OrXD2c9PgtsS) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/nwojke/deep_sort) [![arXiv](https://img.shields.io/badge/arXiv-1703.07402-b31b1b.svg)](https://arxiv.org/abs/1703.07402) |
| **FairMOT**    | ![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/implementing-fairmot-tutorial/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=64Ncymcfpsk) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/FairMOT) [![arXiv](https://img.shields.io/badge/arXiv-2004.01888-b31b1b.svg)](https://arxiv.org/abs/2004.01888)|
| **StrongSORT** | ![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/objects-tracking-using-strongsort/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=hviocgahbpc) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/dyhBUPT/StrongSORT) [![arXiv](https://img.shields.io/badge/arXiv-2202.13514-b31b1b.svg)](https://arxiv.org/abs/2202.13514) |
| **OC-SORT** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/OC-SORT) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/oc-sort/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/bORBNxLLTC0?si=KZOk9NimZHKXuJnD) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/dyhBUPT/StrongSORT) [![arXiv](https://img.shields.io/badge/arXiv-2202.13514-b31b1b.svg)](https://arxiv.org/abs/2202.13514) |

## *Other Vision Tasks*

| **Model**       | **Jupyter Notebook** | **Complementary** | **Repository / Paper** |
|:----------------|:--------------------:|:-----------------:|:----------------------:|
| **Mistral OCR** | [![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/blob/main/Model%20Notebooks/Mistral/mistralOCR/mistralOCR.ipynb) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/mistralocr-did-it-do-what-it-claim/) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision/tree/main/Model%20Notebooks/Mistral/mistralOCR) |
| **Matching Anything by Segmenting Anything** | ![Jupyter](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/jupyter-logo.svg) | [![Blog](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/LABELLERR-LOGO.svg)](https://www.labellerr.com/blog/matching-anything-by-segment-anything/) [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=HBk_hkP6k-I) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/siyuanliii/masa) [![arXiv](https://img.shields.io/badge/arXiv-2406.04221-b31b1b.svg)](https://arxiv.org/abs/2406.04221) |

## ðŸ’» *run locally*

We try to make it as easy as possible to run Labellerr Notebooks in Colab and Kaggle, but if you still want to run them locally, below you will find instructions on how to do it. Remember don't install your dependencies globally, use [venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/).   
<a href="https://trackgit.com">
  <img src="https://us-central1-trackgit-analytics.cloudfunctions.net/token/ping/mhekogqktzej6g2xqnom" alt="trackgit-views" />
</a>
