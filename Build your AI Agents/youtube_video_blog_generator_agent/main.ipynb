{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7129bc63",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **YT Video Blog Generator**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525d7d8",
   "metadata": {},
   "source": [
    "This notebook implements an automated multi-agent pipeline that transforms YouTube videos into professional blog articles using CrewAI. The system employs three specialized AI agents working in sequence: a transcript extractor that retrieves and structures video content, an outline drafter that organizes the material into a logical blog structure, and a content writer that generates polished, publication-ready articles.\n",
    "\n",
    "The pipeline begins by extracting transcripts from any YouTube URL format using a custom tool that handles various video types (shorts, live streams, embeds). The extracted content then flows through a structured workflow where agents analyze, organize, and refine the material while maintaining the original video's educational value and insights.\n",
    "\n",
    "Key features include configurable LLM settings for different creative tasks, professional writing guidelines to ensure human-like quality, and automatic saving of generated content with timestamps. This system effectively repurposes video content into written format, saving significant time while maintaining content quality and coherence. The modular design allows for easy customization and extension to handle various content types and writing styles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1984f8d",
   "metadata": {},
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c324451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crewai python-dotenv youtube-transcript-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25e290",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Imports and Environment Setup\n",
    "\n",
    "This cell imports all necessary libraries and dependencies for the YouTube to Blog conversion system:\n",
    "\n",
    "- **crewai**: Core framework for creating AI agents, tasks, and crews\n",
    "- **dotenv**: For loading environment variables from .env file\n",
    "- **youtube_transcript_api**: For extracting transcripts from YouTube videos\n",
    "- **re**: Regular expressions for URL parsing\n",
    "- **os**: Operating system interface for environment variables\n",
    "\n",
    "This setup provides the foundation for the multi-agent system that will process YouTube videos and convert them into blog posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481b68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Imports and Environment setup =====\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.tools import tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4683a6e",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Load API Key from .env\n",
    "\n",
    "This cell loads the Gemini API key from the environment variables:\n",
    "\n",
    "- Uses `load_dotenv()` to read the `.env` file\n",
    "- Retrieves the `GEMINI_API_KEY` environment variable\n",
    "- Stores it for later use by the LLM configurations\n",
    "\n",
    "**Important**: Make sure your `.env` file contains `GEMINI_API_KEY=your_actual_key_here` for the system to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db60888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Load API Key from .env =====\n",
    "# Make sure you have a .env file with a line: GEMINI_API_KEY=your_key_here\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c5106",
   "metadata": {},
   "source": [
    "### ðŸŽ¬ YouTube Transcript Extractor Tool\n",
    "\n",
    "This cell defines a custom tool for extracting transcripts from YouTube videos:\n",
    "\n",
    "**Key Features:**\n",
    "- Supports multiple YouTube URL formats (watch, youtu.be, embed, shorts, live, mobile)\n",
    "- Extracts 11-character video ID using regex patterns\n",
    "- Fetches English transcripts, falling back to auto-generated if needed\n",
    "- Returns cleaned, concatenated transcript text\n",
    "\n",
    "**Error Handling:**\n",
    "- Returns descriptive error messages if video ID extraction fails\n",
    "- Handles exceptions during transcript fetching gracefully\n",
    "\n",
    "This tool is essential for the first agent to obtain raw content from YouTube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47374adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"YouTube Transcript Extractor\")\n",
    "def extract_youtube_transcript(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract transcript from any YouTube URL format.\n",
    "    \n",
    "    Supports: watch, youtu.be, embed, shorts, live, mobile URLs.\n",
    "    Returns English transcript text of video.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract 11-char video ID from any YouTube URL format\n",
    "        video_id = None\n",
    "        \n",
    "        # Try query parameter first (watch URLs)\n",
    "        if 'v=' in url:\n",
    "            video_id = re.search(r'v=([a-zA-Z0-9_-]{11})', url)\n",
    "        \n",
    "        # Try path-based formats (youtu.be, embed, shorts, live, v)\n",
    "        if not video_id:\n",
    "            video_id = re.search(r'(?:youtu\\.be/|embed/|shorts/|live/|/v/)([a-zA-Z0-9_-]{11})', url)\n",
    "        \n",
    "        if not video_id:\n",
    "            return \"ERROR: Could not extract video ID from URL.\"\n",
    "        \n",
    "        # print(video_id.group(1))\n",
    "        \n",
    "        video_id = video_id.group(1)\n",
    "        \n",
    "        api = YouTubeTranscriptApi()\n",
    "        transcript_list = api.list(video_id)\n",
    "\n",
    "        # Try fetching English transcript, fallback to auto-generated\n",
    "        try:\n",
    "            transcript = transcript_list.find_transcript(['en']).fetch()\n",
    "        except Exception:\n",
    "            transcript = transcript_list.find_generated_transcript(['en']).fetch()\n",
    "\n",
    "        # Each entry is now a FetchedTranscriptSnippet object\n",
    "        # Access its .text attribute instead of ['text']\n",
    "        text = ' '.join([snippet.text for snippet in transcript])\n",
    "\n",
    "        return text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e386345",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Function (Commented Out)\n",
    "\n",
    "This cell contains a commented-out test function for the transcript extractor:\n",
    "\n",
    "- Can be uncommented to test the YouTube transcript extraction\n",
    "- Useful for debugging URL parsing and transcript fetching\n",
    "- Replace the URL with any YouTube video to verify the tool works correctly\n",
    "\n",
    "**Usage Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c429c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I'm going over how to write production code in Python. This is a topic that's extremely important that many developers honestly never learn and it's the number one thing that separates a junior developer from a senior developer. If you're serious about writing Python code and becoming a Python developer, then definitely watch this video and I'm going to go over a lot of concepts with in-depth examples so you can understand exactly how you can apply them to your own codebase. Okay, let's dive into it. And by the way, if you want access to all of the code that I show in this video, as well as this cheat sheet that I have on screen right now, you can do that by clicking the link in the description. Simply sign up for my newsletter and I will send it over to you for free. So, this video will cover eight main design principles with in-depth examples. We'll quickly go over what those principles are and then we'll dive into the code and explain them more in depth. Number one, cohesion and single responsibility, encapsulation and abstraction, loose coupling and modularity, reusability and extensibility, portability, defensibility, maintainability and testability, and then simplicity. Now, there are many other design principles and this is not an exhaustive list, but these, in my opinion, are the most important and the ones that you definitely need to get right, especially if you want to get to that senior level. So with that said, let's dive in and start talking about cohesion and the single responsibility pattern. Now this essentially states that you want to have one job for every single piece of code that you write. So in the case of Python, every class or every function should only have one reason to change. Now when you have high cohesion, that means that related things are grouped together. Related classes are in the same file. Related modules are in the same folder. Related code is in the same function. So you want to always aim for a high cohesion when you're writing code. Now single responsibility principle is just something that states that every piece of code that you write should have one single responsibility. And this actually ties into a lot of the other design principles that we'll talk about and will allow you to just generally have significantly better code. So let's start by looking at an example of bad user management. Full disclosure, a lot of this code was generated with AI, but obviously I reviewed it and told it what to generate just faster than me writing it from scratch. So here you're going to see an example of a class that at first glance looks fine. However, as a program grows, which is really the importance of these design principles, scaling and getting into large enterprisegrade software, this becomes a really big problem. So if we skim through this, you'll see that we have a user manager class and inside of here we initialize it by creating some users and then we have kind of this mega function that does a bunch of different things. It performs validation. It looks in the database. It sends an email. It then reports this to some logs and all of the tasks like sending a welcome email, you know, logging the creation and generating the user report are all inside of this one class which is called the user manager. Now again in smaller programs this is fine. you know, no one's going to yell at you for this, but as things get larger and more complex and as you maybe want to change the database or change the email reporting system or change the logic here, right, for the logging, it can be very difficult to do that because you've tightly coupled all of these operations together. So, let's have a look at some good user management and see how we separate this out. Now, at first glance, when you see these examples, it's going to seem overkill. It's going to seem like, why am I doing this? It's so much more code. But again, this is that systems level thinking that you have as a senior software engineer where you're anticipating what's going to happen in the future and preparing for that now. So in this example, every class that we look at has a single responsibility. We have a class for an email validator for a password validator. We have a user repository class. And notice that while it seems simple, right, and we just have single functions inside of here, it's very clear what each of these classes are doing. For example, this is how we save a user. This is how we get all the users. This is how we initialize the users. And it's stored in a very accurately named class, user repository. Continuing, we have an email service. In here, we could easily change the implementation of this function or use some other email service. We have a user activity logger. And then we go to our main user service. In here, our function effectively does the exact same thing that it did before. But now we delegate all of this work out to the individual services where if we did need to change something in the future or debug our code or maybe even change the service, it's a lot easier to do that, right? So when we initialize the class, we take in a repository, we take in an email service and we take in a logger and we then use that inside of the class. Okay. Okay. And then if we keep going, you can see that now if I wanted to change how the user service operates, it would be very easy for me to do that. I would simply just change the repository that I passed to my user service, right? Or I would change the email service or change the logger because of the way that I've set this up. Now, as you can see some benefits, right? Each class has one reason to change. Easy to test validator. So you can test all of these individual functions. You can easily swap the various services and you can reuse these components in other contexts because they're not tightly coupled into this one kind of user mega class that we had before. Now again, in small programs, this isn't an issue. In fact, you're probably looking at this and going, \"This is completely overkill. Why would I ever write this?\" Again, this is only important in large systems, which is what I'm trying to teach you in this video. You may not start with this type of code, but as your software gets more complex, you want to start thinking about these things and make sure that you're really just doing one thing in all of your classes, in all of your functions, and that the cohesion is good. Now, before we get into the next design principle, I want to take a moment to thank today's sponsor, boot.dev. It's an online learning platform designed specifically for back-end development, and it approaches learning in a way that's far more interactive than the usual video-based courses. Rather than having you sit through hours of lectures, boot.dev puts you straight into hands-on coding. You'll work directly in your browser building real projects while learning back-end fundamentals like APIs, databases, and serverside logic using Python and Go. Now, what makes it stand out is the way that it borrows from game design. You'll progress through levels, unlock new content, and keep your momentum up as you go. The platform is filled with exercises and practical challenges. So you'll end up writing a lot of code, which is exactly what helps you improve. Now, all of the core content is free to access, and if you decide to commit to the annual plan, you can use the code tech with Tim to get 25% off your first year. I've been going through it myself lately, and honestly, it's surprisingly addictive. Thanks to boot.dev. Now, let's get back into it. Now, we move on to the next topic here, which is encapsulation and abstraction. Now this essentially means that you want to hide the implementation details from other users or other programmers in our case and simply present a useful interface. What that means is that you want to keep internal state private. You want to expose the behavior of the code not the data and you want to use things like properties and getters for controlled access and always abstract away all of the complexity. Now, this can get out of control quite quickly, but let me show you what I mean because this is something that a lot of developers get wrong. Okay, so we're having a look at a pretty simple class here, right? A bank account class where we define some owner, we have some balance, and then we define some transactions. Now, it seems like what could possibly be wrong with this code, right? There's hardly any code here at all. But the thing is that with this type of code, it's actually too flexible. It allows us to do pretty much anything. And while we may know how to use this class correctly, another developer or someone implementing this bank account, right, or wanting to use it in their program may not. So you can see that we can, for example, have a negative balance, right? We can have some, you know, massive value in the balance that maybe doesn't make any sense. We can corrupt the internal state by setting it to something that's, you know, not a list, right? And you just notice that we have all of these problems where, again, if we're just writing this code for ourselves, it's not an issue. But if we wanted to provide this bank account to someone else to use, they can mess it up very badly, right? And this is going to tie into a lot of the other design principles that we'll look at later. The point is when you design things like a class that you intend for other people to use in the future, you want to design it so that it works exactly the way that it should work and you protect against all of these weird edge cases like negative balances, right? And you know, corrupting the internal state. So what I'm going to show you again is going to look overkill. There's always a debate on when to do this, but I want you to understand these patterns because that's the point of this video. So, if we scroll down, notice that now my bank account class first of all is expanded. It has a lot more code, but now it is very kind of secure in terms of the way in which we utilize it and it exposes behavior, not data. So, notice that we've used what's called a private attribute in Python. This is not actually truly private. you still can access it but by using a leading underscore before an attribute name that indicates that this is internal to the class or to the structure and that you should not modify it from outside. So now after the bank account is initialized the owner the balance and the transactions are all private attributes that we should not touch outside of using the interface that's exposed to us exposed to us sorry which is the uh the methods that are here right the public methods. So you see we go down here, we have a deposit method. Now in the deposit method, we have value errors that we're raising where you can't deposit a negative amount, right? And then we modify the internal state. We actually create a transaction. So we're now tracking all of this internally in the way in which we should do that. And we're not exposing all of this kind of data and functionality and implementation that we don't need to. If a user wants to deposit money in the bank account again like another programmer using this class, they simply use the deposit method. they don't need to worry about how it works. Same thing with withdrawing, right? We make sure they can withdraw the correct amount. We make sure that it's, you know, a amount that's non- negative, right? We then adjust the balance. We put the transaction in here and everything is done properly. Then we have a get balance function which actually exposes the internal state. Here we could also maybe do something with the balance like rounding the value or something. we can generate a statement and then we have private internal helper methods which we denote again with this leading underscore which are only meant to be used internally and not exposed to the user. So as someone using this class all you need to know is that you have these four methods you can use them they simply work and all of the implementation details are hidden from you. Now the next example that we look at here is called loose coupling and modularity. Now, the definition of coupling is how tightly things are connected together. Typically, when you write code, you don't want to couple things together too much. What that means is that you don't want to write functions that rely on other functions or rely on some specific implementation or some specific class or environment variable or all of these things that are essentially tying all of these components in together. You want to make things as flexible as possible and to purely rely on kind of their internal state and logic as opposed to external things, right? I know it's kind of a vague definition, but here what we're going to do, right, is we're going to talk about interfaces, abstract classes, injecting dependencies, and components that can be swappable. So rather than coupling, for example, our email service to only one email provider, it should work with any email provider. So we could simply swap that in the future and we're good to go. And that's exactly the example that I'm going to look uh look at right now with you. So let's have a look at some tightly coupled um code. So we have this email sender class, right? And notice that directly inside of my order processor, I actually couple the email sender inside of it. Now the reason why this is coupled is because now if this email sender class ceases to exist, this code no longer works, right? And it means that I now cannot change the email sender class that I'm going to use inside of here. I would have to actually just make a modification directly to this class. Instead, what you would want to do is you would want to take in the email sender as a parameter and rather than relying on an exact class implementation, you rely on what's called an abstract class which actually enforces or yeah, kind of defines an interface that any email sender needs to have. We'll talk about that more later, but that's a quick example. So, the point is we've coupled this together and now anytime I want to send an email, I have to use this email sender. So let's have a look at a loosely coupled application which is again going to look overkill which is this good notification folder. Now inside of here we have a lot of code. So let me just open it up and I can show you how we've decoupled this application and the fact that now all of these components are individual and we inject them when we need them. So inside of main for example what we can do is you know create an instance of an email notifier. We can create an order processor by passing that email notifier inside. for our order processor. We also could pass an SMS notifier, right? We also could have a multiple notifier where now we passed in an email notifier or an SMS notifier and now this works. So this is just an example of usage how now my order processor isn't coupled to one type of service. It can actually use multiple. Now the reason why that's the case is because we've defined what's called an abstract base class in Python. This is kind of the closest thing you can get to what's referred to as an interface where essentially you can define a class that dictates what any class that inherits from it must define. So in this case we're going to say anything that can be used as a notifier must have this send method. The send method has to look like this where we have a recipient, a subject and a message. Now by writing this method with the abstract method decorator, this enforces that anything that inherits from it that wants to implement this class must have this method. So now if I go to my order processor, you'll notice that for my order processor, I actually only rely on the fact that I'm using a notifier. So I say, okay, I'm going to import this notifier class and I'm going to use a notifier as my parameter type, which means you can pass me any concrete implementation of the notifier. I don't care what it is so long as it has this definition, right? So long as it has this send method. So now inside of here, I can use this send method and it doesn't really matter what implementation of the notifier that I'm using, this class still works and it's loosely coupled from what's actually notifying the user. Right? So now if I go to my SMS notifier, you can see I inherit from this notifier abstract class and I can implement my SMS sending. Right? If I go to my email notifier, same thing. Same thing. I inherit from my abstract notifier. I implement the send method. And now both my email notifier and my SMS notifier can be used interchangeably inside of my order processor or anywhere where I want to rely on this notifier abstract class. Same thing with the multi notifier. I take a list of notifier objects, right? And as long as they have that implementation and they have that send method, I'm good to go. This allows me to use them interchangeably and is a huge benefit. Now the next pattern on my list is reusability and extensibility. Essentially this means ask yourself the question can I add new functionality without editing existing code. Sound straightforward? Let's have a look at an example. So here's a bad example of a report generator. We have this monolithic generator where it's very difficult to extend it and add functionality because we do everything inside of this one function. Right? So we check, you know, if there's a text format, if there's a CSV format, if there's an HTML format, and if I wanted to add additional formats, I would need to go in here. I would need to understand the logic. I would need to write another L if statement. And I would just keep doing that and have this kind of endless nest of if L if statements, which really is not best practice. Again, for short programs, fine, non-issue. For larger software starts to become a problem and really isn't good practice. Now, let's hop over to the good report example and see how we can modify this. So, similarly to what we looked at before, we now define an abstract base class. This defines that anything that wants to be a report formatter must have this format method. We then are able to write all of the different format methods that we need. So, we can have a text formatter. We can have a CSV formatter. Notice they're all implementing their own format method. And they could have other ones if they want to. HTML formatter. Now, I have a new JSON formatter. Now, I have a new markdown formatter. Right? So I've written all of these individual formatterers based on this interface right here. And then for my report generator, what I can do is I can take in any report formatter, right? And then I can generate a report by simply using that formatter. So now if I want to extend this, there's no changes that need to be made to my report generator. I simply write another report formatter and I can now pass that into my report generator and it can generate a report. It's extensible without needing to be modified. And if I go down here, you can see that I can use this generator with all these different formatterers. I can even use a list, for example, and it just works. Now, the next design pattern on my list is frequently forgotten, and that is portability. Essentially, what that means is, is what I'm writing right now going to work in a different environment? Is it going to work if I don't have the newest version of C++ installed? Is it going to work if I'm not on Windows 11.2.1? Is it going to work if I'm not on this new Mac version or using this crazy software? Right? So, when you think about portability, you essentially want to think, okay, how can I make sure the code that I'm writing is as portable as possible and is going to work in as many situations as it possibly can. Okay, so let's have a look at some examples here by looking at a file handler, which is actually where I most commonly see this done wrong. All right, so let's look at a bad file handler. Notice that we have this data processor. Okay. And then inside of here, we hardcode some input and output directories. Now, immediately by us hard- coding these directories, what we've done is just ensure that this code will never work on any machine other than ours. The reason for that is that I would need to manually change this, which is obviously not good for the code. That doesn't make it portable. And this is a Windows file path, which means even if we did have these exact uh directory structures on Mac or Linux, for example, this would simply not work because of the fact that we've hard-coded the Windows style path rather than using a dynamic path, which you can do in Python. We've also hardcoded a database connection. We've hardcoded the API endpoint. So again, I can only use this in this exact environment situation, which is almost never when I would want to use this, especially in production. Okay. And then same thing for processing the file, right? I'm building these hard-coded paths with this Windows style separator. And this only now will work on Windows. So if we go to a good example here, you can see that what I do right away is I import OS and I create this environment variable file. Inside of here, I put all of the dynamic values that I may need to change depending on the environment in which I'm running this code. Very common. You've probably seen an environment variable file before, right? I have my database information. I have my API information. I have the current environment I'm in. I have the file path directory which works crossplatform. Right? And now if I go here, I rely on environment variables rather than relying on hard-coded values. Same thing for my file paths. I use the path variable from the path lib which makes this dynamic and works crossplatform. Okay, there's a lot of other stuff in this example. The point is this now works no matter what environment you're in because we've created this kind of dynamic environment variable file that we read from which tells us essentially what to do and what values to use based on our environment. The next example on my list is defensibility. Now this means writing your code as if an idiot was going to use it. That essentially means that you want to validate all of the input. You want to have for example least privilege access which we'll talk about later and things like safe default values. Now, you always want to ask yourself, what's the worst thing that could possibly happen to my code if bad input was provided? And you want to make sure that you defend against that situation. You're essentially writing code that no other developer could use in a way where it would, you know, alter the system or mess something up quite badly. So, let's have a look at some examples here so you can see what I mean and let's get into it. Okay, so here's an example of a bad payment processor. You can see that we have, you know, debug mode is equal to true. Probably wouldn't want that to be true. we'd probably want that to be false because if someone accidentally left that on, that could be a huge issue. For maximum retries, we probably don't want that to be 100. That's a crazy default value that could potentially cause the system to lag or even crash. And then we don't have any timeout value, right? So all these default values that we've set are not safe. Whenever you set a default value, you want to set it in a way such that if someone didn't change it, your code would work properly and it would be a reasonable value. Right? Now, same thing with processing the payment. The biggest thing you can make a mistake with is not validating or sanitizing your input. So, in this case, you can see that we have some amount, some account number, some CVV, and it's not even typed properly, right? So, we don't even have like the type in Python. And this means that someone could pass, you know, a string for an amount. They could pass an invalid account number. You get the idea. And here we're not checking any of those things. Okay? So that's kind of the idea is that I can use this function in crazy ways that will cause a crash or an exception in my program especially if I pass something that you know just isn't the right value. I also could pass some massive amount or you know the wrong account number. You get the idea. This function is prone to be using used sorry incorrectly. Now if we go to a good payment example you can see that again it looks more complex but this is what you need to think about. We have custom errors. So validation errors and payment errors. We have a payment result which is a immutable type which we define with a data class. We have a payment validator where we validate that the amount is actually correct before we allow you to charge that amount. We validate the account to ensure the account is correct and accurate and that the account number is clean before we actually try to use that. We validate the CVV number again if you're talking about like a credit card payment. And then we go through our payment processor. We have nice clean safe default values right for the processing of the payment. We make sure that everything is valid before we start trying to do anything. We only log the necessary information. We never log sensitive data. And then when we try to process the payment, if it doesn't work, we throw an error that makes sense so the user knows what the problem is. We then create an immutable result, which means you cannot modify the result, which is best practice. So someone doesn't accidentally change one of these values, which we shouldn't change related to a payment. Hopefully you're getting the idea here. But we've defended this method and this code really well where now someone can't really use this incorrectly. They can just call the function and even if they pass the wrong values, they're going to get clear error messages on what's going wrong. And we're going to make sure we don't accidentally charge someone's card with some ridiculous value. Now we move on to the next example, which is maintainability and testability. The thing that many people fail to realize about software is that the most expensive thing about it is not writing it. It is maintaining it. Any software that you write, no matter how large, is something that is prone to errors, prone to bugs, and that could eventually need to be changed, fixed, modified, who knows, right? You know, some developer could mess up their operating system, which could cause all of your software to go down and force you to have to go in there and make some changes. So, when you're writing software, you need to think about how you're going to maintain it, and more importantly, how you're going to test it. Especially as software scales, you need to have automated testing for this software. You can't rely on someone manually testing every single feature. And even if you could, a lot of stuff is going to slip through the cracks, right? So, what we're going to do is just quickly have a look at an example of how you write maintainable and testable code, focusing a little bit more on the testability side because code that is testable is kind of by default more maintainable. Not always, but in most cases it is. All right, so let's have a look at a example of a bad calculator. Now, this is a calculator that has a super complex calculate method, right? We have all these kind of nested statements. We're dealing with tries and excepts and with statements, and we're writing stuff to a file. We have all these side effects that are happening inside of our function. And we're just doing like so much stuff that at first glance, it's very difficult for us to understand what this function does. And if I wanted to test it, there's like 30 different examples of things that could happen in this function, right? I pass some expression. It could maybe be a plus. It could be a minus. It could be a multiplier. It could write to a function. It could not write to a function. It could throw an error. How the heck am I going to test this function? Right? I'm going to have to think through 500 different edge cases. There's no way I'm going to get 100% coverage of this. So, how do we make that better? Well, we go to this example. Notice here I now start separating things into smaller components like we talked about earlier that are easier for me to test. I have a calculation result, easy for me to check if the calculation result is correct. I have an operation parser. Rather than just passing a whole expression, I now pass an expression to one function. And this function is purely responsible for parsing the expression. That's a lot easier for me to test, right? Than a whole calculator function. I have different operations. I can test to make sure my add, my subtract, my multiply, my divider working properly. Super easy for me to test that code. Then I have something that gets the operation. Again, I can make sure it's mapping to the correct values. Then I have my calculator. And look at how much simpler this function is. I have a an operator a b I get the operation. I perform the operation and boom, I can test this and it doesn't take a million different edge cases, right? And then if we go to a calculator with history, same thing. We now have the ability to kind of log the history of the calculator results. much easier for me to test how this is working where I've decoupled it from the calculator and I'm able to actually just make sure the component that I'm looking for which is a history component is working without testing the calculator at the same time. Hopefully you get the idea. Again, it seems more complex. It takes more time upfront. Good code is difficult to write. That's why we have senior developers. People still get paid a massive amount of money. And I guarantee you if you ask AI to generate this style of code, it's not always going to make the best decisions. And you need to know deep down what the correct architecture and design is, which is why I'm showing you these patterns. Now, the last pattern that I'm just going to go over verbally here, I'm not going to dive into the code, is simplicity. And a few of these kind of sub patterns, like keep it simple, stupid, don't repeat yourself, and you aren't going to need it. Now, these are very common patterns, so I'm not going to spend too much time covering them, but these are things that you always want to ask yourself when you're writing code. First of all, keep it simple, stupid. The simpler the code is, first of all, the harder it is to actually write. It's much more difficult to write simple code than it is to write complex code. So keep that in mind if you know you have an ego about writing something that's really complicated and convoluted. But it makes it just easier for you and other people to understand. You always want to simplify everything you do as much as humanly possible so that anyone in the future could get in there and modify the code. And more importantly, you can modify the code when you forget what the heck you did 3 years later. Next, don't repeat yourself. It's very common for people to redefine the same variables, redefine the same config, keep using the same function in slightly different variations across their code, and you end up with this absolute mess where there's all these different places where you might need to make a change in the future. You want to make sure you're not repeating yourself. You're writing reusable functions that anything you're doing more than one time, you wrap it into some type of reusable component so you can simply pull it in. All of the code is contained in one place. It's easier to test, it's easier to maintain, and it's easier to change. Lastly, you aren't going to need it. Now, this just means that you don't want to over complicate things at the beginning. As much as these design patterns are great, you don't always need to dive into doing these immediately. Sometimes you don't need the most extensible, flexible, testable code in the world. And if that's the case, don't add it. Don't add features that you don't actually need. Don't overengineer solutions unless it's something that you think is actually feasible to come up in the future. For example, when I was coding my startup, I actually ignored a lot of these design patterns because I didn't need it. It didn't make sense for what I was building. It was going to take me so much more time compared to just getting out a quick prototype so I could validate the idea. So, always ask yourself, what does the business need before you go into the engineering? Because a lot of us as engineers, we forget that the whole value of code is typically to generate money or value, right, for a company. So if you don't need all of those things, if it's not going to be required in the future, you don't need to go ahead and do that over engineering and spend a massive amount of time building something that just never is going to see the light of day. Okay, so that's kind of the common stuff I wanted to go over. Now again, if you want this whole document, so this as well as all of the code and all of the examples that I have here, then simply sign up for my newsletter from the link in the description. If you guys like these more advanced complicated videos, please let me know and I will make more. And I look forward to seeing you in another one. [Music]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "# url = \"https://youtu.be/qU3Rc6_B9es?si=PbQHMxaZrM9o3ocA\"\n",
    "# print(extract_youtube_transcript(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e51a5",
   "metadata": {},
   "source": [
    "### ðŸ¤– LLM Configuration\n",
    "\n",
    "This cell configures three separate LLM instances with different temperature settings:\n",
    "\n",
    "- **extracting_llm** (temperature=0.1): For precise transcript extraction tasks\n",
    "- **outline_llm** (temperature=0.2): For structured outline generation\n",
    "- **writing_llm** (temperature=0.7): For creative blog writing\n",
    "\n",
    "**Temperature Settings:**\n",
    "- Lower temperature = More deterministic, consistent outputs\n",
    "- Higher temperature = More creative, varied outputs\n",
    "\n",
    "Each LLM uses Gemini 2.0 Flash Lite model, optimized for different stages of the content generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bac13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LLM Setup =====\n",
    "extracting_llm = LLM(model='gemini/gemini-2.0-flash-lite', \n",
    "                     apikey=GEMINI_API_KEY, \n",
    "                     temperature=0.1)\n",
    "\n",
    "outline_llm = LLM(model='gemini/gemini-2.0-flash-lite', \n",
    "                  apikey=GEMINI_API_KEY, \n",
    "                  temperature=0.2)\n",
    "\n",
    "writing_llm = LLM(model='gemini/gemini-2.0-flash-lite', \n",
    "                  apikey=GEMINI_API_KEY, \n",
    "                  temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64a254",
   "metadata": {},
   "source": [
    "### ðŸ‘¥ Agent Definitions\n",
    "\n",
    "This cell defines three specialized agents that work together:\n",
    "\n",
    "#### 1. Extractor Agent\n",
    "- **Role**: YouTube transcript extractor\n",
    "- **Goal**: Extract and structure complete transcripts from YouTube URLs\n",
    "- **Tools**: Uses the YouTube transcript extractor tool\n",
    "- **Output**: Structured JSON with video title, URL, segments, and full text\n",
    "\n",
    "#### 2. Blog Outline Drafting Agent\n",
    "- **Role**: Content structure specialist\n",
    "- **Goal**: Create detailed blog outlines from transcripts\n",
    "- **Output**: Structured outline with title, introduction, sections, and conclusion\n",
    "- **Personality**: Analytical, structured, reader-oriented\n",
    "\n",
    "#### 3. Blog Writer Agent\n",
    "- **Role**: Professional content writer\n",
    "- **Goal**: Transform outlines into polished, human-like blog articles\n",
    "- **Writing Guidelines**: Professional tone, active voice, natural flow\n",
    "- **Personality**: Polished, thoughtful, articulate\n",
    "\n",
    "Each agent has specific backstory, tasks, and expected output formats tailored to their role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8055aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Agent Definitions =====\n",
    "extractor_agent = Agent(\n",
    "    role = \"youtube_transcript_extractor_agent\",\n",
    "    goal = (\n",
    "        \"Extract the complete transcript from a given YouTube video URL and provide it in a clean, structured format. \"\n",
    "        \"The output should include speaker timestamps (if available) and the full textual content of the video without summarization. \"\n",
    "        \"This transcript will serve as the raw source material for downstream agents such as the blog_outline_drafting_agent.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"This agent was developed to specialize in transforming video content into structured text data. \"\n",
    "        \"Unlike typical summarization agents, it preserves the full integrity of the spoken content, ensuring no loss of context. \"\n",
    "        \"It is capable of handling both short tutorials and long-form educational content. \"\n",
    "        \"The agent ensures the transcript is cleaned of any redundant formatting, ads, or irrelevant metadata, \"\n",
    "        \"making it ready for analytical or content generation tasks downstream.\"\n",
    "    ),\n",
    "    tasks = [\n",
    "        \"Extract the full transcript from the provided YouTube URL.\",\n",
    "        \"Automatically detect and parse all transcript segments, maintaining order and timestamp accuracy.\",\n",
    "        \"Combine all segments into a clean, human-readable text format.\",\n",
    "        \"Exclude ads, sponsor mentions, or unrelated metadata if detected.\",\n",
    "        \"Provide the complete transcript as structured text output.\"\n",
    "    ],\n",
    "    expected_output_format = {\n",
    "        \"video_title\": \"Title of the YouTube video (if retrievable).\",\n",
    "        \"video_url\": \"Original URL of the video.\",\n",
    "        \"transcript\": [\n",
    "            {\n",
    "                \"start\": \"Timestamp in seconds or readable format (e.g., 00:01)\",\n",
    "                \"text\": \"The spoken content of that segment.\"\n",
    "            }\n",
    "        ],\n",
    "        \"full_text\": \"Concatenated transcript text for downstream use.\"\n",
    "    },\n",
    "    tools = [extract_youtube_transcript],\n",
    "    llm = extracting_llm,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "blog_outline_drafting_agent = Agent(\n",
    "    role = \"blog_outline_drafting_agent\",\n",
    "    goal = (\n",
    "        \"From the transcript provided by the extractor agent (derived from a YouTube video), \"\n",
    "        \"create a structured and reader-friendly blog outline that serves as a foundation for the next agent to write the full article. \"\n",
    "        \"The outline should cover key points, insights, and subtopics that make the content engaging, educational, \"\n",
    "        \"and easy to understand for both students and professionals.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"This agent was designed by a content intelligence team specializing in transforming spoken knowledge into \"\n",
    "        \"readable, structured formats. Its expertise lies in identifying meaningful segments, extracting insights, and \"\n",
    "        \"organizing them logically into an outline. Drawing inspiration from industry best practices in content marketing, \"\n",
    "        \"it ensures that each blog outline not only mirrors the intent of the speaker but also optimizes readability for diverse audiences. \"\n",
    "        \"Whether the transcript is from a tech tutorial, a product walkthrough, or an expert discussion, the agent intelligently \"\n",
    "        \"structures the flow â€” from introduction and context to takeaways and actionable insights.\"\n",
    "    ),\n",
    "    tasks = [\n",
    "        \"Analyze the provided YouTube transcript for key themes, sections, and insights.\",\n",
    "        \"Group related ideas into logical sections (Introduction, Main Concepts, Applications, Summary, Takeaways, etc.).\",\n",
    "        \"Highlight learning objectives, definitions, or frameworks discussed in the video.\",\n",
    "        \"Ensure the outline is detailed enough for another writing agent to develop a complete blog post from it.\",\n",
    "        \"Maintain a balance between technical accuracy and readability.\"\n",
    "    ],\n",
    "    expected_output_format = {\n",
    "        \"Title\": \"A short and clear title representing the video/blog topic.\",\n",
    "        \"Introduction\": [\n",
    "            \"Brief overview of the topic and its importance.\",\n",
    "            \"Target audience and why it matters to them.\"\n",
    "        ],\n",
    "        \"Section 1\": \"Main concept or discussion point #1 with sub-bullets explaining what to cover.\",\n",
    "        \"Section 2\": \"Main concept or discussion point #2 with sub-bullets explaining what to cover.\",\n",
    "        \"Additional Sections\": [\n",
    "            \"Examples, case studies, or visual explanation ideas.\",\n",
    "            \"Common mistakes, FAQs, or myths if mentioned.\"\n",
    "        ],\n",
    "        \"Conclusion\": [\n",
    "            \"Key takeaways or final summary points.\",\n",
    "            \"Call-to-action or suggested next steps (e.g., related resources, tutorials).\"\n",
    "        ]\n",
    "    },\n",
    "    personality = (\n",
    "        \"Analytical, structured, and reader-oriented. Communicates in a clear and concise way, \"\n",
    "        \"with an understanding of content flow and audience engagement.\"\n",
    "    ),\n",
    "    output_example = (\n",
    "        \"Title: How AI is Transforming Video Analytics\\n\\n\"\n",
    "        \"Introduction:\\n- Explain the growing role of AI in video data processing.\\n\"\n",
    "        \"- Mention industries using AI-powered analytics.\\n\\n\"\n",
    "        \"Section 1: Understanding Video Analytics\\n- Definition and key components.\\n\"\n",
    "        \"- Traditional vs AI-based approaches.\\n\\n\"\n",
    "        \"Section 2: Core Technologies Behind AI Video Analysis\\n- Computer Vision and Deep Learning models.\\n\"\n",
    "        \"- Real-world examples like YOLO and MediaPipe.\\n\\n\"\n",
    "        \"Section 3: Applications Across Industries\\n- Security and surveillance.\\n- Retail analytics.\\n- Sports performance analysis.\\n\\n\"\n",
    "        \"Conclusion:\\n- Summarize the impact of AI.\\n- Encourage readers to explore more about real-time video intelligence.\"\n",
    "    ),\n",
    "    llm=outline_llm,\n",
    ")\n",
    "\n",
    "blog_writer_agent = Agent(\n",
    "    role = \"blog_writer_agent\",\n",
    "    goal = (\n",
    "        \"Using the outline created by the blog_outline_drafting_agent, craft a complete blog article that reads naturally, \"\n",
    "        \"reflects a human writing tone, and engages readers with clarity and depth. \"\n",
    "        \"The writing should be professional, coherent, and free from AI-sounding expressions, filler language, or overused transitions. \"\n",
    "        \"Each paragraph should flow logically and deliver value, ensuring that both students and professionals can easily follow and learn.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"This agent is a specialized long-form content creator trained on top-tier editorial standards. \"\n",
    "        \"It was developed to replicate the style of expert technical writers, industry bloggers, and thought leaders. \"\n",
    "        \"Instead of producing formulaic AI responses, it emphasizes natural phrasing, sentence variety, and contextual understanding. \"\n",
    "        \"It pays close attention to flow, pacing, and readability â€” ensuring that the content feels written by a skilled human writer \"\n",
    "        \"with subject expertise and narrative control. \"\n",
    "        \"Its writing is direct, engaging, and always aligned with the audiences knowledge level.\"\n",
    "    ),\n",
    "    tasks = [\n",
    "        \"Read and interpret the provided blog outline.\",\n",
    "        \"Expand each section into well-structured paragraphs with smooth transitions.\",\n",
    "        \"Use a professional tone suitable for both technical and general readers.\",\n",
    "        \"Avoid robotic phrasing, repetitive structures, or generic AI-generated wording.\",\n",
    "        \"Incorporate examples, insights, or simplified analogies where needed.\",\n",
    "        \"Maintain consistency in formatting, heading hierarchy, and grammar quality.\",\n",
    "        \"Produce clean, publication-ready text suitable for blogs or newsletters.\"\n",
    "    ],\n",
    "    writing_guidelines = {\n",
    "        \"Tone\": \"Professional, clear, and informative without being overly formal.\",\n",
    "        \"Style\": \"Active voice, well-paced paragraphs, natural flow of ideas.\",\n",
    "        \"Prohibited Elements\": [\n",
    "            \"Overuse of conjunctions like 'Moreover', 'Additionally', 'In conclusion'.\",\n",
    "            \"AI disclaimers or self-referential statements.\",\n",
    "            \"Long or unnatural sentences.\",\n",
    "            \"Unnecessary dashes or em-dashes.\"\n",
    "        ],\n",
    "        \"Formatting\": {\n",
    "            \"Headings\": \"Follow logical hierarchy (H1, H2, H3).\",\n",
    "            \"Paragraph Length\": \"3 to 5 lines maximum.\",\n",
    "            \"Readability Target\": \"Flesch reading ease between 55 to 70 (balanced for professionals and students).\"\n",
    "        }\n",
    "    },\n",
    "    expected_output_format = {\n",
    "        \"Title\": \"Final blog title reflecting clarity and SEO-friendliness.\",\n",
    "        \"Introduction\": \"Engaging context setting up the main idea and value proposition.\",\n",
    "        \"Body\": [\n",
    "            \"Multiple sections expanding on each outline point.\",\n",
    "            \"Include insights, examples, or explanations.\"\n",
    "        ],\n",
    "        \"Conclusion\": \"Clear wrap-up summarizing the learning or insights, possibly ending with a reflective note or a call to action.\"\n",
    "    },\n",
    "    personality = (\n",
    "        \"Polished, thoughtful, and articulate. \"\n",
    "        \"Writes with purpose and rhythm, ensuring that every line contributes to the readers understanding. \"\n",
    "        \"Balances technical precision with readability.\"\n",
    "    ),\n",
    "    output_example = (\n",
    "        \"Title: The Future of AI in Visual Recognition\\n\\n\"\n",
    "        \"Artificial Intelligence has reshaped how machines interpret the world around us. \"\n",
    "        \"From identifying faces in security systems to detecting diseases in medical scans, visual recognition has evolved rapidly. \"\n",
    "        \"In this article, we explore the key breakthroughs driving this change and what they mean for the next generation of applications.\\n\\n\"\n",
    "        \"Modern visual recognition relies on deep learning frameworks trained on millions of images. \"\n",
    "        \"These systems learn patterns, colors, and object relationships, allowing them to perform tasks that once required human perception. \"\n",
    "        \"Frameworks such as YOLO and OpenCV have made real-time image processing accessible to developers and researchers alike.\\n\\n\"\n",
    "        \"As the technology matures, industries from retail to healthcare continue to integrate AI-driven vision systems to improve accuracy and efficiency. \"\n",
    "        \"The next phase of innovation will focus on reducing bias, improving interpretability, and integrating visual data with contextual understanding.\\n\\n\"\n",
    "        \"The journey of AI in visual recognition has just begun. \"\n",
    "        \"With growing computational power and smarter models, the boundary between human and machine perception continues to blur.\"\n",
    "    ),\n",
    "    llm=writing_llm,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d0afe",
   "metadata": {},
   "source": [
    "### ðŸ“‹ Task Definitions\n",
    "\n",
    "This cell defines the workflow tasks that connect the agents:\n",
    "\n",
    "#### 1. Extract Transcript Task\n",
    "- **Agent**: Extractor Agent\n",
    "- **Input**: YouTube video URL\n",
    "- **Output**: Structured transcript data\n",
    "- **Output Key**: `transcript_data`\n",
    "\n",
    "#### 2. Draft Blog Outline Task\n",
    "- **Agent**: Blog Outline Drafting Agent\n",
    "- **Context**: Depends on transcript extraction task\n",
    "- **Input**: Transcript data from previous task\n",
    "- **Output**: Structured blog outline\n",
    "- **Output Key**: `blog_outline`\n",
    "\n",
    "#### 3. Write Blog Task\n",
    "- **Agent**: Blog Writer Agent\n",
    "- **Context**: Depends on outline drafting task\n",
    "- **Input**: Blog outline from previous task\n",
    "- **Output**: Complete blog article\n",
    "- **Output Key**: `final_blog`\n",
    "\n",
    "The tasks form a sequential pipeline where each task depends on the output of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41797c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_transcript_task = Task(\n",
    "    name=\"Extract YouTube Transcript\",\n",
    "    description=(\n",
    "    \"Given a YouTube video url {url}, extract the full transcript. \"\n",
    "    \"This transcript will be cleaned and structured for downstream use.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "    \"A structured JSON object containing video title, URL, transcript segments, \"\n",
    "    \"and the concatenated full text.\"\n",
    "    ),\n",
    "    agent=extractor_agent,\n",
    "    inputs={\"video_url\": \"<YOUTUBE_VIDEO_URL>\"},\n",
    "    output_key=\"transcript_data\"\n",
    ")\n",
    "\n",
    "draft_blog_outline_task = Task(\n",
    "    name=\"Draft Blog Outline from Transcript\",\n",
    "    description=(\n",
    "    \"Analyze the transcript extracted from the YouTube video and generate \"\n",
    "    \"a detailed blog outline covering the main topics, subtopics, and takeaways.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "    \"A structured blog outline JSON with title, introduction, sections, \"\n",
    "    \"and conclusion ready for the writing agent.\"\n",
    "    ),\n",
    "    context=[extract_transcript_task],\n",
    "    agent=blog_outline_drafting_agent,\n",
    "    inputs={\"transcript_data\": \"{{ Extract YouTube Transcript.output }}\"},\n",
    "    output_key=\"blog_outline\"\n",
    ")\n",
    "\n",
    "write_blog_task = Task(\n",
    "    name=\"Write Complete Blog Article\",\n",
    "    description=(\n",
    "    \"Using the blog outline generated from the previous step, write a polished, \"\n",
    "    \"engaging, and human-like blog article with natural flow, examples, and insights.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "    \"A fully written blog article with title, introduction, main body sections, \"\n",
    "    \"and conclusion. The text should be publication-ready.\"\n",
    "    ),\n",
    "    context=[draft_blog_outline_task],\n",
    "    agent=blog_writer_agent,\n",
    "    inputs={\"blog_outline\": \"{{ Draft Blog Outline from Transcript.output }}\"},\n",
    "    output_key=\"final_blog\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444a001",
   "metadata": {},
   "source": [
    "### ðŸš€ Crew Assembly\n",
    "\n",
    "This cell creates the main crew that orchestrates the entire process:\n",
    "\n",
    "- **Name**: YouTube-to-Blog Conversion Crew\n",
    "- **Description**: Automates conversion of YouTube videos to blog posts\n",
    "- **Agents**: All three defined agents (extractor, outline drafter, writer)\n",
    "- **Tasks**: All three defined tasks in sequence\n",
    "- **Process**: Sequential execution\n",
    "- **Verbose**: True (shows detailed execution logs)\n",
    "\n",
    "The crew manages the workflow, ensuring tasks are executed in the correct order and agents receive the proper inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b28202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the crew to manage the three agents and their tasks\n",
    "blog_generation_crew = Crew(\n",
    "    name=\"YouTube-to-Blog Conversion Crew\",\n",
    "    description=(\n",
    "        \"This crew automates the process of converting a YouTube video into a complete blog post. \"\n",
    "        \"It works in three stages: extracting the transcript, drafting a structured blog outline, \"\n",
    "        \"and writing a polished, human-like blog article.\"\n",
    "    ),\n",
    "    agents=[\n",
    "        extractor_agent,\n",
    "        blog_outline_drafting_agent,\n",
    "        blog_writer_agent\n",
    "    ],\n",
    "    tasks=[\n",
    "        extract_transcript_task,\n",
    "        draft_blog_outline_task,\n",
    "        write_blog_task\n",
    "    ],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76670cd2",
   "metadata": {},
   "source": [
    "### â–¶ï¸ Crew Execution\n",
    "\n",
    "This cell runs the complete YouTube to blog conversion process:\n",
    "\n",
    "- **Input**: YouTube video URL (replace with your target URL)\n",
    "- **Process**: Kicks off the sequential crew workflow\n",
    "- **Result**: Stores the complete output including all intermediate steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74e85e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='```markdown\\n# Create Your Own LinkedIn Post Generator Agent with CrewAI\\n\\n## Introduction\\n\\nAre you tired of spending valuable time manually crafting LinkedIn posts? The process of creating engaging content, finding relevant hashtags, and scheduling posts can be incredibly time-consuming. In today\\'s fast-paced digital world, maintaining a consistent social media presence is crucial for professionals and businesses alike. But what if you could automate this process, saving time and significantly enhancing your LinkedIn presence?\\n\\nThis blog post provides a step-by-step guide on building a LinkedIn post generator agent using CrewAI. We\\'ll dive into the problem of manual LinkedIn posting, explore the benefits of an automated solution, and walk through the creation of an agent that can extract content from a blog post, summarize it, and generate a professional LinkedIn post ready to share. By the end of this tutorial, you\\'ll have the knowledge and tools to automate your social media efforts and focus on what matters most.\\n\\n## Why Automate LinkedIn Posts?\\n\\n### The Tedious Nature of Manual Posting\\n\\nManually creating LinkedIn posts involves several steps: finding relevant content, summarizing it, crafting an engaging message, selecting appropriate hashtags, and scheduling the post. This process, repeated multiple times a week, can quickly become tedious and drain valuable time that could be spent on other important tasks.\\n\\n### Need for Consistent Content in Marketing\\n\\nConsistency is key in social media marketing. Regular posting helps maintain audience engagement, build brand awareness, and drive traffic to your website or blog. However, the manual effort required to produce consistent content often leads to infrequent posting, hindering your social media effectiveness.\\n\\n### Benefits of an Automated Agent\\n\\nAn automated LinkedIn post generator offers several advantages:\\n\\n*   **Consistent and Engaging Presence:** Automate the creation of high-quality LinkedIn posts, ensuring a steady stream of content that keeps your audience engaged.\\n*   **Automated Marketing Tasks with AI:** Leverage the power of AI to streamline your marketing efforts, freeing up time for strategic planning and other important activities.\\n*   **Saving Time and Enhancing Social Media Effectiveness:** Automate the time-consuming process of content creation, allowing you to focus on other priorities while maintaining a strong social media presence.\\n\\n## How the LinkedIn Post Generator Works\\n\\n### Overview of the Process\\n\\nOur LinkedIn post generator will take a blog post URL as input and, through a series of automated steps, generate a ready-to-share LinkedIn post. Here\\'s a breakdown of the process:\\n\\n1.  **Input: Blog Post URL:** The user provides the URL of a blog post.\\n2.  **Extraction of Content from the Blog:** The agent extracts the main content from the blog post, removing unnecessary elements like navigation menus and advertisements.\\n3.  **Summarization of the Blog Content:** The extracted content is summarized to create a concise and engaging summary suitable for a LinkedIn post.\\n4.  **Creation of a Professional LinkedIn Post:** Based on the summary, a professional LinkedIn post is crafted, including relevant hashtags and a link back to the original blog post.\\n5.  **Ready to Share Output:** The generated LinkedIn post is presented, ready for the user to review and publish.\\n\\n## Code Demo: Building the Agent\\n\\nLet\\'s dive into the code and build our LinkedIn post generator agent using CrewAI.\\n\\n### Setting up the Environment\\n\\nFirst, ensure you have Python installed. Then, create a new project directory and install the necessary libraries using pip:\\n\\n```bash\\npip install gluei python-dotenv requests beautifulsoup4 crewai\\n```\\n\\n### Importing Libraries\\n\\nNow, let\\'s import the required libraries into our Python script:\\n\\n```python\\nimport os\\nfrom dotenv import load_dotenv\\nfrom crewai import Agent, Task, Crew, Process\\nfrom bs4 import BeautifulSoup\\nimport requests\\n```\\n\\n### Creating a Helper Function\\n\\nWe\\'ll create a helper function to fetch and extract the content from a blog post using `BeautifulSoup`:\\n\\n```python\\ndef fetch_blog_content(url):\\n    try:\\n        response = requests.get(url)\\n        response.raise_for_status()  # Raise an exception for bad status codes\\n        soup = BeautifulSoup(response.content, \\'html.parser\\')\\n        # Adjust these selectors based on the target website\\'s HTML structure\\n        article = soup.find(\\'article\\') or soup.find(\\'main\\')\\n        if article:\\n            return article.get_text(separator=\\'\\\\n\\', strip=True)\\n        else:\\n            return \"Could not extract content from the provided URL.\"\\n    except requests.exceptions.RequestException as e:\\n        return f\"Error fetching content: {e}\"\\n```\\n\\n### Defining Tools\\n\\nNext, we define our tools. In this case, our primary tool will be the function to fetch blog content:\\n\\n```python\\nfrom crewai.tools.tool import Tool\\n\\nfetch_content_tool = Tool(\\n    name=\"Fetch Blog Content\",\\n    description=\"Fetches and extracts the content from a given blog post URL.\",\\n    func=fetch_blog_content,\\n    args_schema={\\n        \"url\": {\\n            \"type\": \"string\",\\n            \"description\": \"The URL of the blog post.\",\\n        }\\n    }\\n)\\n```\\n\\n### LLM Configuration\\n\\nFor this example, we\\'ll use Gemini models. You\\'ll need to set up your API keys. Make sure your `GOOGLE_API_KEY` is set in your environment variables.\\n\\n```python\\nload_dotenv()\\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\\n```\\n\\n### Agent Creation\\n\\nNow, let\\'s create the agents. We\\'ll have two agents: one to extract and summarize content and another to write the LinkedIn post.\\n\\n```python\\nfrom langchain_google_genai import ChatGoogleGenerativeAI\\n\\n# Configure LLMs\\nllm_extraction = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.1)\\nllm_writing = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\\n\\n# Content Extractor Agent\\ncontent_extractor_agent = Agent(\\n    role=\\'Content Extractor\\',\\n    goal=\\'Extract and summarize content from blog posts.\\',\\n    backstory=\\'I am an expert at extracting the core content from any given blog post and preparing it for summarization.\\',\\n    tools=[fetch_content_tool],\\n    llm=llm_extraction,\\n    verbose=True\\n)\\n\\n# LinkedIn Post Writer Agent\\nlinkedin_post_writer_agent = Agent(\\n    role=\\'LinkedIn Post Writer\\',\\n    goal=\\'Write engaging and professional LinkedIn posts based on extracted content.\\',\\n    backstory=\\'I am a social media expert skilled in crafting compelling LinkedIn posts that capture attention and drive engagement.\\',\\n    llm=llm_writing,\\n    verbose=True\\n)\\n```\\n\\n### Task Definition\\n\\nDefine the tasks for each agent:\\n\\n```python\\n# Extract and Summarize Task\\nextract_and_summarize_task = Task(\\n    description=\\'Extract the content from the blog post at {url} and create a concise summary.\\',\\n    agent=content_extractor_agent,\\n    input={\"url\": \"https://www.example.com/blog-post\"}, # Replace with your blog post URL\\n    expected_output=\\'A concise summary of the blog post content.\\',\\n)\\n\\n# LinkedIn Post Writing Task\\nlinkedin_post_writing_task = Task(\\n    description=\\'Write a professional and engaging LinkedIn post based on the following summary: {summary}. Include relevant hashtags and a link to the original blog post. The post should be under 200 words and have a friendly tone.\\',\\n    agent=linkedin_post_writer_agent,\\n    expected_output=\\'A ready-to-share LinkedIn post.\\',\\n)\\n```\\n\\n### Pre-assembly: Creating the Pipeline (Sequential Process)\\n\\nFinally, create the crew and define the tasks.\\n\\n```python\\n# Assemble the Crew\\ncrew = Crew(\\n    agents=[content_extractor_agent, linkedin_post_writer_agent],\\n    tasks=[extract_and_summarize_task, linkedin_post_writing_task],\\n    process=Process.sequential,\\n    verbose=2, # Set verbose to 2 for detailed execution logs\\n)\\n```\\n\\n## Execution and Results\\n\\n### Providing a Blog URL as Input\\n\\nReplace `\"https://www.example.com/blog-post\"` in the `extract_and_summarize_task` with the actual URL of the blog post you want to use.\\n\\n### Running the Code\\n\\nRun the Python script. The agents will work sequentially, extracting the content, summarizing it, and generating the LinkedIn post.\\n\\n```python\\n# Run the crew to generate the LinkedIn Post\\nresult = crew.kickoff()\\nprint(\"\\\\nGenerated LinkedIn Post:\\\\n\", result)\\n```\\n\\n### Generated LinkedIn Post Example\\n\\nHere\\'s an example of the kind of LinkedIn post that might be generated:\\n\\n### Review of the Generated Post\\n\\nThe generated post will include a summary of the blog post\\'s main points, relevant hashtags, and a link back to the original blog post. Review the output to ensure it aligns with your brand\\'s voice and messaging.\\n\\n### Example Post Content\\n\\nHere\\'s an example of what the output might look like (This is only an example and will vary based on the blog post):\\n\\n```\\nExcited to share a breakdown of how to automate LinkedIn Posts using CrewAI! ðŸš€ This blog post dives into how to extract content from a blog, create summaries, and generate a professional LinkedIn post ready to share. Check it out and start saving time! #AI #LinkedInAutomation #CrewAI #SocialMediaMarketing [link to your blog post]\\n```\\n\\n### Hashtags and Blog Link\\n\\nThe generated post will include relevant hashtags to increase visibility and a link back to your blog post to drive traffic.\\n\\n## Enhancements and Next Steps\\n\\n### Adding an Agent for Automated Posting (Optional)\\n\\nYou could extend this project by adding an agent that interacts with the LinkedIn API to automatically post the generated content. However, this requires additional setup and API key configurations.\\n\\n### Human-in-the-Loop for Quality Control\\n\\nConsider implementing a human-in-the-loop system where a human reviews the generated post before it\\'s published. This ensures the content aligns with your brand\\'s voice and messaging.\\n\\n### Resources: GitHub Repository (Cookbooks, Examples)\\n\\nExplore the CrewAI GitHub repository for more examples and cookbooks to help you get started.\\n\\n### Link to the GitHub Repository\\n\\n[Link to CrewAI GitHub Repository](https://github.com/CrewAI/crewai)\\n\\n## Conclusion\\n\\nCongratulations! You\\'ve successfully created a LinkedIn post generator agent using CrewAI. This automated system can significantly reduce the time and effort required to maintain a consistent presence on LinkedIn. By following this tutorial, you\\'ve learned how to extract content, summarize it, and generate professional LinkedIn posts.\\n\\nWe encourage you to experiment with this project, explore the provided resources, and customize it to fit your specific needs. If you found this tutorial helpful, please like, share, and subscribe for more content on AI automation and social media marketing!\\n```', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Given a YouTube video url https://www.youtube.com/watch?v=lEXkHi3NYxo, extract the full transcript. This transcript will be cleaned and structured for downstream use.', name='Extract YouTube Transcript', expected_output='A structured JSON object containing video title, URL, transcript segments, and the concatenated full text.', summary='Given a YouTube video url https://www.youtube.com/watch?v=lEXkHi3NYxo, extract the full transcript....', raw='```json\\n{\\n  \"video_title\": \"Create Your Own LinkedIn Post Generator Agent | CrewAI Tutorial\",\\n  \"url\": \"https://www.youtube.com/watch?v=lEXkHi3NYxo\",\\n  \"transcript_segments\": [\\n    {\\n      \"start\": 0,\\n      \"text\": \"Hello everyone, welcome to this tutorial on creating your own agent.\"\\n    },\\n    {\\n      \"start\": 2,\\n      \"text\": \"So in this tutorial, I\\'m going to show you how you can build your own LinkedIn post generator agent.\"\\n    },\\n    {\\n      \"start\": 8,\\n      \"text\": \"So what is the requirement to build this agent?\"\\n    },\\n    {\\n      \"start\": 10,\\n      \"text\": \"First to create manual LinkedIn post is a waste of time.\"\\n    },\\n    {\\n      \"start\": 13,\\n      \"text\": \"It it is very tedious come and if you are in marketing you need a steady pipeline to create such po post on regular basis and like if you are creating blogs on everyday topics and you need to create post on that LinkedIn you have to write that manually and it will be a waste of time.\"\\n    },\\n    {\\n      \"start\": 31,\\n      \"text\": \"So you have to build something of an agent like that.\"\\n    },\\n    {\\n      \"start\": 35,\\n      \"text\": \"uh it also create a consistent and engaging pres presence across the media channel.\"\\n    },\\n    {\\n      \"start\": 40,\\n      \"text\": \"So if it\\'s uh agent it will be automated and it will uh generate post reg on regular basis.\"\\n    },\\n    {\\n      \"start\": 46,\\n      \"text\": \"So it will be a engaging presence across social media.\"\\n    },\\n    {\\n      \"start\": 50,\\n      \"text\": \"Then our it will automate our marketing task with AI.\"\\n    },\\n    {\\n      \"start\": 54,\\n      \"text\": \"And our last is to save our valuable time while enhancing social media effectiveness.\"\\n    },\\n    {\\n      \"start\": 60,\\n      \"text\": \"So that how it works just it is very easy to work like if you create a blog something like you just have to enter the blog post to initiate the process then the agent will extract all the detail in the URL URL like if I am targeting creating a blog post so you just have to provide it with the blog URL then agent will extract all the content contents of blog and summarizes it and then another agent will create a professional LinkedIn ready post which will be ready to share.\"\\n    },\\n    {\\n      \"start\": 90,\\n      \"text\": \"Let\\'s see our code demo.\"\\n    },\\n    {\\n      \"start\": 93,\\n      \"text\": \"So it\\'s time to see the code demo of our LinkedIn post generator agents.\"\\n    },\\n    {\\n      \"start\": 97,\\n      \"text\": \"This is the notebook I have created where you can see how you can create your own LinkedIn post generator agent using crew AI and multi- aent system.\"\\n    },\\n    {\\n      \"start\": 107,\\n      \"text\": \"Yes, this is a multi- aent cookbook.\"\\n    },\\n    {\\n      \"start\": 110,\\n      \"text\": \"So I\\'m going to use multiple agent for various task.\"\\n    },\\n    {\\n      \"start\": 114,\\n      \"text\": \"So let\\'s see our steps.\"\\n    },\\n    {\\n      \"start\": 117,\\n      \"text\": \"So our first step is the installation of some important libraries.\"\\n    },\\n    {\\n      \"start\": 121,\\n      \"text\": \"These are gluei port.env PNV request beautiful soup and Qi tools.\"\\n    },\\n    {\\n      \"start\": 127,\\n      \"text\": \"You just have to unccomment it and run this cell.\"\\n    },\\n    {\\n      \"start\": 130,\\n      \"text\": \"I\\'ve already installed this so I\\'m not going to run it again.\"\\n    },\\n    {\\n      \"start\": 134,\\n      \"text\": \"Now this is our part where we import our uh libraries.\"\\n    },\\n    {\\n      \"start\": 138,\\n      \"text\": \"So I am going to import OS env.\"\\n    },\\n    {\\n      \"start\": 141,\\n      \"text\": \"I have to import load environments from crewi.\"\\n    },\\n    {\\n      \"start\": 144,\\n      \"text\": \"I\\'m going to import agent task crew process and llm and then from crew dot tools I\\'m going to import tools then basic libraries like request and beautiful soap here using load dot environment you can uh extract the Germany API key from the env file which I have created here you have to store your API key in the gei key variable stove.\"\\n    },\\n    {\\n      \"start\": 169,\\n      \"text\": \"Now our next step is to create a helper function.\"\\n    },\\n    {\\n      \"start\": 172,\\n      \"text\": \"This is a simple helper helper function using beautiful soup which I have created to extract the content of our blog.\"\\n    },\\n    {\\n      \"start\": 179,\\n      \"text\": \"Like if you provide it with a URL, it will extract all the content related in written in the blog and return as a string format.\"\\n    },\\n    {\\n      \"start\": 187,\\n      \"text\": \"You can run it and test it.\"\\n    },\\n    {\\n      \"start\": 191,\\n      \"text\": \"So so as you can see it had extracted all the content of our blogs.\"\\n    },\\n    {\\n      \"start\": 196,\\n      \"text\": \"Uh I is just showing the top first 500 uh characters.\"\\n    },\\n    {\\n      \"start\": 200,\\n      \"text\": \"Now let\\'s get to our next part of crew a AI tool definition.\"\\n    },\\n    {\\n      \"start\": 204,\\n      \"text\": \"I\\'m just using this fetch block content as a tool in extract block content.\"\\n    },\\n    {\\n      \"start\": 209,\\n      \"text\": \"Just using fetch block containing the fetch block content URLs and providing with the decorator add tool blog content extractor.\"\\n    },\\n    {\\n      \"start\": 219,\\n      \"text\": \"Now our next part is the most important LLM configuration.\"\\n    },\\n    {\\n      \"start\": 223,\\n      \"text\": \"I\\'m going to going to use two LLMs.\"\\n    },\\n    {\\n      \"start\": 225,\\n      \"text\": \"First LLM to like Gemini 2.0 flashlight for extraction of uh these information into structural formats and then the post writer LLM.\"\\n    },\\n    {\\n      \"start\": 235,\\n      \"text\": \"I\\'m going to use a thinking model like Gemini 2.5 to write our uh LinkedIn post.\"\\n    },\\n    {\\n      \"start\": 241,\\n      \"text\": \"So here you can create two LLMs extracting LLMs and writing LLMs.\"\\n    },\\n    {\\n      \"start\": 247,\\n      \"text\": \"Then I\\'m going to create agents.\"\\n    },\\n    {\\n      \"start\": 249,\\n      \"text\": \"There are two agents also like content extractor agents.\"\\n    },\\n    {\\n      \"start\": 253,\\n      \"text\": \"Role is to summarize and extract key from blog posts.\"\\n    },\\n    {\\n      \"start\": 257,\\n      \"text\": \"And next one is the LinkedIn post writer agent as you can see.\"\\n    },\\n    {\\n      \"start\": 262,\\n      \"text\": \"So I provided the role goal and backstory and it with the tools like this extractor is going to use tool life extraction block contents and the LLM it going to use extracting LLM then the writer agents here is the role ro and backtory the LLM is the writing LLM which have which is using Gemini 2.5 now is our task there are two tasks Task also like first to extract and summarize core idea key point from the blog.\"\\n    },\\n    {\\n      \"start\": 288,\\n      \"text\": \"Here is the provided URL then the expected output like summary of the blogs key points supporting detail and the core message.\"\\n    },\\n    {\\n      \"start\": 298,\\n      \"text\": \"You can also add new points according to your uh requirements like uh if you want emoji in your LinkedIn post.\"\\n    },\\n    {\\n      \"start\": 307,\\n      \"text\": \"I have added here like use image emoji for points like this is the task of writing.\"\\n    },\\n    {\\n      \"start\": 314,\\n      \"text\": \"So it will it will use that information to write the LinkedIn post.\"\\n    },\\n    {\\n      \"start\": 319,\\n      \"text\": \"Write a polish creative LinkedIn post max 180 words based on provided blogs.\"\\n    },\\n    {\\n      \"start\": 325,\\n      \"text\": \"Use professional yet approachable tone.\"\\n    },\\n    {\\n      \"start\": 329,\\n      \"text\": \"So with this you can create your task.\"\\n    },\\n    {\\n      \"start\": 332,\\n      \"text\": \"Now our pre assembly time.\"\\n    },\\n    {\\n      \"start\": 334,\\n      \"text\": \"I have to create a pipeline where these both agent and these both task are used.\"\\n    },\\n    {\\n      \"start\": 339,\\n      \"text\": \"So here is the agent which I pro extractor agent writer agent and the task which is extract task and write task and process is sequential.\"\\n    },\\n    {\\n      \"start\": 349,\\n      \"text\": \"So this agent will do this task.\"\\n    },\\n    {\\n      \"start\": 351,\\n      \"text\": \"This agent will do this task.\"\\n    },\\n    {\\n      \"start\": 354,\\n      \"text\": \"Then let\\'s get to our execution part.\"\\n    },\\n    {\\n      \"start\": 357,\\n      \"text\": \"So this is the execution where I provided with a blog URL.\"\\n    },\\n    {\\n      \"start\": 361,\\n      \"text\": \"Here is the blog URL of our company product update of August 2025.\"\\n    },\\n    {\\n      \"start\": 366,\\n      \"text\": \"Let\\'s let\\'s create a LinkedIn post of that.\"\\n    },\\n    {\\n      \"start\": 370,\\n      \"text\": \"So let\\'s run the cell.\"\\n    },\\n    {\\n      \"start\": 372,\\n      \"text\": \"As you can see, it started LinkedIn post creator use and provided blog URL.\"\\n    },\\n    {\\n      \"start\": 378,\\n      \"text\": \"So now our post is created.\"\\n    },\\n    {\\n      \"start\": 381,\\n      \"text\": \"Here you can see it has created a LinkedIn post.\"\\n    },\\n    {\\n      \"start\": 384,\\n      \"text\": \"You can copy it from here.\"\\n    },\\n    {\\n      \"start\": 387,\\n      \"text\": \"So let\\'s see the post.\"\\n    },\\n    {\\n      \"start\": 389,\\n      \"text\": \"Is your video annotation workflow struggling with accuracy and efficiency?\"\\n    },\\n    {\\n      \"start\": 395,\\n      \"text\": \"We hear you.\"\\n    },\\n    {\\n      \"start\": 397,\\n      \"text\": \"Le is excited to unveil our latest platform up update.\"\\n    },\\n    {\\n      \"start\": 403,\\n      \"text\": \"Advancing precision and video annotation engineer to transfer your data labeling process.\"\\n    },\\n    {\\n      \"start\": 411,\\n      \"text\": \"This release de delivers unparalleled accuracy and efficiencies ensuring your training process is pristine.\"\\n    },\\n    {\\n      \"start\": 419,\\n      \"text\": \"So here are the points.\"\\n    },\\n    {\\n      \"start\": 421,\\n      \"text\": \"Here are the blog link you can insert or here are the hashtag of the related topic.\"\\n    },\\n    {\\n      \"start\": 429,\\n      \"text\": \"So that\\'s how you can create your own LinkedIn post uh generator agent.\"\\n    },\\n    {\\n      \"start\": 435,\\n      \"text\": \"You can also add another agent to post this uh data on your LinkedIn automatically.\"\\n    },\\n    {\\n      \"start\": 442,\\n      \"text\": \"But I want some human in the loop.\"\\n    },\\n    {\\n      \"start\": 446,\\n      \"text\": \"Uh so to check the quality of our LinkedIn post.\"\\n    },\\n    {\\n      \"start\": 450,\\n      \"text\": \"If you\\'d like to explore practical resources and hands-on examples, we\\'ve created a dedicated GitHub repository.\"\\n    },\\n    {\\n      \"start\": 458,\\n      \"text\": \"It\\'s filled with cookbooks covering computer vision, AI agents, and more.\"\\n    },\\n    {\\n      \"start\": 463,\\n      \"text\": \"Link is in description.\"\\n    },\\n    {\\n      \"start\": 467,\\n      \"text\": \"So that\\'s it for today\\'s video.\"\\n    },\\n    {\\n      \"start\": 470,\\n      \"text\": \"If you found this tutorial helpful, don\\'t forget to like, share, and subscribe for more content.\"\\n    },\\n    {\\n      \"start\": 477,\\n      \"text\": \"Thanks for watching.\"\\n    }\\n  ],\\n  \"full_text\": \"Hello everyone, welcome to this tutorial on creating your own agent. So in this tutorial, I\\'m going to show you how you can build your own LinkedIn post generator agent. So what is the requirement to build this agent? First to create manual LinkedIn post is a waste of time. It it is very tedious come and if you are in marketing you need a steady pipeline to create such po post on regular basis and like if you are creating blogs on everyday topics and you need to create post on that LinkedIn you have to write that manually and it will be a waste of time. So you have to build something of an agent like that. uh it also create a consistent and engaging pres presence across the media channel. So if it\\'s uh agent it will be automated and it will uh generate post reg on regular basis. So it will be a engaging presence across social media. Then our it will automate our marketing task with AI. And our last is to save our valuable time while enhancing social media effectiveness. So that how it works just it is very easy to work like if you create a blog something like you just have to enter the blog post to initiate the process then the agent will extract all the detail in the URL URL like if I am targeting creating a blog post so you just have to provide it with the blog URL then agent will extract all the content contents of blog and summarizes it and then another agent will create a professional LinkedIn ready post which will be ready to share. Let\\'s see our code demo. So it\\'s time to see the code demo of our LinkedIn post generator agents. This is the notebook I have created where you can see how you can create your own LinkedIn post generator agent using crew AI and multi- aent system. Yes, this is a multi- aent cookbook. So I\\'m going to use multiple agent for various task. So let\\'s see our steps. So our first step is the installation of some important libraries. These are gluei port.env PNV request beautiful soup and Qi tools. You just have to unccomment it and run this cell. I\\'ve already installed this so I\\'m not going to run it again. Now this is our part where we import our uh libraries. So I am going to import OS env. I have to import load environments from crewi. I\\'m going to import agent task crew process and llm and then from crew dot tools I\\'m going to import tools then basic libraries like request and beautiful soap here using load dot environment you can uh extract the Germany API key from the env file which I have created here you have to store your API key in the gei key variable stove. Now our next step is to create a helper function. This is a simple helper helper function using beautiful soup which I have created to extract the content of our blog. Like if you provide it with a URL, it will extract all the content related in written in the blog and return as a string format. You can run it and test it. So so as you can see it had extracted all the content of our blogs. Uh I is just showing the top first 500 uh characters. Now let\\'s get to our next part of crew a AI tool definition. I\\'m just using this fetch block content as a tool in extract block content. Just using fetch block containing the fetch block content URLs and providing with the decorator add tool blog content extractor. Now our next part is the most important LLM configuration. I\\'m going to going to use two LLMs. First LLM to like Gemini 2.0 flashlight for extraction of uh these information into structural formats and then the post writer LLM. I\\'m going to use a thinking model like Gemini 2.5 to write our uh LinkedIn post. So here you can create two LLMs extracting LLMs and writing LLMs. Then I\\'m going to create agents. There are two agents also like content extractor agents. Role is to summarize and extract key from blog posts. And next one is the LinkedIn post writer agent as you can see. So I provided the role goal and backstory and it with the tools like this extractor is going to use tool life extraction block contents and the LLM it going to use extracting LLM then the writer agents here is the role ro and backtory the LLM is the writing LLM which have which is using Gemini 2.5 now is our task there are two tasks Task also like first to extract and summarize core idea key point from the blog. Here is the provided URL then the expected output like summary of the blogs key points supporting detail and the core message. You can also add new points according to your uh requirements like uh if you want emoji in your LinkedIn post. I have added here like use image emoji for points like this is the task of writing. So it will it will use that information to write the LinkedIn post. Write a polish creative LinkedIn post max 180 words based on provided blogs. Use professional yet approachable tone. So with this you can create your task. Now our pre assembly time. I have to create a pipeline where these both agent and these both task are used. So here is the agent which I pro extractor agent writer agent and the task which is extract task and write task and process is sequential. So this agent will do this task. This agent will do this task. Then let\\'s get to our execution part. So this is the execution where I provided with a blog URL. Here is the blog URL of our company product update of August 2025. Let\\'s let\\'s create a LinkedIn post of that. So let\\'s run the cell. As you can see, it started LinkedIn post creator use and provided blog URL. So now our post is created. Here you can see it has created a LinkedIn post. You can copy it from here. So let\\'s see the post. Is your video annotation workflow struggling with accuracy and efficiency? We hear you. Le is excited to unveil our latest platform up update. Advancing precision and video annotation engineer to transfer your data labeling process. This release de delivers unparalleled accuracy and efficiencies ensuring your training process is pristine. So here are the points. Here are the blog link you can insert or here are the hashtag of the related topic. So that\\'s how you can create your own LinkedIn post uh generator agent. You can also add another agent to post this uh data on your LinkedIn automatically. But I want some human in the loop. Uh so to check the quality of our LinkedIn post. If you\\'d like to explore practical resources and hands-on examples, we\\'ve created a dedicated GitHub repository. It\\'s filled with cookbooks covering computer vision, AI agents, and more. Link is in description. So that\\'s it for today\\'s video. If you found this tutorial helpful, don\\'t forget to like, share, and subscribe for more content. Thanks for watching.\"\\n}\\n```', pydantic=None, json_dict=None, agent='youtube_transcript_extractor_agent', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description='Analyze the transcript extracted from the YouTube video and generate a detailed blog outline covering the main topics, subtopics, and takeaways.', name='Draft Blog Outline from Transcript', expected_output='A structured blog outline JSON with title, introduction, sections, and conclusion ready for the writing agent.', summary='Analyze the transcript extracted from the YouTube video and generate...', raw='```json\\n{\\n  \"title\": \"Create Your Own LinkedIn Post Generator Agent with CrewAI\",\\n  \"introduction\": {\\n    \"summary\": \"This blog post provides a step-by-step guide on building a LinkedIn post generator agent using CrewAI. It addresses the time-consuming nature of manual LinkedIn posting and demonstrates how to automate the process, saving time and enhancing social media presence.\",\\n    \"key_points\": [\\n      \"The problem of manual LinkedIn posting.\",\\n      \"Benefits of an automated LinkedIn post generator.\",\\n      \"Overview of the tutorial and its objectives.\"\\n    ]\\n  },\\n  \"sections\": [\\n    {\\n      \"title\": \"Why Automate LinkedIn Posts?\",\\n      \"subtopics\": [\\n        \"The Tedious Nature of Manual Posting\",\\n        \"Need for Consistent Content in Marketing\",\\n        \"Benefits of an Automated Agent\",\\n        \"Consistent and Engaging Presence\",\\n        \"Automated Marketing Tasks with AI\",\\n        \"Saving Time and Enhancing Social Media Effectiveness\"\\n      ]\\n    },\\n    {\\n      \"title\": \"How the LinkedIn Post Generator Works\",\\n      \"subtopics\": [\\n        \"Overview of the Process\",\\n        \"Input: Blog Post URL\",\\n        \"Extraction of Content from the Blog\",\\n        \"Summarization of the Blog Content\",\\n        \"Creation of a Professional LinkedIn Post\",\\n        \"Ready to Share Output\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Code Demo: Building the Agent\",\\n      \"subtopics\": [\\n        \"Setting up the Environment\",\\n        \"Installation of Required Libraries (gluei, python-dotenv, requests, beautifulsoup4, crewai)\",\\n        \"Importing Libraries (OS, load_dotenv, crewai modules)\",\\n        \"Creating a Helper Function (using BeautifulSoup to extract blog content)\",\\n        \"Defining Tools (Fetch Blog Content)\",\\n        \"LLM Configuration\",\\n        \"Using Gemini 2.0 for Extraction\",\\n        \"Using Gemini 2.5 for Writing\",\\n        \"Agent Creation\",\\n        \"Content Extractor Agent (Role, Goal, Tools)\",\\n        \"LinkedIn Post Writer Agent (Role, Goal, Tools)\",\\n        \"Task Definition\",\\n        \"Extract and Summarize Task (Input, Expected Output)\",\\n        \"LinkedIn Post Writing Task (Instructions, Word Limit, Tone)\",\\n        \"Pre-assembly: Creating the Pipeline (Sequential Process)\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Execution and Results\",\\n      \"subtopics\": [\\n        \"Providing a Blog URL as Input\",\\n        \"Running the Code\",\\n        \"Generated LinkedIn Post Example\",\\n        \"Review of the Generated Post\",\\n        \"Example Post Content\",\\n        \"Hashtags and Blog Link\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Enhancements and Next Steps\",\\n      \"subtopics\": [\\n        \"Adding an Agent for Automated Posting (Optional)\",\\n        \"Human-in-the-Loop for Quality Control\",\\n        \"Resources: GitHub Repository (Cookbooks, Examples)\",\\n        \"Link to the GitHub Repository\"\\n      ]\\n    }\\n  ],\\n  \"conclusion\": {\\n    \"summary\": \"Recap of the tutorial and its benefits. Encouragement to experiment and explore further. Call to action to like, share, and subscribe.\",\\n    \"key_points\": [\\n      \"Summary of the LinkedIn post generator creation process.\",\\n      \"Encouragement to explore the provided resources.\",\\n      \"Call to action: Like, share, and subscribe.\"\\n    ]\\n  }\\n}\\n```', pydantic=None, json_dict=None, agent='blog_outline_drafting_agent', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description='Using the blog outline generated from the previous step, write a polished, engaging, and human-like blog article with natural flow, examples, and insights.', name='Write Complete Blog Article', expected_output='A fully written blog article with title, introduction, main body sections, and conclusion. The text should be publication-ready.', summary='Using the blog outline generated from the previous step, write...', raw='```markdown\\n# Create Your Own LinkedIn Post Generator Agent with CrewAI\\n\\n## Introduction\\n\\nAre you tired of spending valuable time manually crafting LinkedIn posts? The process of creating engaging content, finding relevant hashtags, and scheduling posts can be incredibly time-consuming. In today\\'s fast-paced digital world, maintaining a consistent social media presence is crucial for professionals and businesses alike. But what if you could automate this process, saving time and significantly enhancing your LinkedIn presence?\\n\\nThis blog post provides a step-by-step guide on building a LinkedIn post generator agent using CrewAI. We\\'ll dive into the problem of manual LinkedIn posting, explore the benefits of an automated solution, and walk through the creation of an agent that can extract content from a blog post, summarize it, and generate a professional LinkedIn post ready to share. By the end of this tutorial, you\\'ll have the knowledge and tools to automate your social media efforts and focus on what matters most.\\n\\n## Why Automate LinkedIn Posts?\\n\\n### The Tedious Nature of Manual Posting\\n\\nManually creating LinkedIn posts involves several steps: finding relevant content, summarizing it, crafting an engaging message, selecting appropriate hashtags, and scheduling the post. This process, repeated multiple times a week, can quickly become tedious and drain valuable time that could be spent on other important tasks.\\n\\n### Need for Consistent Content in Marketing\\n\\nConsistency is key in social media marketing. Regular posting helps maintain audience engagement, build brand awareness, and drive traffic to your website or blog. However, the manual effort required to produce consistent content often leads to infrequent posting, hindering your social media effectiveness.\\n\\n### Benefits of an Automated Agent\\n\\nAn automated LinkedIn post generator offers several advantages:\\n\\n*   **Consistent and Engaging Presence:** Automate the creation of high-quality LinkedIn posts, ensuring a steady stream of content that keeps your audience engaged.\\n*   **Automated Marketing Tasks with AI:** Leverage the power of AI to streamline your marketing efforts, freeing up time for strategic planning and other important activities.\\n*   **Saving Time and Enhancing Social Media Effectiveness:** Automate the time-consuming process of content creation, allowing you to focus on other priorities while maintaining a strong social media presence.\\n\\n## How the LinkedIn Post Generator Works\\n\\n### Overview of the Process\\n\\nOur LinkedIn post generator will take a blog post URL as input and, through a series of automated steps, generate a ready-to-share LinkedIn post. Here\\'s a breakdown of the process:\\n\\n1.  **Input: Blog Post URL:** The user provides the URL of a blog post.\\n2.  **Extraction of Content from the Blog:** The agent extracts the main content from the blog post, removing unnecessary elements like navigation menus and advertisements.\\n3.  **Summarization of the Blog Content:** The extracted content is summarized to create a concise and engaging summary suitable for a LinkedIn post.\\n4.  **Creation of a Professional LinkedIn Post:** Based on the summary, a professional LinkedIn post is crafted, including relevant hashtags and a link back to the original blog post.\\n5.  **Ready to Share Output:** The generated LinkedIn post is presented, ready for the user to review and publish.\\n\\n## Code Demo: Building the Agent\\n\\nLet\\'s dive into the code and build our LinkedIn post generator agent using CrewAI.\\n\\n### Setting up the Environment\\n\\nFirst, ensure you have Python installed. Then, create a new project directory and install the necessary libraries using pip:\\n\\n```bash\\npip install gluei python-dotenv requests beautifulsoup4 crewai\\n```\\n\\n### Importing Libraries\\n\\nNow, let\\'s import the required libraries into our Python script:\\n\\n```python\\nimport os\\nfrom dotenv import load_dotenv\\nfrom crewai import Agent, Task, Crew, Process\\nfrom bs4 import BeautifulSoup\\nimport requests\\n```\\n\\n### Creating a Helper Function\\n\\nWe\\'ll create a helper function to fetch and extract the content from a blog post using `BeautifulSoup`:\\n\\n```python\\ndef fetch_blog_content(url):\\n    try:\\n        response = requests.get(url)\\n        response.raise_for_status()  # Raise an exception for bad status codes\\n        soup = BeautifulSoup(response.content, \\'html.parser\\')\\n        # Adjust these selectors based on the target website\\'s HTML structure\\n        article = soup.find(\\'article\\') or soup.find(\\'main\\')\\n        if article:\\n            return article.get_text(separator=\\'\\\\n\\', strip=True)\\n        else:\\n            return \"Could not extract content from the provided URL.\"\\n    except requests.exceptions.RequestException as e:\\n        return f\"Error fetching content: {e}\"\\n```\\n\\n### Defining Tools\\n\\nNext, we define our tools. In this case, our primary tool will be the function to fetch blog content:\\n\\n```python\\nfrom crewai.tools.tool import Tool\\n\\nfetch_content_tool = Tool(\\n    name=\"Fetch Blog Content\",\\n    description=\"Fetches and extracts the content from a given blog post URL.\",\\n    func=fetch_blog_content,\\n    args_schema={\\n        \"url\": {\\n            \"type\": \"string\",\\n            \"description\": \"The URL of the blog post.\",\\n        }\\n    }\\n)\\n```\\n\\n### LLM Configuration\\n\\nFor this example, we\\'ll use Gemini models. You\\'ll need to set up your API keys. Make sure your `GOOGLE_API_KEY` is set in your environment variables.\\n\\n```python\\nload_dotenv()\\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\\n```\\n\\n### Agent Creation\\n\\nNow, let\\'s create the agents. We\\'ll have two agents: one to extract and summarize content and another to write the LinkedIn post.\\n\\n```python\\nfrom langchain_google_genai import ChatGoogleGenerativeAI\\n\\n# Configure LLMs\\nllm_extraction = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.1)\\nllm_writing = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\\n\\n# Content Extractor Agent\\ncontent_extractor_agent = Agent(\\n    role=\\'Content Extractor\\',\\n    goal=\\'Extract and summarize content from blog posts.\\',\\n    backstory=\\'I am an expert at extracting the core content from any given blog post and preparing it for summarization.\\',\\n    tools=[fetch_content_tool],\\n    llm=llm_extraction,\\n    verbose=True\\n)\\n\\n# LinkedIn Post Writer Agent\\nlinkedin_post_writer_agent = Agent(\\n    role=\\'LinkedIn Post Writer\\',\\n    goal=\\'Write engaging and professional LinkedIn posts based on extracted content.\\',\\n    backstory=\\'I am a social media expert skilled in crafting compelling LinkedIn posts that capture attention and drive engagement.\\',\\n    llm=llm_writing,\\n    verbose=True\\n)\\n```\\n\\n### Task Definition\\n\\nDefine the tasks for each agent:\\n\\n```python\\n# Extract and Summarize Task\\nextract_and_summarize_task = Task(\\n    description=\\'Extract the content from the blog post at {url} and create a concise summary.\\',\\n    agent=content_extractor_agent,\\n    input={\"url\": \"https://www.example.com/blog-post\"}, # Replace with your blog post URL\\n    expected_output=\\'A concise summary of the blog post content.\\',\\n)\\n\\n# LinkedIn Post Writing Task\\nlinkedin_post_writing_task = Task(\\n    description=\\'Write a professional and engaging LinkedIn post based on the following summary: {summary}. Include relevant hashtags and a link to the original blog post. The post should be under 200 words and have a friendly tone.\\',\\n    agent=linkedin_post_writer_agent,\\n    expected_output=\\'A ready-to-share LinkedIn post.\\',\\n)\\n```\\n\\n### Pre-assembly: Creating the Pipeline (Sequential Process)\\n\\nFinally, create the crew and define the tasks.\\n\\n```python\\n# Assemble the Crew\\ncrew = Crew(\\n    agents=[content_extractor_agent, linkedin_post_writer_agent],\\n    tasks=[extract_and_summarize_task, linkedin_post_writing_task],\\n    process=Process.sequential,\\n    verbose=2, # Set verbose to 2 for detailed execution logs\\n)\\n```\\n\\n## Execution and Results\\n\\n### Providing a Blog URL as Input\\n\\nReplace `\"https://www.example.com/blog-post\"` in the `extract_and_summarize_task` with the actual URL of the blog post you want to use.\\n\\n### Running the Code\\n\\nRun the Python script. The agents will work sequentially, extracting the content, summarizing it, and generating the LinkedIn post.\\n\\n```python\\n# Run the crew to generate the LinkedIn Post\\nresult = crew.kickoff()\\nprint(\"\\\\nGenerated LinkedIn Post:\\\\n\", result)\\n```\\n\\n### Generated LinkedIn Post Example\\n\\nHere\\'s an example of the kind of LinkedIn post that might be generated:\\n\\n### Review of the Generated Post\\n\\nThe generated post will include a summary of the blog post\\'s main points, relevant hashtags, and a link back to the original blog post. Review the output to ensure it aligns with your brand\\'s voice and messaging.\\n\\n### Example Post Content\\n\\nHere\\'s an example of what the output might look like (This is only an example and will vary based on the blog post):\\n\\n```\\nExcited to share a breakdown of how to automate LinkedIn Posts using CrewAI! ðŸš€ This blog post dives into how to extract content from a blog, create summaries, and generate a professional LinkedIn post ready to share. Check it out and start saving time! #AI #LinkedInAutomation #CrewAI #SocialMediaMarketing [link to your blog post]\\n```\\n\\n### Hashtags and Blog Link\\n\\nThe generated post will include relevant hashtags to increase visibility and a link back to your blog post to drive traffic.\\n\\n## Enhancements and Next Steps\\n\\n### Adding an Agent for Automated Posting (Optional)\\n\\nYou could extend this project by adding an agent that interacts with the LinkedIn API to automatically post the generated content. However, this requires additional setup and API key configurations.\\n\\n### Human-in-the-Loop for Quality Control\\n\\nConsider implementing a human-in-the-loop system where a human reviews the generated post before it\\'s published. This ensures the content aligns with your brand\\'s voice and messaging.\\n\\n### Resources: GitHub Repository (Cookbooks, Examples)\\n\\nExplore the CrewAI GitHub repository for more examples and cookbooks to help you get started.\\n\\n### Link to the GitHub Repository\\n\\n[Link to CrewAI GitHub Repository](https://github.com/CrewAI/crewai)\\n\\n## Conclusion\\n\\nCongratulations! You\\'ve successfully created a LinkedIn post generator agent using CrewAI. This automated system can significantly reduce the time and effort required to maintain a consistent presence on LinkedIn. By following this tutorial, you\\'ve learned how to extract content, summarize it, and generate professional LinkedIn posts.\\n\\nWe encourage you to experiment with this project, explore the provided resources, and customize it to fit your specific needs. If you found this tutorial helpful, please like, share, and subscribe for more content on AI automation and social media marketing!\\n```', pydantic=None, json_dict=None, agent='blog_writer_agent', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=16941, prompt_tokens=8760, cached_prompt_tokens=0, completion_tokens=8181, successful_requests=4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace with your actual YouTube URL when running\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=lEXkHi3NYxo\"\n",
    "\n",
    "result = blog_generation_crew.kickoff(\n",
    "    inputs={\"url\": url}\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcfcfa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "# Create Your Own LinkedIn Post Generator Agent with CrewAI\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Are you tired of spending valuable time manually crafting LinkedIn posts? The process of creating engaging content, finding relevant hashtags, and scheduling posts can be incredibly time-consuming. In today's fast-paced digital world, maintaining a consistent social media presence is crucial for professionals and businesses alike. But what if you could automate this process, saving time and significantly enhancing your LinkedIn presence?\n",
      "\n",
      "This blog post provides a step-by-step guide on building a LinkedIn post generator agent using CrewAI. We'll dive into the problem of manual LinkedIn posting, explore the benefits of an automated solution, and walk through the creation of an agent that can extract content from a blog post, summarize it, and generate a professional LinkedIn post ready to share. By the end of this tutorial, you'll have the knowledge and tools to automate your social media efforts and focus on what matters most.\n",
      "\n",
      "## Why Automate LinkedIn Posts?\n",
      "\n",
      "### The Tedious Nature of Manual Posting\n",
      "\n",
      "Manually creating LinkedIn posts involves several steps: finding relevant content, summarizing it, crafting an engaging message, selecting appropriate hashtags, and scheduling the post. This process, repeated multiple times a week, can quickly become tedious and drain valuable time that could be spent on other important tasks.\n",
      "\n",
      "### Need for Consistent Content in Marketing\n",
      "\n",
      "Consistency is key in social media marketing. Regular posting helps maintain audience engagement, build brand awareness, and drive traffic to your website or blog. However, the manual effort required to produce consistent content often leads to infrequent posting, hindering your social media effectiveness.\n",
      "\n",
      "### Benefits of an Automated Agent\n",
      "\n",
      "An automated LinkedIn post generator offers several advantages:\n",
      "\n",
      "*   **Consistent and Engaging Presence:** Automate the creation of high-quality LinkedIn posts, ensuring a steady stream of content that keeps your audience engaged.\n",
      "*   **Automated Marketing Tasks with AI:** Leverage the power of AI to streamline your marketing efforts, freeing up time for strategic planning and other important activities.\n",
      "*   **Saving Time and Enhancing Social Media Effectiveness:** Automate the time-consuming process of content creation, allowing you to focus on other priorities while maintaining a strong social media presence.\n",
      "\n",
      "## How the LinkedIn Post Generator Works\n",
      "\n",
      "### Overview of the Process\n",
      "\n",
      "Our LinkedIn post generator will take a blog post URL as input and, through a series of automated steps, generate a ready-to-share LinkedIn post. Here's a breakdown of the process:\n",
      "\n",
      "1.  **Input: Blog Post URL:** The user provides the URL of a blog post.\n",
      "2.  **Extraction of Content from the Blog:** The agent extracts the main content from the blog post, removing unnecessary elements like navigation menus and advertisements.\n",
      "3.  **Summarization of the Blog Content:** The extracted content is summarized to create a concise and engaging summary suitable for a LinkedIn post.\n",
      "4.  **Creation of a Professional LinkedIn Post:** Based on the summary, a professional LinkedIn post is crafted, including relevant hashtags and a link back to the original blog post.\n",
      "5.  **Ready to Share Output:** The generated LinkedIn post is presented, ready for the user to review and publish.\n",
      "\n",
      "## Code Demo: Building the Agent\n",
      "\n",
      "Let's dive into the code and build our LinkedIn post generator agent using CrewAI.\n",
      "\n",
      "### Setting up the Environment\n",
      "\n",
      "First, ensure you have Python installed. Then, create a new project directory and install the necessary libraries using pip:\n",
      "\n",
      "```bash\n",
      "pip install gluei python-dotenv requests beautifulsoup4 crewai\n",
      "```\n",
      "\n",
      "### Importing Libraries\n",
      "\n",
      "Now, let's import the required libraries into our Python script:\n",
      "\n",
      "```python\n",
      "import os\n",
      "from dotenv import load_dotenv\n",
      "from crewai import Agent, Task, Crew, Process\n",
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "```\n",
      "\n",
      "### Creating a Helper Function\n",
      "\n",
      "We'll create a helper function to fetch and extract the content from a blog post using `BeautifulSoup`:\n",
      "\n",
      "```python\n",
      "def fetch_blog_content(url):\n",
      "    try:\n",
      "        response = requests.get(url)\n",
      "        response.raise_for_status()  # Raise an exception for bad status codes\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "        # Adjust these selectors based on the target website's HTML structure\n",
      "        article = soup.find('article') or soup.find('main')\n",
      "        if article:\n",
      "            return article.get_text(separator='\\n', strip=True)\n",
      "        else:\n",
      "            return \"Could not extract content from the provided URL.\"\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        return f\"Error fetching content: {e}\"\n",
      "```\n",
      "\n",
      "### Defining Tools\n",
      "\n",
      "Next, we define our tools. In this case, our primary tool will be the function to fetch blog content:\n",
      "\n",
      "```python\n",
      "from crewai.tools.tool import Tool\n",
      "\n",
      "fetch_content_tool = Tool(\n",
      "    name=\"Fetch Blog Content\",\n",
      "    description=\"Fetches and extracts the content from a given blog post URL.\",\n",
      "    func=fetch_blog_content,\n",
      "    args_schema={\n",
      "        \"url\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The URL of the blog post.\",\n",
      "        }\n",
      "    }\n",
      ")\n",
      "```\n",
      "\n",
      "### LLM Configuration\n",
      "\n",
      "For this example, we'll use Gemini models. You'll need to set up your API keys. Make sure your `GOOGLE_API_KEY` is set in your environment variables.\n",
      "\n",
      "```python\n",
      "load_dotenv()\n",
      "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
      "```\n",
      "\n",
      "### Agent Creation\n",
      "\n",
      "Now, let's create the agents. We'll have two agents: one to extract and summarize content and another to write the LinkedIn post.\n",
      "\n",
      "```python\n",
      "from langchain_google_genai import ChatGoogleGenerativeAI\n",
      "\n",
      "# Configure LLMs\n",
      "llm_extraction = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.1)\n",
      "llm_writing = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\n",
      "\n",
      "# Content Extractor Agent\n",
      "content_extractor_agent = Agent(\n",
      "    role='Content Extractor',\n",
      "    goal='Extract and summarize content from blog posts.',\n",
      "    backstory='I am an expert at extracting the core content from any given blog post and preparing it for summarization.',\n",
      "    tools=[fetch_content_tool],\n",
      "    llm=llm_extraction,\n",
      "    verbose=True\n",
      ")\n",
      "\n",
      "# LinkedIn Post Writer Agent\n",
      "linkedin_post_writer_agent = Agent(\n",
      "    role='LinkedIn Post Writer',\n",
      "    goal='Write engaging and professional LinkedIn posts based on extracted content.',\n",
      "    backstory='I am a social media expert skilled in crafting compelling LinkedIn posts that capture attention and drive engagement.',\n",
      "    llm=llm_writing,\n",
      "    verbose=True\n",
      ")\n",
      "```\n",
      "\n",
      "### Task Definition\n",
      "\n",
      "Define the tasks for each agent:\n",
      "\n",
      "```python\n",
      "# Extract and Summarize Task\n",
      "extract_and_summarize_task = Task(\n",
      "    description='Extract the content from the blog post at {url} and create a concise summary.',\n",
      "    agent=content_extractor_agent,\n",
      "    input={\"url\": \"https://www.example.com/blog-post\"}, # Replace with your blog post URL\n",
      "    expected_output='A concise summary of the blog post content.',\n",
      ")\n",
      "\n",
      "# LinkedIn Post Writing Task\n",
      "linkedin_post_writing_task = Task(\n",
      "    description='Write a professional and engaging LinkedIn post based on the following summary: {summary}. Include relevant hashtags and a link to the original blog post. The post should be under 200 words and have a friendly tone.',\n",
      "    agent=linkedin_post_writer_agent,\n",
      "    expected_output='A ready-to-share LinkedIn post.',\n",
      ")\n",
      "```\n",
      "\n",
      "### Pre-assembly: Creating the Pipeline (Sequential Process)\n",
      "\n",
      "Finally, create the crew and define the tasks.\n",
      "\n",
      "```python\n",
      "# Assemble the Crew\n",
      "crew = Crew(\n",
      "    agents=[content_extractor_agent, linkedin_post_writer_agent],\n",
      "    tasks=[extract_and_summarize_task, linkedin_post_writing_task],\n",
      "    process=Process.sequential,\n",
      "    verbose=2, # Set verbose to 2 for detailed execution logs\n",
      ")\n",
      "```\n",
      "\n",
      "## Execution and Results\n",
      "\n",
      "### Providing a Blog URL as Input\n",
      "\n",
      "Replace `\"https://www.example.com/blog-post\"` in the `extract_and_summarize_task` with the actual URL of the blog post you want to use.\n",
      "\n",
      "### Running the Code\n",
      "\n",
      "Run the Python script. The agents will work sequentially, extracting the content, summarizing it, and generating the LinkedIn post.\n",
      "\n",
      "```python\n",
      "# Run the crew to generate the LinkedIn Post\n",
      "result = crew.kickoff()\n",
      "print(\"\\nGenerated LinkedIn Post:\\n\", result)\n",
      "```\n",
      "\n",
      "### Generated LinkedIn Post Example\n",
      "\n",
      "Here's an example of the kind of LinkedIn post that might be generated:\n",
      "\n",
      "### Review of the Generated Post\n",
      "\n",
      "The generated post will include a summary of the blog post's main points, relevant hashtags, and a link back to the original blog post. Review the output to ensure it aligns with your brand's voice and messaging.\n",
      "\n",
      "### Example Post Content\n",
      "\n",
      "Here's an example of what the output might look like (This is only an example and will vary based on the blog post):\n",
      "\n",
      "```\n",
      "Excited to share a breakdown of how to automate LinkedIn Posts using CrewAI! ðŸš€ This blog post dives into how to extract content from a blog, create summaries, and generate a professional LinkedIn post ready to share. Check it out and start saving time! #AI #LinkedInAutomation #CrewAI #SocialMediaMarketing [link to your blog post]\n",
      "```\n",
      "\n",
      "### Hashtags and Blog Link\n",
      "\n",
      "The generated post will include relevant hashtags to increase visibility and a link back to your blog post to drive traffic.\n",
      "\n",
      "## Enhancements and Next Steps\n",
      "\n",
      "### Adding an Agent for Automated Posting (Optional)\n",
      "\n",
      "You could extend this project by adding an agent that interacts with the LinkedIn API to automatically post the generated content. However, this requires additional setup and API key configurations.\n",
      "\n",
      "### Human-in-the-Loop for Quality Control\n",
      "\n",
      "Consider implementing a human-in-the-loop system where a human reviews the generated post before it's published. This ensures the content aligns with your brand's voice and messaging.\n",
      "\n",
      "### Resources: GitHub Repository (Cookbooks, Examples)\n",
      "\n",
      "Explore the CrewAI GitHub repository for more examples and cookbooks to help you get started.\n",
      "\n",
      "### Link to the GitHub Repository\n",
      "\n",
      "[Link to CrewAI GitHub Repository](https://github.com/CrewAI/crewai)\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Congratulations! You've successfully created a LinkedIn post generator agent using CrewAI. This automated system can significantly reduce the time and effort required to maintain a consistent presence on LinkedIn. By following this tutorial, you've learned how to extract content, summarize it, and generate professional LinkedIn posts.\n",
      "\n",
      "We encourage you to experiment with this project, explore the provided resources, and customize it to fit your specific needs. If you found this tutorial helpful, please like, share, and subscribe for more content on AI automation and social media marketing!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Access outputs\n",
    "print(result.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630b6e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Blog saved successfully at: generated_blog_2025-10-27_14-31-43.md\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create a timestamped filename\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_path = f\"generated_blog_{timestamp}.md\"\n",
    "\n",
    "# Write the blog content to a Markdown file\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result.raw)\n",
    "\n",
    "print(f\"âœ… Blog saved successfully at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99546cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
