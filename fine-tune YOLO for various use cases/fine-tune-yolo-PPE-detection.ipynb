{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fine-Tune YOLO to Detect Personal Protective Equipment (PPE) Compliance**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate your Custom dataset using Labellerr\n",
    "\n",
    " ***1. Visit the [Labellerr](https://www.labellerr.com/?utm_source=githubY&utm_medium=social&utm_campaign=github_clicks) website and click **‚ÄúSign Up‚Äù**.*** \n",
    "\n",
    " ***2. After signing in, create your workspace by entering a unique name.***\n",
    "\n",
    " ***3. Navigate to your workspace‚Äôs API keys page (e.g., `https://<your-workspace>.labellerr.com/workspace/api-keys`) to generate your **API Key** and **API Secret**.***\n",
    "\n",
    " ***4. Store the credentials securely, and then use them to initialise the SDK or API client with `api_key`, `api_secret`.*** \n",
    "\n",
    "\n",
    "### Use Labellerr SDK for uploading and perform annotation of your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to install required packages in a Jupyter notebook environment\n",
    "\n",
    "# !pip install git+https://github.com/Labellerr/SDKPython.git\n",
    "# !pip install ipyfilechooser\n",
    "# !git clone https://github.com/Labellerr/yolo_finetune_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports required for this notebook\n",
    "from labellerr.client import LabellerrClient\n",
    "from labellerr.core.datasets import create_dataset_from_local\n",
    "from labellerr.core.annotation_templates import create_template\n",
    "from labellerr.core.projects import create_project\n",
    "from labellerr.core.schemas import DatasetConfig, AnnotationQuestion, QuestionType, CreateTemplateParams, DatasetDataType, CreateProjectParams, RotationConfig\n",
    "from labellerr.core.projects import LabellerrProject\n",
    "from labellerr.core.exceptions import LabellerrError\n",
    "\n",
    "import uuid\n",
    "from ipyfilechooser import FileChooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = input(\"YOUR_API_KEY\")        # go to labellerr workspace to get your API key\n",
    "api_secret = input(\"YOUR_API_SECRET\")  # go to labellerr workspace to get your API secret\n",
    "client_id = input(\"YOUR_CLIENT_ID\")   # Contact labellerr support to get your client ID i.e. support@tensormatics.com\n",
    "\n",
    "client = LabellerrClient(api_key, api_secret, client_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***STEP-1: Create a dataset on labellerr from your local folder***\n",
    "\n",
    "The SDK supports in creating dataset by uploading local files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bab602150d0462d8a724c7f48ac1984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='D:\\', filename='', title='Select a folder containing your dataset', show_hidden=False, selec‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a folder chooser starting from a directory (for example, your home directory)\n",
    "chooser = FileChooser('/')\n",
    "\n",
    "# Set the chooser to folder selection mode only\n",
    "chooser.title = 'Select a folder containing your dataset'\n",
    "chooser.show_only_dirs = True\n",
    "\n",
    "# Display the widget\n",
    "display(chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected: D:\\Professional\\Projects\\Cell_Segmentation_using_YOLO\\frames_output\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = chooser.selected_path\n",
    "print(\"You selected:\", path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataset type: video\n"
     ]
    }
   ],
   "source": [
    "my_dataset_type = input(\"Enter your dataset type (video or image): \").lower()\n",
    "print(\"Selected dataset type:\", my_dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset_from_local(\n",
    "    client=client,\n",
    "    dataset_config=DatasetConfig(dataset_name=\"My Dataset\", data_type=\"image\"),\n",
    "    folder_to_upload=path_to_dataset\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with ID: {dataset.dataset_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***STEP-2: Create annotation project on labellerr of your created dataset***\n",
    "\n",
    "Create a annotation project of your uploaded dataset to start performing annotation on labellerr UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation guideline template for video annotation project (like classes to be annotated)\n",
    "\n",
    "template = create_template(\n",
    "    client=client,\n",
    "    params=CreateTemplateParams(\n",
    "        template_name=\"My Template\",\n",
    "        data_type=DatasetDataType.image,\n",
    "        questions=[\n",
    "            AnnotationQuestion(\n",
    "                question_number=1,\n",
    "                question=\"Object\",\n",
    "                question_id=str(uuid.uuid4()),\n",
    "                question_type=QuestionType.polygon,\n",
    "                required=True,\n",
    "                color=\"#FF0000\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(f\"Annotation template created with ID: {template.annotation_template_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.status()        # wait until dataset is processed before creating project\n",
    "\n",
    "project = create_project(\n",
    "    client=client,\n",
    "    params=CreateProjectParams(\n",
    "        project_name=\"My Project\",\n",
    "        data_type=DatasetDataType.image,\n",
    "        rotations=RotationConfig(\n",
    "            annotation_rotation_count=1,\n",
    "            review_rotation_count=1,\n",
    "            client_review_rotation_count=1\n",
    "        )\n",
    "    ),\n",
    "    datasets=[dataset],\n",
    "    annotation_template=template\n",
    ")\n",
    "\n",
    "print(f\"‚úì Project created: {project.project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project has been created now go to labellerr platform to perform annotation \n",
    "\n",
    "***click to go to labellerr.com***\n",
    "\n",
    "[![Labellerr](https://cdn.labellerr.com/1%20%20Documentation/1c9dc7ce-9a54-4111-8fd5-0363ba3e00e1.webp)](https://www.labellerr.com/?utm_source=githubY&utm_medium=social&utm_campaign=github_clicks)\n",
    "Open the project you created (Projects ‚Üí select your project).\n",
    "\n",
    "Click Start Labeling to open the annotation interface. Use the configured labeling tools (bounding boxes, polygon, dot, classification, etc.) to annotate files.\n",
    "### ***STEP-3: Export your annotation in required format***\n",
    "\n",
    "Generate a temporary download URL to retrieve your exported JSON file:\n",
    "\n",
    "### Export Configuration Parameters\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `export_name` | string | Display name for the export |\n",
    "| `export_description` | string | Description of what this export contains |\n",
    "| `export_format` | string | Output format (e.g., `json`, `xml`, `coco`) |\n",
    "| `statuses` | list | Annotation statuses to include in export |\n",
    "\n",
    "### Common Annotation Statuses\n",
    "\n",
    "- **`review`**: Annotations pending review\n",
    "- **`r_assigned`**: Review assigned to a reviewer\n",
    "- **`client_review`**: Under client review\n",
    "- **`cr_assigned`**: Client review assigned\n",
    "- **`accepted`**: Annotations accepted and finalized\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_config = {\n",
    "    \"export_name\": \"Weekly Export\",\n",
    "    \"export_description\": \"Export of all accepted annotations\",\n",
    "    \"export_format\": \"coco_json\",\n",
    "    \"statuses\": ['review', 'r_assigned','client_review', 'cr_assigned','accepted']\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Get project instance\n",
    "    project = LabellerrProject(client=client, project_id=project.project_id)\n",
    "    \n",
    "    # Create export\n",
    "    result = project.create_local_export(export_config)\n",
    "    export_id = result[\"response\"]['report_id']\n",
    "    print(f\"Local export created successfully. Export ID: {export_id}\")\n",
    "except LabellerrError as e:\n",
    "    print(f\"Local export creation failed: {str(e)}\")\n",
    "    \n",
    "    \n",
    "try:\n",
    "    download_url = client.fetch_download_url(\n",
    "        project_id=project.project_id,\n",
    "        uuid=str(uuid.uuid4()),\n",
    "        export_id=export_id\n",
    "    )\n",
    "    print(f\"Download URL: {download_url}\")\n",
    "except LabellerrError as e:\n",
    "    print(f\"Failed to fetch download URL: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can download your annotations locally using given URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convert COCO Format to YOLO Format**\n",
    "Transform COCO JSON annotations to YOLO's required format with normalized bounding box coordinates in separate .txt files. This prepares the dataset for YOLO model fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_finetune_utils.coco_yolo_converter.bbox_converter import coco_to_yolo_converter\n",
    "\n",
    "result = coco_to_yolo_converter(\n",
    "            json_path='annotation.json',\n",
    "            images_dir='./output',\n",
    "            output_dir='yolo_format',\n",
    "            use_split=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Install Ultralytics YOLO Package**\n",
    "Install the Ultralytics library which provides the YOLO model implementation for object detection tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T10:53:42.140929Z",
     "iopub.status.busy": "2024-10-08T10:53:42.140487Z",
     "iopub.status.idle": "2024-10-08T10:53:57.946910Z",
     "shell.execute_reply": "2024-10-08T10:53:57.945769Z",
     "shell.execute_reply.started": "2024-10-08T10:53:42.140885Z"
    },
    "id": "Lrt8kAH2R5IH",
    "outputId": "08082014-c5c9-45f7-aa75-9546b9e168a9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (8.3.168)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
      "Requirement already satisfied: filelock in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.8.0->ultralytics) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/HP/miniconda3/envs/finetune-yolo/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verify Ultralytics Installation**\n",
    "Run system checks to verify the Ultralytics package is properly installed and configured with all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T10:54:09.803437Z",
     "iopub.status.busy": "2024-10-08T10:54:09.802985Z",
     "iopub.status.idle": "2024-10-08T10:54:31.308005Z",
     "shell.execute_reply": "2024-10-08T10:54:31.306916Z",
     "shell.execute_reply.started": "2024-10-08T10:54:09.803393Z"
    },
    "id": "OKI6XspoSkdc",
    "outputId": "e46b2ba4-48dc-4a6c-abb4-629cf7e88a44",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168 üöÄ Python-3.10.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA L4, 22491MiB)\n",
      "Setup complete ‚úÖ (4 CPUs, 15.6 GB RAM, 82.9/247.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Required Libraries**\n",
    "Import YOLO model class from Ultralytics and Image display utility for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T10:54:37.319418Z",
     "iopub.status.busy": "2024-10-08T10:54:37.318897Z",
     "iopub.status.idle": "2024-10-08T10:54:37.324139Z",
     "shell.execute_reply": "2024-10-08T10:54:37.323199Z",
     "shell.execute_reply.started": "2024-10-08T10:54:37.319379Z"
    },
    "id": "oHWcOSblSGg8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Display Current Working Directory**\n",
    "Show the current directory path in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Construct Dataset Path**\n",
    "Build the full path to the YOLO format dataset directory for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T10:55:32.254504Z",
     "iopub.status.busy": "2024-10-08T10:55:32.254004Z",
     "iopub.status.idle": "2024-10-08T10:55:32.263896Z",
     "shell.execute_reply": "2024-10-08T10:55:32.262758Z",
     "shell.execute_reply.started": "2024-10-08T10:55:32.254460Z"
    },
    "id": "mdZobxnHVhhf",
    "outputId": "40268334-9043-437c-c6ed-de1cd5374e8e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/yolo_format\n"
     ]
    }
   ],
   "source": [
    "location = !pwd\n",
    "dataset_path = f\"{location[0]}/yolo_format\"\n",
    "print(f\"Dataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fine-tune YOLO11 on Custom PPE Dataset**\n",
    "Train a YOLO11x model on the custom PPE detection dataset for 200 epochs with batch size 30 and 640x640 image resolution. The model learns to detect various PPE items in images and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T11:01:01.462203Z",
     "iopub.status.busy": "2024-10-08T11:01:01.461737Z",
     "iopub.status.idle": "2024-10-08T11:44:40.134169Z",
     "shell.execute_reply": "2024-10-08T11:44:40.132786Z",
     "shell.execute_reply.started": "2024-10-08T11:01:01.462163Z"
    },
    "id": "yxp_shPlYBAS",
    "outputId": "950df9d7-2ca6-4624-fc38-dfc4264059cb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train data={dataset_path}/dataset.yaml model=\"yolo11x.pt\" epochs=200 imgsz=640 batch=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run Inference on Video**\n",
    "Execute the fine-tuned model on a test video to detect PPE compliance. Uses the best trained model weights with 0.25 confidence threshold and saves annotated output video showing detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T11:49:37.983486Z",
     "iopub.status.busy": "2024-10-08T11:49:37.983009Z",
     "iopub.status.idle": "2024-10-08T11:49:37.989115Z",
     "shell.execute_reply": "2024-10-08T11:49:37.987921Z",
     "shell.execute_reply.started": "2024-10-08T11:49:37.983443Z"
    },
    "id": "xmwUaudA8JFj",
    "outputId": "2dbb1af8-60b2-42d9-bad7-2f9a7317a5b9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168 üöÄ Python-3.10.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA L4, 22491MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "video 1/1 (frame 1/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 70.5ms\n",
      "video 1/1 (frame 2/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 11.1ms\n",
      "video 1/1 (frame 3/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.6ms\n",
      "video 1/1 (frame 4/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.8ms\n",
      "video 1/1 (frame 5/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 10.8ms\n",
      "video 1/1 (frame 6/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 7 vests, 10.1ms\n",
      "video 1/1 (frame 7/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 8 vests, 10.2ms\n",
      "video 1/1 (frame 8/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 8 vests, 9.6ms\n",
      "video 1/1 (frame 9/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 10.3ms\n",
      "video 1/1 (frame 10/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.4ms\n",
      "video 1/1 (frame 11/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 12/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 10.0ms\n",
      "video 1/1 (frame 13/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.7ms\n",
      "video 1/1 (frame 14/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.4ms\n",
      "video 1/1 (frame 15/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 16/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.5ms\n",
      "video 1/1 (frame 17/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 11.4ms\n",
      "video 1/1 (frame 18/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 19/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 20/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.6ms\n",
      "video 1/1 (frame 21/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.8ms\n",
      "video 1/1 (frame 22/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 8.9ms\n",
      "video 1/1 (frame 23/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 24/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 25/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 26/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 8.8ms\n",
      "video 1/1 (frame 27/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 8.9ms\n",
      "video 1/1 (frame 28/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 10.0ms\n",
      "video 1/1 (frame 29/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.4ms\n",
      "video 1/1 (frame 30/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 10.1ms\n",
      "video 1/1 (frame 31/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 32/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 33/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 34/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 10.3ms\n",
      "video 1/1 (frame 35/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.0ms\n",
      "video 1/1 (frame 36/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 10.0ms\n",
      "video 1/1 (frame 37/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.6ms\n",
      "video 1/1 (frame 38/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 10.4ms\n",
      "video 1/1 (frame 39/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 40/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 41/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.9ms\n",
      "video 1/1 (frame 42/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.9ms\n",
      "video 1/1 (frame 43/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.7ms\n",
      "video 1/1 (frame 44/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.0ms\n",
      "video 1/1 (frame 45/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.8ms\n",
      "video 1/1 (frame 46/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 10.2ms\n",
      "video 1/1 (frame 47/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 48/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 9 safety helmets, 8 vests, 8.9ms\n",
      "video 1/1 (frame 49/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 50/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.5ms\n",
      "video 1/1 (frame 51/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.8ms\n",
      "video 1/1 (frame 52/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.9ms\n",
      "video 1/1 (frame 53/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 8.8ms\n",
      "video 1/1 (frame 54/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 9 vests, 10.9ms\n",
      "video 1/1 (frame 55/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.6ms\n",
      "video 1/1 (frame 56/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 57/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 58/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 59/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 60/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 61/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.5ms\n",
      "video 1/1 (frame 62/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 63/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.5ms\n",
      "video 1/1 (frame 64/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 6 vests, 9.4ms\n",
      "video 1/1 (frame 65/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.0ms\n",
      "video 1/1 (frame 66/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 67/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.7ms\n",
      "video 1/1 (frame 68/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 69/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 9 vests, 9.0ms\n",
      "video 1/1 (frame 70/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.5ms\n",
      "video 1/1 (frame 71/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.9ms\n",
      "video 1/1 (frame 72/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.5ms\n",
      "video 1/1 (frame 73/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 10.5ms\n",
      "video 1/1 (frame 74/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.3ms\n",
      "video 1/1 (frame 75/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.8ms\n",
      "video 1/1 (frame 76/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.4ms\n",
      "video 1/1 (frame 77/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 9 vests, 9.1ms\n",
      "video 1/1 (frame 78/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.2ms\n",
      "video 1/1 (frame 79/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 80/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 81/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.0ms\n",
      "video 1/1 (frame 82/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 83/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.7ms\n",
      "video 1/1 (frame 84/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.2ms\n",
      "video 1/1 (frame 85/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 8.9ms\n",
      "video 1/1 (frame 86/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.5ms\n",
      "video 1/1 (frame 87/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.3ms\n",
      "video 1/1 (frame 88/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 89/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.3ms\n",
      "video 1/1 (frame 90/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 91/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.8ms\n",
      "video 1/1 (frame 92/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 11.2ms\n",
      "video 1/1 (frame 93/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.4ms\n",
      "video 1/1 (frame 94/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.6ms\n",
      "video 1/1 (frame 95/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.6ms\n",
      "video 1/1 (frame 96/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 10.2ms\n",
      "video 1/1 (frame 97/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 9 vests, 9.6ms\n",
      "video 1/1 (frame 98/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.5ms\n",
      "video 1/1 (frame 99/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 9 safety helmets, 8 vests, 9.8ms\n",
      "video 1/1 (frame 100/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 101/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 102/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.2ms\n",
      "video 1/1 (frame 103/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 9 vests, 9.1ms\n",
      "video 1/1 (frame 104/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.1ms\n",
      "video 1/1 (frame 105/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 8 vests, 9.3ms\n",
      "video 1/1 (frame 106/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 10.3ms\n",
      "video 1/1 (frame 107/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 7 vests, 9.6ms\n",
      "video 1/1 (frame 108/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 6 vests, 10.5ms\n",
      "video 1/1 (frame 109/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 8 safety helmets, 6 vests, 10.0ms\n",
      "video 1/1 (frame 110/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 9.2ms\n",
      "video 1/1 (frame 111/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 7 vests, 9.1ms\n",
      "video 1/1 (frame 112/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.8ms\n",
      "video 1/1 (frame 113/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 10.2ms\n",
      "video 1/1 (frame 114/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 115/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.2ms\n",
      "video 1/1 (frame 116/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 117/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.9ms\n",
      "video 1/1 (frame 118/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 10.1ms\n",
      "video 1/1 (frame 119/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 8.9ms\n",
      "video 1/1 (frame 120/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.0ms\n",
      "video 1/1 (frame 121/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 11.1ms\n",
      "video 1/1 (frame 122/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 7 vests, 10.2ms\n",
      "video 1/1 (frame 123/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.2ms\n",
      "video 1/1 (frame 124/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.4ms\n",
      "video 1/1 (frame 125/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 11.5ms\n",
      "video 1/1 (frame 126/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 127/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 10.1ms\n",
      "video 1/1 (frame 128/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.2ms\n",
      "video 1/1 (frame 129/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 5 safety helmets, 6 vests, 11.0ms\n",
      "video 1/1 (frame 130/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.4ms\n",
      "video 1/1 (frame 131/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.7ms\n",
      "video 1/1 (frame 132/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.1ms\n",
      "video 1/1 (frame 133/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.2ms\n",
      "video 1/1 (frame 134/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 7 vests, 9.2ms\n",
      "video 1/1 (frame 135/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 136/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.1ms\n",
      "video 1/1 (frame 137/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.0ms\n",
      "video 1/1 (frame 138/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.1ms\n",
      "video 1/1 (frame 139/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.9ms\n",
      "video 1/1 (frame 140/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.0ms\n",
      "video 1/1 (frame 141/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 8.9ms\n",
      "video 1/1 (frame 142/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 143/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 6 safety helmets, 6 vests, 10.0ms\n",
      "video 1/1 (frame 144/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.5ms\n",
      "video 1/1 (frame 145/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.1ms\n",
      "video 1/1 (frame 146/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.4ms\n",
      "video 1/1 (frame 147/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.7ms\n",
      "video 1/1 (frame 148/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.1ms\n",
      "video 1/1 (frame 149/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 150/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.3ms\n",
      "video 1/1 (frame 151/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 7 vests, 10.2ms\n",
      "video 1/1 (frame 152/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 9.0ms\n",
      "video 1/1 (frame 153/153) /home/HP/USE_CASE_PROJECT/fine-tune-yolo-for-PPE-detection/video/b.mp4: 736x1280 7 safety helmets, 6 vests, 10.0ms\n",
      "Speed: 5.6ms preprocess, 9.9ms inference, 5.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"./runs/detect/train/weights/best.pt\" conf=0.25 source=\"./video/b.mp4\" save=True show_labels=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **View Inference Results**\n",
    "Display the results from the model inference showing detected PPE items and their confidence scores in the output video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üë®‚Äçüíª About Labellerr's Hands-On Learning in Computer Vision\n",
    "\n",
    "Thank you for exploring this **Labellerr Hands-On Computer Vision Cookbook**! We hope this notebook helped you learn, prototype, and accelerate your vision projects.  \n",
    "Labellerr provides ready-to-run Jupyter/Colab notebooks for the latest models and real-world use cases in computer vision, AI agents, and data annotation.\n",
    "\n",
    "---\n",
    "## üßë‚Äçüî¨ Check Our Popular Youtube Videos\n",
    "\n",
    "Whether you're a beginner or a practitioner, our hands-on training videos are perfect for learning custom model building, computer vision techniques, and applied AI:\n",
    "\n",
    "- [How to Fine-Tune YOLO on Custom Dataset](https://www.youtube.com/watch?v=pBLWOe01QXU)  \n",
    "  Step-by-step guide to fine-tuning YOLO for real-world use‚Äîenvironment setup, annotation, training, validation, and inference.\n",
    "- [Build a Real-Time Intrusion Detection System with YOLO](https://www.youtube.com/watch?v=kwQeokYDVcE)  \n",
    "  Create an AI-powered system to detect intruders in real time using YOLO and computer vision.\n",
    "- [Finding Athlete Speed Using YOLO](https://www.youtube.com/watch?v=txW0CQe_pw0)  \n",
    "  Estimate real-time speed of athletes for sports analytics.\n",
    "- [Object Counting Using AI](https://www.youtube.com/watch?v=smsjBBQcIUQ)  \n",
    "  Learn dataset curation, annotation, and training for robust object counting AI applications.\n",
    "---\n",
    "\n",
    "## üé¶ Popular Labellerr YouTube Videos\n",
    "\n",
    "Level up your skills and see video walkthroughs of these tools and notebooks on the  \n",
    "[Labellerr YouTube Channel](https://www.youtube.com/@Labellerr/videos):\n",
    "\n",
    "- [How I Fixed My Biggest Annotation Nightmare with Labellerr](https://www.youtube.com/watch?v=hlcFdiuz_HI) ‚Äì Solving complex annotation for ML engineers.\n",
    "- [Explore Your Dataset with Labellerr's AI](https://www.youtube.com/watch?v=LdbRXYWVyN0) ‚Äì Auto-tagging, object counting, image descriptions, and dataset exploration.\n",
    "- [Boost AI Image Annotation 10X with Labellerr's CLIP Mode](https://www.youtube.com/watch?v=pY_o4EvYMz8) ‚Äì Refine annotations with precision using CLIP mode.\n",
    "- [Boost Data Annotation Accuracy and Efficiency with Active Learning](https://www.youtube.com/watch?v=lAYu-ewIhTE) ‚Äì Speed up your annotation workflow using Active Learning.\n",
    "\n",
    "> üëâ **Subscribe** for Labellerr's deep learning, annotation, and AI tutorials, or watch videos directly alongside notebooks!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Stay Connected\n",
    "\n",
    "- **Website:** [https://www.labellerr.com/](https://www.labellerr.com/)\n",
    "- **Blog:** [https://www.labellerr.com/blog/](https://www.labellerr.com/blog/)\n",
    "- **GitHub:** [Labellerr/Hands-On-Learning-in-Computer-Vision](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "- **LinkedIn:** [Labellerr](https://in.linkedin.com/company/labellerr)\n",
    "- **Twitter/X:** [@Labellerr1](https://x.com/Labellerr1)\n",
    "\n",
    "*Happy learning and building with Labellerr!*\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "finetune-yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
