{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75cd5632",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fashion Brand Tag OCR**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e9c2b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates an end-to-end computer vision pipeline for automated retail price tag analysis using a YOLO-based detection model combined with optical character recognition (OCR). The workflow covers real-time tag detection, intelligent text extraction, and inventory logging, designed to streamline data entry in retail environments.\n",
    "\n",
    "#### Key Features:\n",
    "* **Hybrid Architecture:** Combines YOLOv11 for precise object detection (Brand, Price, Size) with EasyOCR for robust text extraction.\n",
    "* **Intelligent Pre-processing:** Implements adaptive thresholding and contour analysis to handle varying lighting conditions, shadows, and image noise.\n",
    "* **Surgical OCR Logic:** Features custom \"surgical\" cropping techniques to eliminate currency symbols (e.g., ‚Çπ) that confuse standard OCR engines, ensuring high-accuracy price validation.\n",
    "* **Global Context Awareness:** Utilizes full-tag fuzzy matching to identify brands even when specific brand bounding boxes are missed or occluded.\n",
    "* **Automated Inventory Logging:** Automatically validates extracted data (Price, Size, Brand) and logs unique items to an Excel database in real-time.\n",
    "\n",
    "#### Real-World Applications:\n",
    "* Automated inventory management and stock auditing\n",
    "* Retail checkout automation and smart shopping systems\n",
    "* Price verification and compliance monitoring\n",
    "* Data digitization for e-commerce cataloging\n",
    "* Supply chain tracking for fashion and apparel industries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e554a7",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "This section imports all the required libraries used throughout the project for computer vision, visualization, deep learning, and structured coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Labellerr/yolo_finetune_utils.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5ba35",
   "metadata": {},
   "source": [
    "## üì• Download Annotations from Labellerr\n",
    "\n",
    "After completing data labeling on the **Labellerr** platform, export the annotations in **COCO JSON format**.\n",
    "\n",
    "Download the COCO JSON file from the Labellerr website and upload it into this project workspace to use it for further dataset preparation and training.\n",
    "\n",
    "This COCO JSON file will be used in the next steps for:\n",
    "- Frame‚Äìannotation alignment\n",
    "- COCO ‚Üí YOLO format conversion\n",
    "- Model training and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6bc058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading COCO dataset from export-#LsYK4074YWR3WypfuCLR.json\n",
      "Found 98 images and 270 annotations\n",
      "Categories mapping:\n",
      "  COCO ID 0 (Brand) -> YOLO class 0\n",
      "  COCO ID 1 (Size) -> YOLO class 1\n",
      "  COCO ID 2 (MRP) -> YOLO class 2\n",
      "Images with annotations: 92\n",
      "Dataset split:\n",
      "  train: 64 images\n",
      "  val: 18 images\n",
      "  test: 10 images\n",
      "\n",
      "Processing train split...\n",
      "\n",
      "Processing val split...\n",
      "\n",
      "Processing test split...\n",
      "\n",
      "Conversion completed:\n",
      "  Successfully processed: 92 images\n",
      "  Failed to find: 0 images\n",
      "  Total annotations converted: 270\n",
      "  Categories: 3\n",
      "\n",
      "YOLO dataset created at: yolo_dataset\n",
      "Dataset configuration: yolo_dataset\\dataset.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_path': 'yolo_dataset',\n",
       " 'yaml_path': 'yolo_dataset\\\\dataset.yaml',\n",
       " 'stats': {'total_images': 98,\n",
       "  'images_with_annotations': 92,\n",
       "  'successful_copies': 92,\n",
       "  'failed_copies': 0,\n",
       "  'total_annotations': 270,\n",
       "  'categories': 3,\n",
       "  'category_mapping': {0: 0, 1: 1, 2: 2},\n",
       "  'class_names': {0: 'Brand', 1: 'Size', 2: 'MRP'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yolo_finetune_utils.coco_yolo_converter.bbox_converter import coco_to_yolo_converter\n",
    "\n",
    "coco_to_yolo_converter(\n",
    "    json_path=\"export-#LsYK4074YWR3WypfuCLR.json\",\n",
    "    images_dir=\"drive-download-20260122T045027Z-1-001\",\n",
    "    output_dir=\"yolo_dataset\",\n",
    "    use_split=True,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b2fe6",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The following script initiates the training process for the YOLOv11 model. It uses the custom dataset defined in `dataset.yaml` and trains for 100 epochs to ensure robust detection of tags, prices, and brand text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv11 Nano model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=\"yolo_dataset\\dataset.yaml\",      # Path to the yaml file created above\n",
    "    epochs=100,         # 100 iterations\n",
    "    imgsz=640,          # Standard image size\n",
    "    batch=16,           # Batch size (reduce to 8 if you run out of memory)\n",
    "    project=\"Tag_OCR_Project\",\n",
    "    name=\"run_tag_detection\",\n",
    "    device=\"cpu\"        # Change to 0 if you have an NVIDIA GPU setup\n",
    ")\n",
    "\n",
    "print(\" Training Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0a53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4651783",
   "metadata": {},
   "source": [
    "#  Inference\n",
    "\n",
    "This script is the central engine for the Price Tag OCR project, coordinating object detection (YOLO), text recognition (EasyOCR), and database logging (Pandas).\n",
    "\n",
    "---\n",
    "\n",
    "##  1. Libraries & Dependencies\n",
    "\n",
    "| Library | Purpose |\n",
    "| :--- | :--- |\n",
    "| **cv2** (OpenCV) | Image processing: converting to grayscale, resizing crops, and drawing boxes. |\n",
    "| **re** | Regex for cleaning OCR output (extracting 1299 from Rs. 1,299). |\n",
    "| **pandas** | Database management: reading/writing the inventory_log.xlsx file. |\n",
    "| **ultralytics** | Loads the custom YOLOv11 model (best.pt) for object detection. |\n",
    "| **easyocr** | The Deep Learning engine that reads text from image crops. |\n",
    "| **difflib** | Fuzzy logic to correct brand typos (e.g., matching \"PEPE JENS\" to \"PEPE JEANS\"). |\n",
    "| **`tkinter** | Creates the Windows file upload popup for \"Upload Mode\". |\n",
    "\n",
    "---\n",
    "\n",
    "##  2. Key Configuration\n",
    "\n",
    "* **MODEL_PATH**: Points to your trained YOLO weights (best.pt).\n",
    "* **CONFIDENCE_THRESHOLD = 0.3**: Ignores any detection with less than 30% confidence to reduce noise.\n",
    "* **KNOWN_BRANDS**: A strict allow-list. The system only logs brands that fuzzy-match this list, preventing random text from being saved as a brand.\n",
    "\n",
    "---\n",
    "\n",
    "##  3. Core Logic Breakdown\n",
    "\n",
    "### **A. clean_price(text)**\n",
    "Sanitizes raw OCR output.\n",
    "* **Logic:** Removes junk symbols (MRP, ‚Çπ, Rs.) and uses Regex (\\d+) to grab the first valid number sequence.\n",
    "\n",
    "### **B. process_frame(frame)**\n",
    "The main pipeline running on every image. It has two stages:\n",
    "\n",
    "**Stage 1: YOLO Detection (Price & Size)**\n",
    "* **The \"Left Cut\":** For Price boxes, it slices off the **left 20%** of the image. This physically removes the Rupee symbol (`‚Çπ`) so OCR doesn't misread it as a 2.\n",
    "* **Upscaling:** Resizes crops (2x) to make small text clearer for EasyOCR.\n",
    "\n",
    "**Stage 2: Global Context (Full Tag Scan)**\n",
    "* **Trigger:** Runs *only* if a valid Price is found.\n",
    "* **Full Scan:** Reads the entire image text to find the **Brand Name** \n",
    "\n",
    "### **C. save_to_excel(data)**\n",
    "Handles data persistence.\n",
    "* **Duplicate Check:** Creates a unique ID (Brand_Price) and checks if it exists in the Excel file before saving.\n",
    "* **Logging:** Appends valid data (Brand, Size, MRP, Time) to inventory_log.xlsx.\n",
    "\n",
    "---\n",
    "\n",
    "##  4. Execution Modes\n",
    "\n",
    "* **Mode 1 (Webcam):** Sets camera to HD (1280x720) for clarity and runs in a live loop.\n",
    "* **Mode 2 (Upload):** Uses a hidden Tkinter window (forced to top) to open a file picker for high-res static images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from datetime import datetime\n",
    "from difflib import get_close_matches\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_PATH = \"best (5).pt\"  \n",
    "CONFIDENCE_THRESHOLD = 0.3 \n",
    "\n",
    "\n",
    "KNOWN_BRANDS = [\n",
    "    \"MAXFASHION\", \"MAX\", \n",
    "    \"PEPE JEANS\", \"PEPE\", \n",
    "    \"ARVIND YOUTH\", \"ARVIND\",\n",
    "    \"ADITYA BIRLA FASHION\", \"ADITYA BIRLA\", \"MADURA FASHION\",\n",
    "    \"SPYKAR\", \"LIFESTYLE\", \"LIFESTYLE INTERNATIONAL\", \"MELANGE\", \"GINGER\", \"CODE\"\n",
    "]\n",
    "\n",
    "def clean_price(text):\n",
    "    \"\"\" Robust Price Cleaner \"\"\"\n",
    "    text = text.upper()\n",
    "    for junk in [',', ' ', 'MRP', 'RS', 'RS.', 'INR', '‚Çπ', 'PRICE', ':', 'INCL', 'TAXES', 'ALL', 'OF', '.00', '/-']:\n",
    "        text = text.replace(junk, '')\n",
    "        \n",
    "    match = re.search(r'(\\d+)', text)\n",
    "    if match: return match.group(1)\n",
    "    return None\n",
    "\n",
    "def fuzzy_match_brand(full_text):\n",
    "    \"\"\" Scans the WHOLE tag text for the brand \"\"\"\n",
    "    if not full_text: return None\n",
    "    full_text_upper = full_text.upper()\n",
    "    \n",
    "    \n",
    "    for brand in KNOWN_BRANDS:\n",
    "        if brand in full_text_upper: return brand\n",
    "\n",
    "    \n",
    "    words = full_text_upper.split()\n",
    "    for word in words:\n",
    "        if len(word) < 3: continue \n",
    "        matches = get_close_matches(word, KNOWN_BRANDS, n=1, cutoff=0.6)\n",
    "        if matches: return matches[0]\n",
    "    return None\n",
    "\n",
    "def process_frame(frame, model, reader):\n",
    "    results = model(frame, stream=True, verbose=False)\n",
    "    data = {\"Brand\": None, \"Size\": None, \"MRP\": None}\n",
    "    price_detected = False\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = model.names[int(box.cls[0])]\n",
    "            \n",
    "           \n",
    "            if cls_name == 'Brand': \n",
    "                continue\n",
    "\n",
    "            thresh = 0.15 if cls_name == 'Size' else CONFIDENCE_THRESHOLD\n",
    "            if conf < thresh: continue\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            color = (0, 255, 0) if cls_name == 'MRP' else (0, 165, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "            \n",
    "            \n",
    "            pad = 5\n",
    "            crop = frame[max(0, y1-pad):min(h, y2+pad), max(0, x1-pad):min(w, x2+pad)]\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                if cls_name == 'MRP':\n",
    "                    crop_h, crop_w = crop.shape[:2]\n",
    "                    crop = crop[:, int(crop_w * 0.20) : int(crop_w * 0.95)]\n",
    "                \n",
    "            \n",
    "                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "                gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "                \n",
    "                \n",
    "                ocr_result = reader.readtext(gray, detail=0) \n",
    "                text_val = \" \".join(ocr_result)\n",
    "                \n",
    "                print(f\"RAW READ ({cls_name}): {text_val}\") \n",
    "                \n",
    "                if text_val:\n",
    "                    if cls_name == 'MRP':\n",
    "                        cleaned = clean_price(text_val)\n",
    "                        if cleaned:\n",
    "                            data[\"MRP\"] = cleaned\n",
    "                            price_detected = True\n",
    "                            print(f\"üí∞ Price Validated: {cleaned}\")\n",
    "                            \n",
    "                    elif cls_name == 'Size':\n",
    "                        size_clean = text_val.split()[0].replace(',', '').replace('.', '')\n",
    "                        data[\"Size\"] = size_clean\n",
    "                    \n",
    "                    cv2.putText(frame, f\"{cls_name}: {text_val}\", (x1, y1-15), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    if price_detected:\n",
    "        print(\"Reading Full Tag for Brand...\")\n",
    "        try:\n",
    "            \n",
    "            scan_frame = frame.copy()\n",
    "            if w > 1600:\n",
    "                scale = 1600 / w\n",
    "                scan_frame = cv2.resize(scan_frame, None, fx=scale, fy=scale)\n",
    "            \n",
    "            full_text_list = reader.readtext(scan_frame, detail=0)\n",
    "            full_text = \" \".join(full_text_list)\n",
    "            \n",
    "            found_brand = fuzzy_match_brand(full_text)\n",
    "            if found_brand:\n",
    "                data[\"Brand\"] = found_brand\n",
    "                cv2.rectangle(frame, (0, 0), (w, 80), (0, 255, 0), -1)\n",
    "                cv2.putText(frame, f\"BRAND: {found_brand}\", (20, 60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 4)\n",
    "\n",
    "            \n",
    "            if not data[\"Size\"]:\n",
    "                common_sizes = ['XS', 'S', 'M', 'L', 'XL', 'XXL', '30', '32', '34', '36', '38', '40', '42', '44']\n",
    "                full_text_words = full_text.upper().replace('\\n', ' ').split()\n",
    "                for size in common_sizes:\n",
    "                    if size in full_text_words:\n",
    "                        data[\"Size\"] = size\n",
    "                        break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Global Error: {e}\")\n",
    "            \n",
    "    return frame, data\n",
    "\n",
    "def save_to_excel(data):\n",
    "    \"\"\"\n",
    "    Saves data to Excel WITHOUT checking for duplicates.\n",
    "    Every scan = New Row.\n",
    "    \"\"\"\n",
    "    if data[\"MRP\"]:\n",
    "        final_brand = data[\"Brand\"] if data[\"Brand\"] else \"Unknown\"\n",
    "        final_size = data[\"Size\"] if data[\"Size\"] else \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_excel(\"inventory_log.xlsx\")\n",
    "            inventory_log = df.to_dict('records')\n",
    "        except:\n",
    "            inventory_log = []\n",
    "\n",
    "        \n",
    "        item_id = f\"{final_brand}_{data['MRP']}\" \n",
    "        \n",
    "        print(f\"SAVING: {final_brand} | {final_size} | {data['MRP']}\")\n",
    "        entry = {\n",
    "            \"ID\": item_id, \n",
    "            \"Brand\": final_brand, \n",
    "            \"Size\": final_size, \n",
    "            \"MRP\": data[\"MRP\"], \n",
    "            \"Time\": datetime.now().strftime(\"%H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        inventory_log.append(entry)\n",
    "        pd.DataFrame(inventory_log).to_excel(\"inventory_log.xlsx\", index=False)\n",
    "        print(\"Excel Updated!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"‚è≥ Loading YOLO...\")\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(\"‚è≥ Loading EasyOCR...\")\n",
    "    reader = easyocr.Reader(['en'], gpu=False)\n",
    "    \n",
    "    mode = input(\"Select Mode:\\n[1] Live Webcam\\n[2] Upload Image\\n>>> \")\n",
    "\n",
    "    if mode == '2':\n",
    "        root = tk.Tk(); root.withdraw(); root.attributes('-topmost', True)\n",
    "        print(\" Pick your image!\")\n",
    "        file_path = filedialog.askopenfilename(parent=root, filetypes=[(\"Images\", \"*.jpg;*.png;*.jpeg\")])\n",
    "        \n",
    "        if file_path:\n",
    "            img = cv2.imread(file_path)\n",
    "            processed_img, result_data = process_frame(img, model, reader)\n",
    "            save_to_excel(result_data)\n",
    "            \n",
    "            h, w = processed_img.shape[:2]\n",
    "            if h > 800:\n",
    "                scale = 800 / h\n",
    "                processed_img = cv2.resize(processed_img, None, fx=scale, fy=scale)\n",
    "                \n",
    "            cv2.imshow(\"Result\", processed_img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        print(\" Webcam Started!\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            processed_frame, result_data = process_frame(frame, model, reader)\n",
    "            if result_data[\"Brand\"] and result_data[\"MRP\"]:\n",
    "                save_to_excel(result_data)\n",
    "            cv2.imshow(\"Live\", processed_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adf820",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908aa947",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üë®‚Äçüíª About Labellerr's Hands-On Learning in Computer Vision\n",
    "\n",
    "Thank you for exploring this **Labellerr Hands-On Computer Vision Cookbook**! We hope this notebook helped you learn, prototype, and accelerate your vision projects.  \n",
    "Labellerr provides ready-to-run Jupyter/Colab notebooks for the latest models and real-world use cases in computer vision, AI agents, and data annotation.\n",
    "\n",
    "---\n",
    "## üßë‚Äçüî¨ Check Our Popular Youtube Videos\n",
    "\n",
    "Whether you're a beginner or a practitioner, our hands-on training videos are perfect for learning custom model building, computer vision techniques, and applied AI:\n",
    "\n",
    "- [How to Fine-Tune YOLO on Custom Dataset](https://www.youtube.com/watch?v=pBLWOe01QXU)  \n",
    "  Step-by-step guide to fine-tuning YOLO for real-world use‚Äîenvironment setup, annotation, training, validation, and inference.\n",
    "- [Build a Real-Time Intrusion Detection System with YOLO](https://www.youtube.com/watch?v=kwQeokYDVcE)  \n",
    "  Create an AI-powered system to detect intruders in real time using YOLO and computer vision.\n",
    "- [Finding Athlete Speed Using YOLO](https://www.youtube.com/watch?v=txW0CQe_pw0)  \n",
    "  Estimate real-time speed of athletes for sports analytics.\n",
    "- [Object Counting Using AI](https://www.youtube.com/watch?v=smsjBBQcIUQ)  \n",
    "  Learn dataset curation, annotation, and training for robust object counting AI applications.\n",
    "---\n",
    "\n",
    "## üé¶ Popular Labellerr YouTube Videos\n",
    "\n",
    "Level up your skills and see video walkthroughs of these tools and notebooks on the  \n",
    "[Labellerr YouTube Channel](https://www.youtube.com/@Labellerr/videos):\n",
    "\n",
    "- [How I Fixed My Biggest Annotation Nightmare with Labellerr](https://www.youtube.com/watch?v=hlcFdiuz_HI) ‚Äì Solving complex annotation for ML engineers.\n",
    "- [Explore Your Dataset with Labellerr's AI](https://www.youtube.com/watch?v=LdbRXYWVyN0) ‚Äì Auto-tagging, object counting, image descriptions, and dataset exploration.\n",
    "- [Boost AI Image Annotation 10X with Labellerr's CLIP Mode](https://www.youtube.com/watch?v=pY_o4EvYMz8) ‚Äì Refine annotations with precision using CLIP mode.\n",
    "- [Boost Data Annotation Accuracy and Efficiency with Active Learning](https://www.youtube.com/watch?v=lAYu-ewIhTE) ‚Äì Speed up your annotation workflow using Active Learning.\n",
    "\n",
    "> üëâ **Subscribe** for Labellerr's deep learning, annotation, and AI tutorials, or watch videos directly alongside notebooks!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Stay Connected\n",
    "\n",
    "- **Website:** [https://www.labellerr.com/](https://www.labellerr.com/)\n",
    "- **Blog:** [https://www.labellerr.com/blog/](https://www.labellerr.com/blog/)\n",
    "- **GitHub:** [Labellerr/Hands-On-Learning-in-Computer-Vision](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "- **LinkedIn:** [Labellerr](https://in.linkedin.com/company/labellerr)\n",
    "- **Twitter/X:** [@Labellerr1](https://x.com/Labellerr1)\n",
    "\n",
    "*Happy learning and building with Labellerr!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d98e13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
