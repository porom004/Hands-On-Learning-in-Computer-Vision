{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4785073c",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **An Integrated YOLOv8-Based Fire Detection and Automated Alarm Notification System**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59425e",
   "metadata": {},
   "source": [
    "## Annotate your Custom dataset using Labellerr\n",
    "\n",
    " ***1. Visit the [Labellerr](https://www.labellerr.com/?utm_source=githubY&utm_medium=social&utm_campaign=github_clicks) website and click **‚ÄúSign Up‚Äù**.*** \n",
    "\n",
    " ***2. After signing in, create your workspace by entering a unique name.***\n",
    "\n",
    " ***3. Navigate to your workspace‚Äôs API keys page (e.g., `https://<your-workspace>.labellerr.com/workspace/api-keys`) to generate your **API Key** and **API Secret**.***\n",
    "\n",
    " ***4. Store the credentials securely, and then use them to initialise the SDK or API client with `api_key`, `api_secret`.*** \n",
    "\n",
    "\n",
    "### Use Labellerr SDK for uploading and perform annotation of your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717eda4",
   "metadata": {},
   "source": [
    "## üìÅ Create & Annotate Your Dataset on Labellerr\n",
    "\n",
    "Before exporting your annotations, you must set up your project structure on the **Labellerr** platform to ensure your data is organized for the AI model.\n",
    "\n",
    "1.  **Create a Dataset Folder**: Log in to your Labellerr dashboard and create a new project folder specifically for this fire detection task.\n",
    "2.  **Upload Raw Data**: Upload your 5G camera frames or video segments into this folder.\n",
    "3.  **Perform Labeling**: Use the Labellerr interface to draw bounding boxes around fire and smoke regions.\n",
    "4.  **Export Annotations**: Once labeling is complete, export the data in **COCO JSON format**.\n",
    "\n",
    "---\n",
    "\n",
    "## üì• Download & Import Annotations\n",
    "\n",
    "Download the generated COCO JSON file from the Labellerr website and upload it into your local project workspace.\n",
    "\n",
    "This file is the \"ground truth\" for your AI and will be used for:\n",
    "* **Frame‚ÄìAnnotation Alignment**: Matching each JSON entry to the correct image frame.\n",
    "* **Format Conversion**: Converting Labellerr‚Äôs COCO format into the **YOLOv8** `.txt` format.\n",
    "* **Training & Evaluation**: Providing the labeled data required for the model to learn fire patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Labellerr/yolo_finetune_utils.git\n",
    "from yolo_finetune_utils.coco_yolo_converter.seg_converter import coco_to_yolo_converter\n",
    "\n",
    "coco_to_yolo_converter(\n",
    "    json_path=\"New_Annotation.json\",\n",
    "    images_dir=\"manufacturing_dataset_frames\",\n",
    "    output_dir=\"yolo_dataset\",\n",
    "    use_split=True,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    shuffle=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fc341",
   "metadata": {},
   "source": [
    "# Load and Train YOLO Segmentation Model\n",
    "\n",
    "Loads the YOLO segmentation model and trains it using the converted YOLO dataset.\n",
    "- Data: Path to YOLO-style `data.yaml`\n",
    "- Parameters: epochs, image size, batch size, device, dataloader workers, experiment name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"yolo_dataset/data.yaml\",\n",
    "    epochs=25,\n",
    "    imgsz=640,\n",
    "    batch=2,\n",
    "    device=\"cpu\",\n",
    "    workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11371d",
   "metadata": {},
   "source": [
    "# Technical Code Overview: Real-Time Fire Detection\n",
    "\n",
    "This script implements a production-ready fire detection pipeline using **YOLOv8** for object detection and **OpenCV** for real-time stream processing. It is designed to minimize false positives through temporal verification logic before triggering external alerts via a **REST API**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Key Configuration Parameters**\n",
    "The script uses several constants to define the sensitivity and behavior of the detection engine:\n",
    "* **Detection Threshold**: `CONF_THRESHOLD = 0.70` ensures that only detections with high AI confidence are processed.\n",
    "* **Temporal Filter**: `FRAME_COUNT_THRESHOLD = 3` requires fire to be detected in multiple consecutive frames to trigger an alert.\n",
    "* **Target Classes**: `FIRE_CLASS_IDS = [0, 1]` specifically monitors for indices representing 'smoke' and 'fire'.\n",
    "* **Integration Point**: `FASTAPI_SERVER_URL` defines the endpoint where validated alerts are dispatched.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core Logic & Implementation**\n",
    "\n",
    "#### **A. Stream Acquisition & Inference**\n",
    "The system captures video via `cv2.VideoCapture` and utilizes a generator-based inference (`stream=True`) with the **YOLOv8** model. This approach is optimized for memory efficiency during continuous real-time monitoring.\n",
    "\n",
    "#### **B. Verification Logic (The \"Counter\" Mechanism)**\n",
    "To ensure reliability, the script uses a non-persistent counter system:\n",
    "1. **Detection Check**: For every frame, the script iterates through detected bounding boxes.\n",
    "2. **Hit**: If a box matches the target class and exceeds the confidence threshold, `found_high_conf_fire` becomes `True`.\n",
    "3. **Persistence**:\n",
    "    * If **True**, the `fire_detection_counter` increments.\n",
    "    * If **False**, the counter immediately resets to `0` (enforcing *consecutive* detection).\n",
    "\n",
    "#### **C. Automated Alert Dispatch**\n",
    "Once the counter reaches the threshold (3 frames), the script uses the `requests` library to send an **HTTP POST request** to the backend server. \n",
    "* **Error Handling**: The script includes specific exceptions for `ConnectionError` to ensure the main loop doesn't crash if the alert server is offline.\n",
    "* **Spam Prevention**: The counter is reset immediately after a successful dispatch.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Operational Flowchart**\n",
    "\n",
    "\n",
    "\n",
    "1. **Input**: Connects to the camera/RTSP stream.\n",
    "2. **Process**: Runs YOLOv8 inference on each frame.\n",
    "3. **Logic**: Filters results by class ID and confidence.\n",
    "4. **Verify**: Tracks consecutive frames to confirm the event.\n",
    "5. **Action**: Dispatches a POST request and provides visual feedback via `cv2.imshow`.\n",
    "6. **Cleanup**: Properly releases hardware resources (camera) and closes windows on exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad874b32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests  # <-- ADDED FOR SENDING ALERTS\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "RTSP_URL = 0 # 0 for webcam, or your \"rtsp://...\" string\n",
    "MODEL_PATH = 'best.pt'\n",
    "CONF_THRESHOLD = 0.70\n",
    "FRAME_COUNT_THRESHOLD = 3\n",
    "FIRE_CLASS_IDS = [0, 1]  # 0='smoke', 1='fire'\n",
    "FASTAPI_SERVER_URL = \"http://127.0.0.1:8000/alert\"\n",
    "\n",
    "# --- 2. Initialization ---\n",
    "print(\"Loading model...\")\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "print(f\"Connecting to video stream ({RTSP_URL})...\")\n",
    "try:\n",
    "    cap = cv2.VideoCapture(RTSP_URL)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Cannot open video capture.\")\n",
    "    print(\"Video stream connected successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"--- ERROR: Failed to connect to video stream. ---\")\n",
    "    print(f\"--- If using a webcam, is it in use by another app? ---\")\n",
    "    print(f\"--- Error details: {e} ---\")\n",
    "    exit()\n",
    "\n",
    "fire_detection_counter = 0\n",
    "print(\"--- Starting fire detection loop (Press 'q' to quit) ---\")\n",
    "\n",
    "# --- 3. Main Processing Loop ---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Stream ended or error.\")\n",
    "        break\n",
    "\n",
    "    # --- 4. AI Model Inference ---\n",
    "    results = model(frame, stream=True, verbose=False)\n",
    "\n",
    "    found_high_conf_fire = False\n",
    "\n",
    "    # --- 5. Process Results (Apply Logic) ---\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            confidence = box.conf[0]\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            if class_id in FIRE_CLASS_IDS and confidence >= CONF_THRESHOLD:\n",
    "                found_high_conf_fire = True\n",
    "\n",
    "                # --- (Optional) Draw a box on the frame ---\n",
    "                # --- NEW, CORRECT LINE ---\n",
    "                x1, y1, x2, y2 = np.array(box.xyxy[0], dtype=int)\n",
    "                label = f\"{model.names[class_id]}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                break  # Only need one detection per frame\n",
    "\n",
    "    # --- 6. Implement \"3+ Frames\" Logic ---\n",
    "    if found_high_conf_fire:\n",
    "        fire_detection_counter += 1\n",
    "    else:\n",
    "        fire_detection_counter = 0  # Reset counter if no fire is found\n",
    "\n",
    "    # --- 7. Trigger Alert ---\n",
    "    if fire_detection_counter >= FRAME_COUNT_THRESHOLD:\n",
    "        print(f\"!!! ALERT: Fire detected for {fire_detection_counter} frames! Sending to server... !!!\")\n",
    "        try:\n",
    "            # Send an HTTP POST request to your FastAPI server\n",
    "            r = requests.post(FASTAPI_SERVER_URL)\n",
    "            r.raise_for_status()  # Raise an exception if the server returns an error\n",
    "            print(\"--- Alert successfully sent to server. ---\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"--- ERROR: Could not connect to FastAPI server. Is it running? ---\")\n",
    "        except Exception as e:\n",
    "            print(f\"--- ERROR: An unknown error occurred: {e} ---\")\n",
    "\n",
    "        # Reset counter after sending alert to avoid spamming\n",
    "        fire_detection_counter = 0\n",
    "\n",
    "    # --- (Optional) Display the video feed ---\n",
    "    cv2.imshow(\"Fire Detection Stream\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- 8. Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"--- Detection stopped. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ceb9ed",
   "metadata": {},
   "source": [
    "# Alert Server Overview: Multi-Channel Emergency Response\n",
    "\n",
    "This backend script acts as the **Alert Orchestration Layer** of the fire detection ecosystem. It transforms a technical detection signal into an actionable emergency response by simultaneously triggering three communication channels: **Email**, **SMS**, and **Voice Call**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Key Functional Components**\n",
    "\n",
    "* **FastAPI Endpoint (`/alert`)**: A high-performance REST API that listens for POST requests from the detection script. When triggered, it executes the notification cascade in parallel.\n",
    "* **Email Alerting (`smtplib`)**: Connects to Gmail‚Äôs SMTP server using **SSL/TLS** to send a high-priority alert to the specified administrator email.\n",
    "* **Twilio SMS Integration**: Utilizes the Twilio REST API to send an instantaneous text message alert to a verified mobile device.\n",
    "* **Twilio Voice Call (`make_voice_call`)**: Initiates an automated phone call that speaks the custom alert message defined in your **TwiML Bin**.\n",
    "    * **Auth Persistence**: The script specifically appends the `AccountSid` to the TwiML URL to ensure seamless authentication during the call request.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Technical Stack Mapping**\n",
    "\n",
    "| Feature | Technology | Role in Architecture |\n",
    "| :--- | :--- | :--- |\n",
    "| **API Framework** | **FastAPI** | Receives signals from the YOLOv8/NumPy logic stage. |\n",
    "| **Server** | **Uvicorn** | Manages the high-speed ASGI server environment. |\n",
    "| **Email Protocol** | **SMTP** | Handles secure transmission of emergency emails. |\n",
    "| **SMS/Voice** | **Twilio Client** | Manages external telephony and messaging gateways. |\n",
    "| **Security** | **python-dotenv** | Manages sensitive API keys and credentials securely. |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Operational Workflow**\n",
    "\n",
    "1.  **System Check**: On startup, the script validates that all five required environment variables (Gmail and Twilio secrets) are correctly loaded.\n",
    "2.  **Listening Mode**: The server waits at `http://127.0.0.1:8000/alert` for incoming signals from the 5G AI Camera pipeline.\n",
    "3.  **Trigger Activation**: Once the **YOLOv8 logic** confirms fire persistence, it sends a POST request to this server.\n",
    "4.  **Multi-Channel Dispatch**:\n",
    "    * **Email** is sent via Gmail's secure tunnel.\n",
    "    * **SMS** is dispatched via Twilio's messaging service.\n",
    "    * **Voice Call** is triggered using the TwiML Bin URL for audio instructions.\n",
    "5.  **Confirmation**: The server logs the SIDs of the sent alerts and returns a success status to the detection script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import smtplib\n",
    "import ssl\n",
    "import os\n",
    "from twilio.rest import Client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# --- Email Configuration ---\n",
    "SMTP_SERVER = \"smtp.gmail.com\"\n",
    "SMTP_PORT = 587\n",
    "SENDER_EMAIL = \"aaryanaggarwal2005@gmail.com\"\n",
    "RECEIVER_EMAIL = \"aaryanaggarwal.bt23ece@pec.edu.in\"\n",
    "\n",
    "# --- Twilio Configuration ---\n",
    "TO_PHONE_NUMBER = \"+919915840484\" # Phone number to alert\n",
    "\n",
    "# --- Load all secrets from environment variables ---\n",
    "EMAIL_PASSWORD = os.environ.get(\"GMAIL_APP_PASSWORD\")\n",
    "TWILIO_ACCOUNT_SID = os.environ.get(\"TWILIO_ACCOUNT_SID\")\n",
    "TWILIO_AUTH_TOKEN = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n",
    "TWILIO_PHONE_NUMBER = os.environ.get(\"TWILIO_PHONE_NUMBER\")\n",
    "TWIML_BIN_URL = os.environ.get(\"TWIML_BIN_URL\")  # <-- 1. ADD NEW VARIABLE\n",
    "# --------------------------------------------------\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# (Your send_email() function stays here, unchanged)\n",
    "def send_email():\n",
    "    if not EMAIL_PASSWORD:\n",
    "        print(\"--- ERROR: Cannot send email. Password is not set. ---\")\n",
    "        return\n",
    "    # ... (rest of your email code is here) ...\n",
    "    message = \"\"\"\\\n",
    "Subject: !!! FIRE ALERT DETECTED !!!\n",
    "\n",
    "A fire or smoke event has been confirmed by the AI detection system.\n",
    "Please check the cameras immediately.\n",
    "\"\"\"\n",
    "    context = ssl.create_default_context()\n",
    "    print(\"--- Connecting to Gmail server to send alert... ---\")\n",
    "    try:\n",
    "        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
    "        server.starttls(context=context)\n",
    "        server.login(SENDER_EMAIL, EMAIL_PASSWORD)\n",
    "        server.sendmail(SENDER_EMAIL, RECEIVER_EMAIL, message)\n",
    "        server.quit()\n",
    "        print(\"--- Email alert successfully sent! ---\")\n",
    "    except smtplib.SMTPException as e:\n",
    "        print(f\"--- ERROR: Failed to send email: {e} ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"--- An unexpected error occurred: {e} ---\")\n",
    "\n",
    "\n",
    "# (Your send_sms() function stays here, unchanged)\n",
    "def send_sms():\n",
    "    if not all([TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER]):\n",
    "        print(\"--- ERROR: Twilio credentials not set. Cannot send SMS. ---\")\n",
    "        return\n",
    "    # ... (rest of your SMS code is here) ...\n",
    "    print(\"--- Connecting to Twilio to send SMS... ---\")\n",
    "    try:\n",
    "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "        message = client.messages.create(\n",
    "            body=\"!!! FIRE ALERT DETECTED !!! Check cameras immediately.\",\n",
    "            from_=TWILIO_PHONE_NUMBER,\n",
    "            to=TO_PHONE_NUMBER\n",
    "        )\n",
    "        print(f\"--- SMS alert successfully sent! (SID: {message.sid}) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"--- ERROR: Failed to send SMS: {e} ---\")\n",
    "\n",
    "\n",
    "# --- 2. ADD NEW MAKE_VOICE_CALL FUNCTION ---\n",
    "def make_voice_call():\n",
    "    \"\"\"\n",
    "    Uses Twilio to make an automated voice call.\n",
    "    \"\"\"\n",
    "    if not all([TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER, TWIML_BIN_URL]):\n",
    "        print(\"--- ERROR: Twilio credentials or TwiML URL not set. Cannot make call. ---\")\n",
    "        return\n",
    "\n",
    "    print(\"--- Connecting to Twilio to make voice call... ---\")\n",
    "    try:\n",
    "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "        \n",
    "        # Add AccountSid as query parameter to TwiML Bin URL\n",
    "        twiml_url_with_auth = f\"{TWIML_BIN_URL}?AccountSid={TWILIO_ACCOUNT_SID}\"\n",
    "        \n",
    "        call = client.calls.create(\n",
    "            url=twiml_url_with_auth,  # <-- Tells Twilio what to say\n",
    "            from_=TWILIO_PHONE_NUMBER,\n",
    "            to=TO_PHONE_NUMBER\n",
    "        )\n",
    "        print(f\"--- Voice call initiated! (SID: {call.sid}) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"--- ERROR: Failed to make voice call: {e} ---\")\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "@app.post(\"/alert\")\n",
    "async def receive_alert():\n",
    "    \"\"\"\n",
    "    This endpoint triggers email, SMS, and a voice call.\n",
    "    \"\"\"\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"!!! ALERT RECEIVED FROM DETECTION SCRIPT !!!\")\n",
    "    print(\"--- Fire or smoke has been confirmed. ---\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    # --- 3. CALL ALL THREE FUNCTIONS ---\n",
    "    send_email()\n",
    "    send_sms()\n",
    "    make_voice_call()\n",
    "    # ---------------------------------\n",
    "    \n",
    "    return {\"status\": \"alert received, notifications triggered\"}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not all([EMAIL_PASSWORD, TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER, TWIML_BIN_URL]):\n",
    "        print(\"--- WARNING: One or more environment variables are missing! ---\")\n",
    "        print(\"--- Please set all 5 variables: GMAIL, TWILIO_SID, TWILIO_TOKEN, TWILIO_PHONE, and TWIML_BIN_URL ---\")\n",
    "\n",
    "    print(\"Starting FastAPI server on http://127.0.0.1:8000\")\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b17cff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üë®‚Äçüíª About Labellerr's Hands-On Learning in Computer Vision\n",
    "\n",
    "Thank you for exploring this **Labellerr Hands-On Computer Vision Cookbook**! We hope this notebook helped you learn, prototype, and accelerate your vision projects.  \n",
    "Labellerr provides ready-to-run Jupyter/Colab notebooks for the latest models and real-world use cases in computer vision, AI agents, and data annotation.\n",
    "\n",
    "---\n",
    "## üßë‚Äçüî¨ Check Our Popular Youtube Videos\n",
    "\n",
    "Whether you're a beginner or a practitioner, our hands-on training videos are perfect for learning custom model building, computer vision techniques, and applied AI:\n",
    "\n",
    "- [How to Fine-Tune YOLO on Custom Dataset](https://www.youtube.com/watch?v=pBLWOe01QXU)  \n",
    "  Step-by-step guide to fine-tuning YOLO for real-world use‚Äîenvironment setup, annotation, training, validation, and inference.\n",
    "- [Build a Real-Time Intrusion Detection System with YOLO](https://www.youtube.com/watch?v=kwQeokYDVcE)  \n",
    "  Create an AI-powered system to detect intruders in real time using YOLO and computer vision.\n",
    "- [Finding Athlete Speed Using YOLO](https://www.youtube.com/watch?v=txW0CQe_pw0)  \n",
    "  Estimate real-time speed of athletes for sports analytics.\n",
    "- [Object Counting Using AI](https://www.youtube.com/watch?v=smsjBBQcIUQ)  \n",
    "  Learn dataset curation, annotation, and training for robust object counting AI applications.\n",
    "---\n",
    "\n",
    "## üé¶ Popular Labellerr YouTube Videos\n",
    "\n",
    "Level up your skills and see video walkthroughs of these tools and notebooks on the  \n",
    "[Labellerr YouTube Channel](https://www.youtube.com/@Labellerr/videos):\n",
    "\n",
    "- [How I Fixed My Biggest Annotation Nightmare with Labellerr](https://www.youtube.com/watch?v=hlcFdiuz_HI) ‚Äì Solving complex annotation for ML engineers.\n",
    "- [Explore Your Dataset with Labellerr's AI](https://www.youtube.com/watch?v=LdbRXYWVyN0) ‚Äì Auto-tagging, object counting, image descriptions, and dataset exploration.\n",
    "- [Boost AI Image Annotation 10X with Labellerr's CLIP Mode](https://www.youtube.com/watch?v=pY_o4EvYMz8) ‚Äì Refine annotations with precision using CLIP mode.\n",
    "- [Boost Data Annotation Accuracy and Efficiency with Active Learning](https://www.youtube.com/watch?v=lAYu-ewIhTE) ‚Äì Speed up your annotation workflow using Active Learning.\n",
    "\n",
    "> üëâ **Subscribe** for Labellerr's deep learning, annotation, and AI tutorials, or watch videos directly alongside notebooks!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Stay Connected\n",
    "\n",
    "- **Website:** [https://www.labellerr.com/](https://www.labellerr.com/)\n",
    "- **Blog:** [https://www.labellerr.com/blog/](https://www.labellerr.com/blog/)\n",
    "- **GitHub:** [Labellerr/Hands-On-Learning-in-Computer-Vision](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "- **LinkedIn:** [Labellerr](https://in.linkedin.com/company/labellerr)\n",
    "- **Twitter/X:** [@Labellerr1](https://x.com/Labellerr1)\n",
    "\n",
    "*Happy learning and building with Labellerr!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a4a7b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
