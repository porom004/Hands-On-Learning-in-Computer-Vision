{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0556d854",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **YOLO vs RT-DETR Video Detection Comparison Notebook**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e51e5",
   "metadata": {},
   "source": [
    "This notebook compares the performance of the YOLO (You Only Look Once) and RT-DETR (Real-Time Detection Transformer) models for object detection on video data.\n",
    "\n",
    "**Main Objectives:**\n",
    "- Demonstrate installation and setup for Ultralyics YOLO and RT-DETR with all required dependencies.\n",
    "- Define configuration classes and settings for both models.\n",
    "- Implement a class-based workflow (`VideoDetectionComparator`) to:\n",
    "  - Run both models on video frames side-by-side.\n",
    "  - Collect metrics such as inference time, detection counts, and confidence scores.\n",
    "  - Save annotated output videos for each model.\n",
    "  - Generate performance reports and visualizations (plots) comparing both models.\n",
    "\n",
    "**Features:**\n",
    "- Supports large and extra-large variants of YOLO and RT-DETR models.\n",
    "- Processes videos frame by frame and aggregates accuracy and speed metrics.\n",
    "- Produces comparison tables, summary statistics (FPS, detections/frame, confidence), and visualization charts.\n",
    "- Includes usage examples and test cases for quick validation.\n",
    "\n",
    "**Intended Use:**\n",
    "- Benchmark and analyze trade-offs between speed and accuracy for YOLO vs RT-DETR on real video data.\n",
    "- Help computer vision practitioners select optimal models for deployment in applications requiring efficient and accurate object detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048a5f7",
   "metadata": {},
   "source": [
    "## Installation & Setup\n",
    "\n",
    "This section provides installation commands to set up the required packages for running YOLO and RT-DETR model comparisons. Ensure these commands are run in your terminal before executing other notebook cells.\n",
    "- Installs: ultralytics, opencv-python, pandas, matplotlib, seaborn, numpy, torch, torchvision (CPU/GPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08692b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: INSTALLATION & SETUP\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "# Installation Commands (run in terminal):\n",
    "\n",
    "pip install ultralytics  # For both YOLO and RT-DETR\n",
    "pip install opencv-python\n",
    "pip install pandas\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install numpy\n",
    "pip install torch torchvision  # PyTorch (if not already installed)\n",
    "\n",
    "# For GPU support:\n",
    "# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f676d2f",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Imports all necessary Python libraries for video processing, model inference, visualization, and file handling.\n",
    "Included:\n",
    "- OpenCV for video I/O\n",
    "- Core libraries (time, json)\n",
    "- pandas, numpy, seaborn, matplotlib for data analysis and visualization\n",
    "- Ultralytics YOLO and RT-DETR models\n",
    "- Pathlib for path management\n",
    "- Defaultdict for results storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454da2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO, RTDETR\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ae3c7",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "Defines the configuration class for YOLO and RT-DETR models.\n",
    "- Specifies available model variants (large, extra large)\n",
    "- Sets default parameters for confidence and IoU thresholds used in comparison tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdda948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3: MODEL CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for YOLO and RT-DETR models\"\"\"\n",
    "    \n",
    "    # Available YOLO models\n",
    "    YOLO_MODELS = {\n",
    "        'yolov8l': 'yolov8l.pt',  # Large\n",
    "        'yolov8x': 'yolov8x.pt',  # Extra Large\n",
    "    }\n",
    "    \n",
    "    # Available RT-DETR models\n",
    "    RTDETR_MODELS = {\n",
    "        'rtdetr-l': 'rtdetr-l.pt',  # Large\n",
    "        'rtdetr-x': 'rtdetr-x.pt',  # Extra Large\n",
    "    }\n",
    "    \n",
    "    # Default test parameters\n",
    "    DEFAULT_CONF = 0.25  # Confidence threshold\n",
    "    DEFAULT_IOU = 0.45   # IoU threshold for NMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9249f",
   "metadata": {},
   "source": [
    "## Video Processing & Comparison\n",
    "\n",
    "Implements the `VideoDetectionComparator` class for frame-by-frame inference and metric tracking.\n",
    "- Initializes YOLO and RT-DETR models\n",
    "- Processes individual frames for detection\n",
    "- Annotates and saves outputs\n",
    "- Aggregates detection results and timing metrics\n",
    "- Main function for comparing two models across all video frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b38415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 4: VIDEO PROCESSOR CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class VideoDetectionComparator:\n",
    "    \"\"\"Main class for comparing YOLO and RT-DETR on videos\"\"\"\n",
    "    \n",
    "    def __init__(self, yolo_model='yolov8l', rtdetr_model='rtdetr-l', \n",
    "                 conf_threshold=0.25, iou_threshold=0.45):\n",
    "        \"\"\"\n",
    "        Initialize models for comparison\n",
    "        \n",
    "        Args:\n",
    "            yolo_model: YOLO model variant\n",
    "            rtdetr_model: RT-DETR model variant\n",
    "            conf_threshold: Confidence threshold for detections\n",
    "            iou_threshold: IoU threshold for NMS\n",
    "        \"\"\"\n",
    "        print(f\"Loading {yolo_model}...\")\n",
    "        self.yolo = YOLO(ModelConfig.YOLO_MODELS[yolo_model])\n",
    "        \n",
    "        print(f\"Loading {rtdetr_model}...\")\n",
    "        self.rtdetr = RTDETR(ModelConfig.RTDETR_MODELS[rtdetr_model])\n",
    "        \n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        \n",
    "        self.yolo_name = yolo_model\n",
    "        self.rtdetr_name = rtdetr_model\n",
    "        \n",
    "        # Metrics storage\n",
    "        self.results = {\n",
    "            'yolo': defaultdict(list),\n",
    "            'rtdetr': defaultdict(list)\n",
    "        }\n",
    "    \n",
    "    def process_frame(self, frame, model, model_type):\n",
    "        \"\"\"Process a single frame with given model\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = model(frame, conf=self.conf_threshold, \n",
    "                       iou=self.iou_threshold, verbose=False, show_labels=False)[0]\n",
    "        \n",
    "        inference_time = (time.time() - start_time) * 1000  # ms\n",
    "        \n",
    "        # Extract metrics\n",
    "        boxes = results.boxes\n",
    "        num_detections = len(boxes)\n",
    "        confidences = boxes.conf.cpu().numpy() if num_detections > 0 else []\n",
    "        classes = boxes.cls.cpu().numpy() if num_detections > 0 else []\n",
    "        \n",
    "        return {\n",
    "            'inference_time': inference_time,\n",
    "            'num_detections': num_detections,\n",
    "            'confidences': confidences,\n",
    "            'classes': classes,\n",
    "            'boxes': boxes,\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    def process_video(self, video_path, output_dir='outputs', \n",
    "                     save_videos=True, max_frames=None):\n",
    "        \"\"\"\n",
    "        Process video with both models and compare\n",
    "        \n",
    "        Args:\n",
    "            video_path: Path to input video\n",
    "            output_dir: Directory to save outputs\n",
    "            save_videos: Whether to save annotated videos\n",
    "            max_frames: Maximum frames to process (None for all)\n",
    "        \"\"\"\n",
    "        video_path = Path(video_path)\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {video_path.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        if max_frames:\n",
    "            total_frames = min(total_frames, max_frames)\n",
    "        \n",
    "        print(f\"Video specs: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "        \n",
    "        # Setup video writers\n",
    "        if save_videos:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            yolo_out = cv2.VideoWriter(\n",
    "                str(output_dir / f'{video_path.stem}_yolo.mp4'),\n",
    "                fourcc, fps, (width, height)\n",
    "            )\n",
    "            rtdetr_out = cv2.VideoWriter(\n",
    "                str(output_dir / f'{video_path.stem}_rtdetr.mp4'),\n",
    "                fourcc, fps, (width, height)\n",
    "            )\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        while cap.isOpened() and (max_frames is None or frame_count < max_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process with YOLO\n",
    "            yolo_result = self.process_frame(frame, self.yolo, 'yolo')\n",
    "            self.results['yolo']['inference_time'].append(yolo_result['inference_time'])\n",
    "            self.results['yolo']['num_detections'].append(yolo_result['num_detections'])\n",
    "            self.results['yolo']['confidences'].extend(yolo_result['confidences'])\n",
    "            \n",
    "            # Process with RT-DETR\n",
    "            rtdetr_result = self.process_frame(frame, self.rtdetr, 'rtdetr')\n",
    "            self.results['rtdetr']['inference_time'].append(rtdetr_result['inference_time'])\n",
    "            self.results['rtdetr']['num_detections'].append(rtdetr_result['num_detections'])\n",
    "            self.results['rtdetr']['confidences'].extend(rtdetr_result['confidences'])\n",
    "            \n",
    "            # Save annotated frames\n",
    "            if save_videos:\n",
    "                yolo_frame = yolo_result['results'].plot()\n",
    "                rtdetr_frame = rtdetr_result['results'].plot()\n",
    "                \n",
    "                yolo_out.write(yolo_frame)\n",
    "                rtdetr_out.write(rtdetr_frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"Processed {frame_count}/{total_frames} frames...\", end='\\r')\n",
    "        \n",
    "        cap.release()\n",
    "        if save_videos:\n",
    "            yolo_out.release()\n",
    "            rtdetr_out.release()\n",
    "        \n",
    "        print(f\"\\n✓ Completed processing {frame_count} frames\")\n",
    "        \n",
    "        # Generate comparison report\n",
    "        self._generate_report(video_path.stem, output_dir)\n",
    "    \n",
    "    def _generate_report(self, video_name, output_dir):\n",
    "        \"\"\"Generate comparison metrics and visualizations\"\"\"\n",
    "        print(\"\\nGenerating comparison report...\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {}\n",
    "        for model_name in ['yolo', 'rtdetr']:\n",
    "            inf_times = self.results[model_name]['inference_time']\n",
    "            detections = self.results[model_name]['num_detections']\n",
    "            confidences = self.results[model_name]['confidences']\n",
    "            \n",
    "            stats[model_name] = {\n",
    "                'avg_inference_time': float(np.mean(inf_times)),\n",
    "                'std_inference_time': float(np.std(inf_times)),\n",
    "                'min_inference_time': float(np.min(inf_times)),\n",
    "                'max_inference_time': float(np.max(inf_times)),\n",
    "                'avg_fps': float(1000 / np.mean(inf_times)),\n",
    "                'avg_detections': float(np.mean(detections)),\n",
    "                'total_detections': int(np.sum(detections)),\n",
    "                'avg_confidence': float(np.mean(confidences)) if len(confidences) > 0 else 0.0,\n",
    "            }\n",
    "        \n",
    "        # Print comparison table\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"COMPARISON RESULTS: {video_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"\\n{'Metric':<30} {'YOLO':<15} {'RT-DETR':<15}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "        \n",
    "        metrics_display = [\n",
    "            ('Avg Inference Time (ms)', 'avg_inference_time'),\n",
    "            ('Std Inference Time (ms)', 'std_inference_time'),\n",
    "            ('Average FPS', 'avg_fps'),\n",
    "            ('Avg Detections/Frame', 'avg_detections'),\n",
    "            ('Total Detections', 'total_detections'),\n",
    "            ('Avg Confidence', 'avg_confidence'),\n",
    "        ]\n",
    "        \n",
    "        for label, key in metrics_display:\n",
    "            yolo_val = stats['yolo'][key]\n",
    "            rtdetr_val = stats['rtdetr'][key]\n",
    "            print(f\"{label:<30} {yolo_val:<15.2f} {rtdetr_val:<15.2f}\")\n",
    "        \n",
    "        # Save statistics to JSON\n",
    "        stats_file = output_dir / f'{video_name}_stats.json'\n",
    "        with open(stats_file, 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        print(f\"\\n✓ Statistics saved to: {stats_file}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        self._create_visualizations(video_name, output_dir, stats)\n",
    "    \n",
    "    def _create_visualizations(self, video_name, output_dir, stats):\n",
    "        \"\"\"Create comparison visualizations\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'YOLO vs RT-DETR Comparison: {video_name}', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Inference Time Distribution\n",
    "        ax1 = axes[0, 0]\n",
    "        yolo_times = self.results['yolo']['inference_time']\n",
    "        rtdetr_times = self.results['rtdetr']['inference_time']\n",
    "        \n",
    "        ax1.hist(yolo_times, bins=50, alpha=0.6, label=f'YOLO ({self.yolo_name})', \n",
    "                color='blue', edgecolor='black')\n",
    "        ax1.hist(rtdetr_times, bins=50, alpha=0.6, label=f'RT-DETR ({self.rtdetr_name})', \n",
    "                color='red', edgecolor='black')\n",
    "        ax1.set_xlabel('Inference Time (ms)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Inference Time Distribution')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Inference Time Over Frames\n",
    "        ax2 = axes[0, 1]\n",
    "        frames = range(len(yolo_times))\n",
    "        ax2.plot(frames, yolo_times, alpha=0.7, label=f'YOLO ({self.yolo_name})', \n",
    "                linewidth=1, color='blue')\n",
    "        ax2.plot(frames, rtdetr_times, alpha=0.7, label=f'RT-DETR ({self.rtdetr_name})', \n",
    "                linewidth=1, color='red')\n",
    "        ax2.set_xlabel('Frame Number')\n",
    "        ax2.set_ylabel('Inference Time (ms)')\n",
    "        ax2.set_title('Inference Time Over Frames')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Detections Per Frame\n",
    "        ax3 = axes[1, 0]\n",
    "        yolo_dets = self.results['yolo']['num_detections']\n",
    "        rtdetr_dets = self.results['rtdetr']['num_detections']\n",
    "        \n",
    "        ax3.plot(frames, yolo_dets, alpha=0.7, label=f'YOLO ({self.yolo_name})', \n",
    "                linewidth=1.5, color='blue')\n",
    "        ax3.plot(frames, rtdetr_dets, alpha=0.7, label=f'RT-DETR ({self.rtdetr_name})', \n",
    "                linewidth=1.5, color='red')\n",
    "        ax3.set_xlabel('Frame Number')\n",
    "        ax3.set_ylabel('Number of Detections')\n",
    "        ax3.set_title('Detections Per Frame')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Performance Metrics Comparison\n",
    "        ax4 = axes[1, 1]\n",
    "        metrics = ['Avg FPS', 'Avg Detections', 'Avg Confidence']\n",
    "        yolo_values = [\n",
    "            stats['yolo']['avg_fps'],\n",
    "            stats['yolo']['avg_detections'],\n",
    "            stats['yolo']['avg_confidence'] * 100  # Scale to 0-100\n",
    "        ]\n",
    "        rtdetr_values = [\n",
    "            stats['rtdetr']['avg_fps'],\n",
    "            stats['rtdetr']['avg_detections'],\n",
    "            stats['rtdetr']['avg_confidence'] * 100\n",
    "        ]\n",
    "        \n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax4.bar(x - width/2, yolo_values, width, label=f'YOLO ({self.yolo_name})', \n",
    "               color='blue', alpha=0.8)\n",
    "        ax4.bar(x + width/2, rtdetr_values, width, label=f'RT-DETR ({self.rtdetr_name})', \n",
    "               color='red', alpha=0.8)\n",
    "        \n",
    "        ax4.set_ylabel('Value')\n",
    "        ax4.set_title('Performance Metrics Comparison')\n",
    "        ax4.set_xticks(x)\n",
    "        ax4.set_xticklabels(metrics)\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (y_val, r_val) in enumerate(zip(yolo_values, rtdetr_values)):\n",
    "            ax4.text(i - width/2, y_val, f'{y_val:.1f}', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "            ax4.text(i + width/2, r_val, f'{r_val:.1f}', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_file = output_dir / f'{video_name}_comparison.png'\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"✓ Visualizations saved to: {plot_file}\")\n",
    "    \n",
    "    def reset_results(self):\n",
    "        \"\"\"Reset results for processing a new video\"\"\"\n",
    "        self.results = {\n",
    "            'yolo': defaultdict(list),\n",
    "            'rtdetr': defaultdict(list)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152c289",
   "metadata": {},
   "source": [
    "## Test Cases & Usage Examples\n",
    "\n",
    "Demonstrates how to use the `VideoDetectionComparator` for model comparisons on sample input videos.\n",
    "- `test_case_single_video()` compares the inference and detection counts for YOLO vs RT-DETR for one video file.\n",
    "- Outputs annotated videos and saves metrics/statistics.\n",
    "Run this as the main workflow to validate your setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9de10c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST CASE 1: Single Video Comparison\n",
      "============================================================\n",
      "Loading yolov8l...\n",
      "Loading rtdetr-l...\n",
      "\n",
      "============================================================\n",
      "Processing: sample_1.mp4\n",
      "============================================================\n",
      "Video specs: 1280x720 @ 29fps, 471 frames\n",
      "Processed 450/471 frames...\n",
      "✓ Completed processing 471 frames\n",
      "\n",
      "Generating comparison report...\n",
      "\n",
      "============================================================\n",
      "COMPARISON RESULTS: sample_1\n",
      "============================================================\n",
      "\n",
      "Metric                         YOLO            RT-DETR        \n",
      "------------------------------------------------------------\n",
      "Avg Inference Time (ms)        32.50           33.59          \n",
      "Std Inference Time (ms)        44.61           27.82          \n",
      "Average FPS                    30.77           29.77          \n",
      "Avg Detections/Frame           22.39           38.42          \n",
      "Total Detections               10546.00        18095.00       \n",
      "Avg Confidence                 0.63            0.54           \n",
      "\n",
      "✓ Statistics saved to: outputs\\test1_model-l\\sample_1_stats.json\n",
      "✓ Visualizations saved to: outputs\\test1_model-l\\sample_1_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 5: TEST CASES & USAGE EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "def test_case_single_video():\n",
    "    \"\"\"Test Case 1: Single video comparison with default models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST CASE 1: Single Video Comparison\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparator = VideoDetectionComparator(\n",
    "        yolo_model='yolov8l',\n",
    "        rtdetr_model='rtdetr-l',\n",
    "        conf_threshold=0.25\n",
    "    )\n",
    "    \n",
    "    # Process video\n",
    "    comparator.process_video(\n",
    "        video_path='sample_1.mp4',\n",
    "        output_dir='outputs/test1_model-l',\n",
    "        save_videos=True,\n",
    "        max_frames=None  # Process all frames\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_case_single_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2f26d",
   "metadata": {},
   "source": [
    "## Test Case: Extra Large Models\n",
    "\n",
    "Compares YOLOv8x with RT-DETR-x using the same workflow as above.\n",
    "- Switches to the \"extra large\" variants for an alternate performance baseline.\n",
    "- Processes the same video and saves to a different output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a925c916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST CASE 1: Single Video Comparison\n",
      "============================================================\n",
      "Loading yolov8x...\n",
      "Loading rtdetr-x...\n",
      "\n",
      "============================================================\n",
      "Processing: sample_2.mp4\n",
      "============================================================\n",
      "Video specs: 1920x1080 @ 29fps, 518 frames\n",
      "Processed 510/518 frames...\n",
      "✓ Completed processing 518 frames\n",
      "\n",
      "Generating comparison report...\n",
      "\n",
      "============================================================\n",
      "COMPARISON RESULTS: sample_2\n",
      "============================================================\n",
      "\n",
      "Metric                         YOLO            RT-DETR        \n",
      "------------------------------------------------------------\n",
      "Avg Inference Time (ms)        43.91           40.00          \n",
      "Std Inference Time (ms)        44.17           41.67          \n",
      "Average FPS                    22.77           25.00          \n",
      "Avg Detections/Frame           30.44           53.47          \n",
      "Total Detections               15769.00        27699.00       \n",
      "Avg Confidence                 0.55            0.48           \n",
      "\n",
      "✓ Statistics saved to: outputs\\test1-2_model-x\\sample_2_stats.json\n",
      "✓ Visualizations saved to: outputs\\test1-2_model-x\\sample_2_comparison.png\n"
     ]
    }
   ],
   "source": [
    "def test_case_single_video():\n",
    "    \"\"\"Test Case 1: Single video comparison with default models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST CASE 1: Single Video Comparison\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparator = VideoDetectionComparator(\n",
    "        yolo_model='yolov8x',\n",
    "        rtdetr_model='rtdetr-x',\n",
    "        conf_threshold=0.25\n",
    "    )\n",
    "    \n",
    "    # Process video\n",
    "    comparator.process_video(\n",
    "        video_path='sample_2.mp4',\n",
    "        output_dir='outputs/test1-2_model-x',\n",
    "        save_videos=True,\n",
    "        max_frames=None  # Process all frames\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_case_single_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
