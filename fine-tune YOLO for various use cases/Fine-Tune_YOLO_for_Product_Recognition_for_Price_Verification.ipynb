{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb52261d",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fine-Tune YOLO for Product Recognition for Price Verification**\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "\n",
    "## üéØ Objective\n",
    "\n",
    "This notebook demonstrates how to build an automated checkout system by fine-tuning a YOLOv8 model for retail product recognition. The goal is to detect products in an image, categorize them, count them, and calculate a total price, simulating a real-world smart retail solution.\n",
    "\n",
    "\n",
    "## üöÄ Key Features\n",
    "\n",
    "* **Data Preparation**: A self-contained function to convert COCO annotations to the required YOLO format.\n",
    "* **Model Training**: Fine-tuning a pre-trained YOLOv8 model on a custom retail product dataset.\n",
    "* **Product Categorization**: Grouping specific product classes into broader \"superclasses\" for easier management.\n",
    "* **Automated Counting & Billing**: Functions to count detected products by category and calculate a final bill based on pre-defined prices.\n",
    "\n",
    "\n",
    "## üìö Libraries & Prerequisites\n",
    "\n",
    "* **Core Libraries**: `ultralytics`, `opencv-python`, `matplotlib`, `pyyaml`.\n",
    "* **Environment**: A Python environment with GPU support is highly recommended for model training.\n",
    "* **Dataset**: A dataset of retail products with annotations in COCO format. The notebook is configured for the \"Retail Product Checkout Dataset\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a7dab",
   "metadata": {},
   "source": [
    "## **Dataset Creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3d20",
   "metadata": {},
   "source": [
    "We begin by preparing the dataset. The initial code for downloading from Kaggle is commented out. The core of this step is the `convert_coco_to_yolo_flat` function, which handles the critical task of converting COCO annotations into the flat YOLO format required for training. This function also creates the necessary `data.yaml` configuration file for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76de763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"diyer22/retail-product-checkout-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "\n",
    "def convert_coco_to_yolo_flat(\n",
    "    json_path: str,\n",
    "    images_dir: str,\n",
    "    output_dir: str,\n",
    "    max_images: int = None,\n",
    "    seed: int = 42,\n",
    "    split: bool = True,\n",
    "    train_ratio: float = 0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a COCO-like JSON file to flat YOLO detection format with bounding\n",
    "    boxes, optional train/val split, and generate both data.yaml and classes.json.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load JSON data\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images      = data['images']\n",
    "    annotations = data['annotations']\n",
    "    categories  = data['categories']\n",
    "\n",
    "    # Build robust category-id ‚Üí name map\n",
    "    cat_id_to_name = {c['id']: c['name'] for c in categories}\n",
    "    all_ann_ids    = {ann['category_id'] for ann in annotations}\n",
    "    # fallback for any missing\n",
    "    for missing in all_ann_ids - cat_id_to_name.keys():\n",
    "        cat_id_to_name[missing] = f\"class_{missing}\"\n",
    "    sorted_cat_ids = sorted(cat_id_to_name.keys())\n",
    "    # contiguous 0-based mapping\n",
    "    cat_id_map     = {cid: idx for idx, cid in enumerate(sorted_cat_ids)}\n",
    "    class_names    = [cat_id_to_name[cid] for cid in sorted_cat_ids]\n",
    "    num_classes    = len(class_names)\n",
    "\n",
    "    # Group annotations by image\n",
    "    ann_by_image = defaultdict(list)\n",
    "    for ann in annotations:\n",
    "        ann_by_image[ann['image_id']].append(ann)\n",
    "\n",
    "    # Optional max_images sampling evenly across classes\n",
    "    if max_images:\n",
    "        images_by_class = defaultdict(list)\n",
    "        for img in images:\n",
    "            for ann in ann_by_image.get(img['id'], []):\n",
    "                images_by_class[ann['category_id']].append(img)\n",
    "        per_class   = max_images // num_classes\n",
    "        selected_ids = set()\n",
    "        for cid in sorted_cat_ids:\n",
    "            cands = images_by_class.get(cid, [])\n",
    "            if cands:\n",
    "                pick = random.sample(cands, min(per_class, len(cands)))\n",
    "                selected_ids |= {img['id'] for img in pick}\n",
    "        remaining = max_images - len(selected_ids)\n",
    "        if remaining > 0:\n",
    "            others = [img for img in images if img['id'] not in selected_ids]\n",
    "            extra  = random.sample(others, min(remaining, len(others)))\n",
    "            selected_ids |= {img['id'] for img in extra}\n",
    "        images = [img for img in images if img['id'] in selected_ids]\n",
    "\n",
    "    # Split into subsets\n",
    "    if split:\n",
    "        random.shuffle(images)\n",
    "        n_train = int(len(images) * train_ratio)\n",
    "        subsets = {'train': images[:n_train], 'val': images[n_train:]}\n",
    "    else:\n",
    "        subsets = {'all': images}\n",
    "\n",
    "    # Prepare directories\n",
    "    for subset in subsets:\n",
    "        img_out = os.path.join(output_dir, 'images', subset) if split else os.path.join(output_dir, 'images')\n",
    "        lbl_out = os.path.join(output_dir, 'labels', subset) if split else os.path.join(output_dir, 'labels')\n",
    "        os.makedirs(img_out, exist_ok=True)\n",
    "        os.makedirs(lbl_out, exist_ok=True)\n",
    "\n",
    "    # Helper to normalize\n",
    "    def norm(x, m): return x / m\n",
    "\n",
    "    # Process images & write YOLO bbox labels\n",
    "    for subset, imgs in subsets.items():\n",
    "        img_out = os.path.join(output_dir, 'images', subset) if split else os.path.join(output_dir, 'images')\n",
    "        lbl_out = os.path.join(output_dir, 'labels', subset) if split else os.path.join(output_dir, 'labels')\n",
    "        for img in imgs:\n",
    "            src_img = os.path.join(images_dir, img['file_name'])\n",
    "            dst_img = os.path.join(img_out, os.path.basename(img['file_name']))\n",
    "            if not os.path.exists(src_img):\n",
    "                print(f\"Warning: {src_img} does not exist\")\n",
    "                continue\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            w, h = img['width'], img['height']\n",
    "            lines = []\n",
    "            for ann in ann_by_image.get(img['id'], []):\n",
    "                cid = ann['category_id']\n",
    "                cls_idx = cat_id_map[cid]\n",
    "                bbox = ann.get('bbox', None)\n",
    "                if not bbox or len(bbox) != 4:\n",
    "                    continue\n",
    "                x_min, y_min, bw, bh = bbox\n",
    "                xc = (x_min + bw/2) / w\n",
    "                yc = (y_min + bh/2) / h\n",
    "                lines.append(f\"{cls_idx} {xc:.6f} {yc:.6f} {bw/w:.6f} {bh/h:.6f}\")\n",
    "            # write label file\n",
    "            label_path = os.path.join(lbl_out, os.path.splitext(os.path.basename(img['file_name']))[0] + '.txt')\n",
    "            with open(label_path, 'w', encoding='utf-8') as lf:\n",
    "                lf.write(\"\\n\".join(lines))\n",
    "\n",
    "    # Write data.yaml\n",
    "    data_yaml = {\n",
    "    'path': output_dir,\n",
    "    'train': 'images/train' if split else 'images',\n",
    "    'val':   'images/val'   if split else 'images',\n",
    "    'nc':    num_classes,\n",
    "    # Instead of a list, build a dict of index ‚Üí class name\n",
    "    'names': {idx: name for idx, name in enumerate(class_names)}\n",
    "}\n",
    "    with open(os.path.join(output_dir, 'data.yaml'), 'w', encoding='utf-8') as yf:\n",
    "        yaml.dump(data_yaml, yf, sort_keys=False)\n",
    "\n",
    "    # Write classes.json\n",
    "    classes_json = {'names': class_names}\n",
    "    with open(os.path.join(output_dir, 'classes.json'), 'w', encoding='utf-8') as jf:\n",
    "        json.dump(classes_json, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "    total = sum(len(imgs) for imgs in subsets.values())\n",
    "    print(f\"Conversion complete: {total} images\")\n",
    "    print(f\"data.yaml at {os.path.join(output_dir, 'data.yaml')}\")\n",
    "    print(f\"classes.json at {os.path.join(output_dir, 'classes.json')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolo_flat(\n",
    "    json_path = r\"archive\\instances_train2019.json\" ,\n",
    "    images_dir = r\"archive\\train2019\",\n",
    "    output_dir = \"yolo_train_format\",\n",
    "    max_images = 5000,\n",
    "    split = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67281156",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173edff5",
   "metadata": {},
   "source": [
    "With the dataset correctly formatted, we proceed to train the YOLOv8 model. We load a pre-trained `yolov8x.pt` checkpoint to leverage transfer learning and then fine-tune it on our custom product dataset for 100 epochs using the `data.yaml` file created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375eebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"yolo_train_format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512836f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\")  # Use .pt suffix for weights\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f\"{dataset_path}/data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=10,\n",
    "    save_period=10,   # Save checkpoints every 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f86772",
   "metadata": {},
   "source": [
    "After training, we load the best-performing weights (`best.pt`) and run a prediction on a test image to verify that the model is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee58742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=\"test_imgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2390f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb91962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=\"test_imgz/20180829-10-52-03-1253.jpg\", save= True)\n",
    "\n",
    "print(results[0].boxes)  # Print class \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e22963",
   "metadata": {},
   "source": [
    "# **CHECKOUT SYSTEM CREATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e896e",
   "metadata": {},
   "source": [
    "To build the checkout system, we first map the model's specific class predictions (e.g., 'coke', 'pepsi') to broader 'superclasses' (e.g., 'drink'). This simplifies item counting and pricing. We also assign a unique color to each superclass for clear visualization in the output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Your existing mappings\n",
    "SUPERCLASS_MAP = {\n",
    "    'puffed_food': list(range(0, 12)),\n",
    "    'dried_fruit': list(range(12, 21)),\n",
    "    'dried_food': list(range(21, 30)),\n",
    "    'instant_drink': list(range(30, 41)),\n",
    "    'instant_noodles': list(range(41, 53)),\n",
    "    'dessert': list(range(53, 70)),\n",
    "    'drink':     list(range(70, 78)) + list(range(80, 87)),\n",
    "    'alcohol':   list(range(78, 80)) + list(range(87, 96)),\n",
    "    'milk':      list(range(96, 107)),\n",
    "    'canned_food': list(range(107, 121)),\n",
    "    'chocolate': list(range(121, 133)),\n",
    "    'gum':       list(range(133, 141)),\n",
    "    'candy':     list(range(141, 151)),\n",
    "    'seasoner':  list(range(151, 163)),\n",
    "    'personal_hygiene': list(range(163, 173)),\n",
    "    'tissue':    list(range(173, 193)),\n",
    "    'stationery':list(range(193, 200)),\n",
    "}\n",
    "\n",
    "# Invert mapping: class index ‚Üí superclass name\n",
    "INDEX_TO_SUPER = {}\n",
    "for super_name, idx_list in SUPERCLASS_MAP.items():\n",
    "    for idx in idx_list:\n",
    "        INDEX_TO_SUPER[idx] = super_name\n",
    "\n",
    "# Assign a unique color to each superclass (BGR format for OpenCV)\n",
    "random.seed(42)  # For consistent colors\n",
    "SUPERCLASS_COLORS = {\n",
    "    super_name: tuple(random.choices(range(50, 256), k=3))\n",
    "    for super_name in SUPERCLASS_MAP\n",
    "}\n",
    "\n",
    "INDEX_TO_SUPER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67b9dd",
   "metadata": {},
   "source": [
    "Next, we create the core processing function, `annotate_and_count_superclasses`. This function takes the model's raw predictions, filters them by confidence, maps each detection to its superclass, counts the items, and draws colored bounding boxes and labels on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_and_count_superclasses(image, results, confidence_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Annotate YOLO detections with superclass colors and return superclass counts.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        results: YOLO results object from model inference\n",
    "        confidence_threshold: Minimum confidence to consider detection\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (annotated_image, superclass_counts)\n",
    "            - annotated_image: Image with bounding boxes and labels\n",
    "            - superclass_counts: Dictionary with superclass names as keys and counts as values\n",
    "    \"\"\"\n",
    "    annotated_image = image.copy()\n",
    "    superclass_counts = defaultdict(int)\n",
    "    \n",
    "    # Get detection data from YOLO results\n",
    "    if hasattr(results, '__len__') and len(results) > 0:\n",
    "        r = results[0]  # First image results\n",
    "        \n",
    "        if r.boxes is not None and len(r.boxes) > 0:\n",
    "            # Extract detection data\n",
    "            boxes = r.boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2\n",
    "            confidences = r.boxes.conf.cpu().numpy()\n",
    "            class_ids = r.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "                \n",
    "                # Get superclass for this class_id\n",
    "                superclass = INDEX_TO_SUPER.get(class_id, 'unknown')\n",
    "                if superclass == 'unknown':\n",
    "                    continue\n",
    "                \n",
    "                # Count this detection\n",
    "                superclass_counts[superclass] += 1\n",
    "                \n",
    "                # Get color for this superclass\n",
    "                color = SUPERCLASS_COLORS.get(superclass, (128, 128, 128))\n",
    "                \n",
    "                # Draw bounding box\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Prepare label text\n",
    "                original_class_name = r.names[class_id] if hasattr(r, 'names') else f\"class_{class_id}\"\n",
    "                label = f\"{superclass}: {original_class_name} ({conf:.2f})\"\n",
    "                \n",
    "                # Calculate text size and background\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 1\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                \n",
    "                # Draw background rectangle for text\n",
    "                cv2.rectangle(annotated_image, \n",
    "                            (x1, y1 - text_height - 10), \n",
    "                            (x1 + text_width, y1), \n",
    "                            color, -1)\n",
    "                \n",
    "                # Draw text\n",
    "                cv2.putText(annotated_image, label, \n",
    "                          (x1, y1 - 5), \n",
    "                          font, font_scale, \n",
    "                          (255, 255, 255), thickness)\n",
    "    \n",
    "    return annotated_image, dict(superclass_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"test_imgz/20180829-10-52-03-1253.jpg\")\n",
    "result_img, count = annotate_and_count_superclasses(image, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.imshow(result_img[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "    results = model.predict(source=image_path)\n",
    "    result_img, count = annotate_and_count_superclasses(image, results)\n",
    "    \n",
    "    print(f\"Detected superclasses: {count}\")\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result_img[..., ::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ce5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pipeline(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb01b66",
   "metadata": {},
   "source": [
    "## **Adding Total Price Counting Feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93155e45",
   "metadata": {},
   "source": [
    "To calculate the final bill, we first define a price for each superclass in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERCLASS_PRICE = {\n",
    "    'puffed_food': 100,\n",
    "    'dried_fruit': 90,\n",
    "    'dried_food': 80,\n",
    "    'instant_drink': 70,\n",
    "    'instant_noodles': 55,\n",
    "    'dessert': 60,\n",
    "    'drink': 50,\n",
    "    'alcohol': 100,\n",
    "    'milk': 40,\n",
    "    'canned_food': 30,\n",
    "    'chocolate': 2,\n",
    "    'gum': 1,\n",
    "    'candy': 5,\n",
    "    'seasoner': 25,\n",
    "    'personal_hygiene': 20,\n",
    "    'tissue': 15,\n",
    "    'stationery': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e363c",
   "metadata": {},
   "source": [
    "We then create the `calculate_total_price` function. This function takes the superclass counts and the price list to compute the subtotal for each category and the final total price, printing a formatted receipt-style breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_price(counts: dict):\n",
    "    \"\"\"\n",
    "    Calculate and print total price based on detection counts and superclass prices\n",
    "    \n",
    "    Args:\n",
    "        counts: Dictionary with superclass names as keys and detection counts as values\n",
    "        prices: Dictionary with superclass names as keys and prices as values\n",
    "    \n",
    "    Returns:\n",
    "        float: Total calculated price\n",
    "    \"\"\"\n",
    "    prices = SUPERCLASS_PRICE\n",
    "    total_price = 0\n",
    "    print(\"Price Breakdown:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for superclass, count in counts.items():\n",
    "        if superclass in prices:\n",
    "            item_price = prices[superclass]\n",
    "            subtotal = item_price * count\n",
    "            total_price += subtotal\n",
    "            \n",
    "            print(f\"{superclass:15} | {count:2d} √ó {item_price:3d} = {subtotal:4d}\")\n",
    "        else:\n",
    "            print(f\"{superclass:15} | {count:2d} √ó ??? = ???  (Price not found)\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'TOTAL':15} |            = {total_price:4.0f}\")\n",
    "    \n",
    "    return total_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c542a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = calculate_total_price(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09149",
   "metadata": {},
   "source": [
    "## **Final Checkout Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79818d7f",
   "metadata": {},
   "source": [
    "Finally, we wrap all the previous steps into a single `checkout` pipeline. This master function takes an image path and orchestrates the entire process‚Äîrunning prediction, annotating and counting items, and calculating the final price‚Äîto provide a complete, end-to-end solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkout(image_path):\n",
    "    \"\"\"\n",
    "    Perform checkout by calculating total price based on detected items in the image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image for detection\n",
    "    \n",
    "    Returns:\n",
    "        float: Total price of detected items\n",
    "    \"\"\"\n",
    "    counts = pipeline(image_path)\n",
    "    total_price = calculate_total_price(counts)\n",
    "    print(f\"Total price for items in {image_path}: ${total_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189878ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f24f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üë®‚Äçüíª About Labellerr's Hands-On Learning in Computer Vision\n",
    "\n",
    "Thank you for exploring this **Labellerr Hands-On Computer Vision Cookbook**! We hope this notebook helped you learn, prototype, and accelerate your vision projects.  \n",
    "Labellerr provides ready-to-run Jupyter/Colab notebooks for the latest models and real-world use cases in computer vision, AI agents, and data annotation.\n",
    "\n",
    "---\n",
    "## üßë‚Äçüî¨ Check Our Popular Youtube Videos\n",
    "\n",
    "Whether you're a beginner or a practitioner, our hands-on training videos are perfect for learning custom model building, computer vision techniques, and applied AI:\n",
    "\n",
    "- [How to Fine-Tune YOLO on Custom Dataset](https://www.youtube.com/watch?v=pBLWOe01QXU)  \n",
    "  Step-by-step guide to fine-tuning YOLO for real-world use‚Äîenvironment setup, annotation, training, validation, and inference.\n",
    "- [Build a Real-Time Intrusion Detection System with YOLO](https://www.youtube.com/watch?v=kwQeokYDVcE)  \n",
    "  Create an AI-powered system to detect intruders in real time using YOLO and computer vision.\n",
    "- [Finding Athlete Speed Using YOLO](https://www.youtube.com/watch?v=txW0CQe_pw0)  \n",
    "  Estimate real-time speed of athletes for sports analytics.\n",
    "- [Object Counting Using AI](https://www.youtube.com/watch?v=smsjBBQcIUQ)  \n",
    "  Learn dataset curation, annotation, and training for robust object counting AI applications.\n",
    "---\n",
    "\n",
    "## üé¶ Popular Labellerr YouTube Videos\n",
    "\n",
    "Level up your skills and see video walkthroughs of these tools and notebooks on the  \n",
    "[Labellerr YouTube Channel](https://www.youtube.com/@Labellerr/videos):\n",
    "\n",
    "- [How I Fixed My Biggest Annotation Nightmare with Labellerr](https://www.youtube.com/watch?v=hlcFdiuz_HI) ‚Äì Solving complex annotation for ML engineers.\n",
    "- [Explore Your Dataset with Labellerr's AI](https://www.youtube.com/watch?v=LdbRXYWVyN0) ‚Äì Auto-tagging, object counting, image descriptions, and dataset exploration.\n",
    "- [Boost AI Image Annotation 10X with Labellerr's CLIP Mode](https://www.youtube.com/watch?v=pY_o4EvYMz8) ‚Äì Refine annotations with precision using CLIP mode.\n",
    "- [Boost Data Annotation Accuracy and Efficiency with Active Learning](https://www.youtube.com/watch?v=lAYu-ewIhTE) ‚Äì Speed up your annotation workflow using Active Learning.\n",
    "\n",
    "> üëâ **Subscribe** for Labellerr's deep learning, annotation, and AI tutorials, or watch videos directly alongside notebooks!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Stay Connected\n",
    "\n",
    "- **Website:** [https://www.labellerr.com/](https://www.labellerr.com/)\n",
    "- **Blog:** [https://www.labellerr.com/blog/](https://www.labellerr.com/blog/)\n",
    "- **GitHub:** [Labellerr/Hands-On-Learning-in-Computer-Vision](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "- **LinkedIn:** [Labellerr](https://in.linkedin.com/company/labellerr)\n",
    "- **Twitter/X:** [@Labellerr1](https://x.com/Labellerr1)\n",
    "\n",
    "*Happy learning and building with Labellerr!*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
